From c0748fe6dec5927bb343c2bb25741fc5d0d280a2 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Micha=C5=82=20G=C3=B3rny?= <mgorny@gentoo.org>
Date: Mon, 3 Oct 2022 09:59:34 +0200
Subject: [PATCH 01/84] [clang-tools-extra] [clangd] Respect llvm_shlib_dir in
 tests

Add llvm_shlib_dir to variables used in clangd test suite, consistently
to how it is used in the test suites of clang, clang-tools-extra
and a few other components.  This is necessary to ensure that
the correct shared libraries are used when building clang standalone --
otherwise, use_clang() sets LD_LIBRARY_PATH to the directory containing
the earlier system installation of clang rather than the just-built
library.

Differential Revision: https://reviews.llvm.org/D135062

(cherry picked from commit 77945a344c3dee3f9735744c8d4151ef2cec6a8d)
---
 clang-tools-extra/clangd/test/lit.site.cfg.py.in | 1 +
 1 file changed, 1 insertion(+)

diff --git a/clang-tools-extra/clangd/test/lit.site.cfg.py.in b/clang-tools-extra/clangd/test/lit.site.cfg.py.in
index 20caa72af3da1f..1fe7c8d0f32449 100644
--- a/clang-tools-extra/clangd/test/lit.site.cfg.py.in
+++ b/clang-tools-extra/clangd/test/lit.site.cfg.py.in
@@ -10,6 +10,7 @@ config.python_executable = "@Python3_EXECUTABLE@"
 config.clang_tools_dir = lit_config.substitute("@CURRENT_TOOLS_DIR@")
 config.llvm_tools_dir = lit_config.substitute("@LLVM_TOOLS_DIR@")
 config.llvm_libs_dir = lit_config.substitute("@LLVM_LIBS_DIR@")
+config.llvm_shlib_dir = "@SHLIBDIR@"
 
 config.clangd_source_dir = "@CMAKE_CURRENT_SOURCE_DIR@/.."
 config.clangd_binary_dir = "@CMAKE_CURRENT_BINARY_DIR@/.."

From 61fa70903191f2350dc20dee2c9f45a8fbdf28af Mon Sep 17 00:00:00 2001
From: Florian Hahn <flo@fhahn.com>
Date: Fri, 23 Sep 2022 11:53:29 +0100
Subject: [PATCH 02/84] [LoopVersioning] Invalidate SCEV for phi if new values
 are added.

After 20d798bd47ec5191d, SCEV looks through PHIs with a single incoming
value. This means adding a new incoming value may change the SCEV for a
phi. Add missing invalidation when an existing PHI is reused during
LoopVersioning. New incoming values will be added later from the
versioned loop.

Similar issues have been fixed by also adding missing invalidation.

Fixes #57825.

Note that the test case unfortunately requires running loop-vectorize
followed by loop-load-elimination, which does the actual versioning. I
don't think it is possible to reproduce the failure without that
combination.

(cherry picked from commit 623c4a7a55f716b96070a5c2f83fe0096cb38d38)
---
 llvm/lib/Transforms/Utils/LoopVersioning.cpp  |   4 +-
 .../versioning-scev-invalidation.ll           | 125 ++++++++++++++++++
 2 files changed, 128 insertions(+), 1 deletion(-)
 create mode 100644 llvm/test/Transforms/LoopLoadElim/versioning-scev-invalidation.ll

diff --git a/llvm/lib/Transforms/Utils/LoopVersioning.cpp b/llvm/lib/Transforms/Utils/LoopVersioning.cpp
index 97f29527bb95ca..6309eed7963d14 100644
--- a/llvm/lib/Transforms/Utils/LoopVersioning.cpp
+++ b/llvm/lib/Transforms/Utils/LoopVersioning.cpp
@@ -137,8 +137,10 @@ void LoopVersioning::addPHINodes(
     // See if we have a single-operand PHI with the value defined by the
     // original loop.
     for (auto I = PHIBlock->begin(); (PN = dyn_cast<PHINode>(I)); ++I) {
-      if (PN->getIncomingValue(0) == Inst)
+      if (PN->getIncomingValue(0) == Inst) {
+        SE->forgetValue(PN);
         break;
+      }
     }
     // If not create it.
     if (!PN) {
diff --git a/llvm/test/Transforms/LoopLoadElim/versioning-scev-invalidation.ll b/llvm/test/Transforms/LoopLoadElim/versioning-scev-invalidation.ll
new file mode 100644
index 00000000000000..4b0bc908eddfa5
--- /dev/null
+++ b/llvm/test/Transforms/LoopLoadElim/versioning-scev-invalidation.ll
@@ -0,0 +1,125 @@
+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
+; RUN: opt -force-vector-width=4 -force-vector-interleave=1 -passes='loop-vectorize,loop-load-elim' -S %s | FileCheck %s
+
+@glob.1 = external global [100 x double]
+@glob.2 = external global [100 x double]
+
+define void @g(ptr %dst.1, ptr %start, i64 %N) {
+; CHECK-LABEL: @g(
+; CHECK-NEXT:  loop.1.lver.check:
+; CHECK-NEXT:    [[TMP0:%.*]] = shl i64 [[N:%.*]], 3
+; CHECK-NEXT:    [[TMP1:%.*]] = add i64 [[TMP0]], 16
+; CHECK-NEXT:    [[UGLYGEP:%.*]] = getelementptr i8, ptr @glob.2, i64 [[TMP1]]
+; CHECK-NEXT:    [[UGLYGEP2:%.*]] = getelementptr i8, ptr [[DST_1:%.*]], i64 8
+; CHECK-NEXT:    [[BOUND0:%.*]] = icmp ult ptr @glob.2, [[UGLYGEP2]]
+; CHECK-NEXT:    [[BOUND1:%.*]] = icmp ult ptr [[DST_1]], [[UGLYGEP]]
+; CHECK-NEXT:    [[FOUND_CONFLICT:%.*]] = and i1 [[BOUND0]], [[BOUND1]]
+; CHECK-NEXT:    br i1 [[FOUND_CONFLICT]], label [[LOOP_1_PH_LVER_ORIG:%.*]], label [[LOOP_1_PH:%.*]]
+; CHECK:       loop.1.ph.lver.orig:
+; CHECK-NEXT:    br label [[LOOP_1_LVER_ORIG:%.*]]
+; CHECK:       loop.1.lver.orig:
+; CHECK-NEXT:    [[IV_LVER_ORIG:%.*]] = phi i64 [ 0, [[LOOP_1_PH_LVER_ORIG]] ], [ [[IV_NEXT_LVER_ORIG:%.*]], [[LOOP_1_LVER_ORIG]] ]
+; CHECK-NEXT:    [[PTR_IV_1_LVER_ORIG:%.*]] = phi ptr [ @glob.1, [[LOOP_1_PH_LVER_ORIG]] ], [ [[PTR_IV_1_NEXT_LVER_ORIG:%.*]], [[LOOP_1_LVER_ORIG]] ]
+; CHECK-NEXT:    [[GEP_IV_LVER_ORIG:%.*]] = getelementptr inbounds double, ptr @glob.2, i64 [[IV_LVER_ORIG]]
+; CHECK-NEXT:    [[L_1_LVER_ORIG:%.*]] = load double, ptr [[GEP_IV_LVER_ORIG]], align 8
+; CHECK-NEXT:    [[GEP_IV_1_LVER_ORIG:%.*]] = getelementptr inbounds double, ptr getelementptr inbounds (double, ptr @glob.2, i64 1), i64 [[IV_LVER_ORIG]]
+; CHECK-NEXT:    store double 0.000000e+00, ptr [[GEP_IV_1_LVER_ORIG]], align 8
+; CHECK-NEXT:    store double 0.000000e+00, ptr [[DST_1]], align 8
+; CHECK-NEXT:    [[PTR_IV_1_NEXT_LVER_ORIG]] = getelementptr inbounds double, ptr [[PTR_IV_1_LVER_ORIG]], i64 1
+; CHECK-NEXT:    [[IV_NEXT_LVER_ORIG]] = add nuw nsw i64 [[IV_LVER_ORIG]], 1
+; CHECK-NEXT:    [[EXITCOND_NOT_LVER_ORIG:%.*]] = icmp eq i64 [[IV_LVER_ORIG]], [[N]]
+; CHECK-NEXT:    br i1 [[EXITCOND_NOT_LVER_ORIG]], label [[LOOP_2_PH_LOOPEXIT:%.*]], label [[LOOP_1_LVER_ORIG]]
+; CHECK:       loop.1.ph:
+; CHECK-NEXT:    [[LOAD_INITIAL:%.*]] = load double, ptr @glob.2, align 8
+; CHECK-NEXT:    br label [[LOOP_1:%.*]]
+; CHECK:       loop.1:
+; CHECK-NEXT:    [[STORE_FORWARDED:%.*]] = phi double [ [[LOAD_INITIAL]], [[LOOP_1_PH]] ], [ 0.000000e+00, [[LOOP_1]] ]
+; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ 0, [[LOOP_1_PH]] ], [ [[IV_NEXT:%.*]], [[LOOP_1]] ]
+; CHECK-NEXT:    [[PTR_IV_1:%.*]] = phi ptr [ @glob.1, [[LOOP_1_PH]] ], [ [[PTR_IV_1_NEXT:%.*]], [[LOOP_1]] ]
+; CHECK-NEXT:    [[GEP_IV:%.*]] = getelementptr inbounds double, ptr @glob.2, i64 [[IV]]
+; CHECK-NEXT:    [[L_1:%.*]] = load double, ptr [[GEP_IV]], align 8
+; CHECK-NEXT:    [[GEP_IV_1:%.*]] = getelementptr inbounds double, ptr getelementptr inbounds (double, ptr @glob.2, i64 1), i64 [[IV]]
+; CHECK-NEXT:    store double 0.000000e+00, ptr [[GEP_IV_1]], align 8
+; CHECK-NEXT:    store double 0.000000e+00, ptr [[DST_1]], align 8
+; CHECK-NEXT:    [[PTR_IV_1_NEXT]] = getelementptr inbounds double, ptr [[PTR_IV_1]], i64 1
+; CHECK-NEXT:    [[IV_NEXT]] = add nuw nsw i64 [[IV]], 1
+; CHECK-NEXT:    [[EXITCOND_NOT:%.*]] = icmp eq i64 [[IV]], [[N]]
+; CHECK-NEXT:    br i1 [[EXITCOND_NOT]], label [[LOOP_2_PH_LOOPEXIT3:%.*]], label [[LOOP_1]]
+; CHECK:       loop.2.ph.loopexit:
+; CHECK-NEXT:    [[LCSSA_PTR_IV_1_PH:%.*]] = phi ptr [ [[PTR_IV_1_LVER_ORIG]], [[LOOP_1_LVER_ORIG]] ]
+; CHECK-NEXT:    br label [[LOOP_2_PH:%.*]]
+; CHECK:       loop.2.ph.loopexit3:
+; CHECK-NEXT:    [[LCSSA_PTR_IV_1_PH4:%.*]] = phi ptr [ [[PTR_IV_1]], [[LOOP_1]] ]
+; CHECK-NEXT:    br label [[LOOP_2_PH]]
+; CHECK:       loop.2.ph:
+; CHECK-NEXT:    [[LCSSA_PTR_IV_1:%.*]] = phi ptr [ [[LCSSA_PTR_IV_1_PH]], [[LOOP_2_PH_LOOPEXIT]] ], [ [[LCSSA_PTR_IV_1_PH4]], [[LOOP_2_PH_LOOPEXIT3]] ]
+; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i64 [[N]], 4
+; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
+; CHECK:       vector.ph:
+; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i64 [[N]], 4
+; CHECK-NEXT:    [[N_VEC:%.*]] = sub i64 [[N]], [[N_MOD_VF]]
+; CHECK-NEXT:    [[TMP2:%.*]] = mul i64 [[N_VEC]], 8
+; CHECK-NEXT:    [[IND_END:%.*]] = getelementptr i8, ptr [[LCSSA_PTR_IV_1]], i64 [[TMP2]]
+; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
+; CHECK:       vector.body:
+; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
+; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[INDEX]], 0
+; CHECK-NEXT:    [[TMP4:%.*]] = mul i64 [[TMP3]], 8
+; CHECK-NEXT:    [[NEXT_GEP:%.*]] = getelementptr i8, ptr [[LCSSA_PTR_IV_1]], i64 [[TMP4]]
+; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr double, ptr [[NEXT_GEP]], i32 0
+; CHECK-NEXT:    store <4 x double> zeroinitializer, ptr [[TMP5]], align 8
+; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
+; CHECK-NEXT:    [[TMP6:%.*]] = icmp eq i64 [[INDEX_NEXT]], [[N_VEC]]
+; CHECK-NEXT:    br i1 [[TMP6]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
+; CHECK:       middle.block:
+; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 [[N]], [[N_VEC]]
+; CHECK-NEXT:    br i1 [[CMP_N]], label [[EXIT:%.*]], label [[SCALAR_PH]]
+; CHECK:       scalar.ph:
+; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ [[N_VEC]], [[MIDDLE_BLOCK]] ], [ 0, [[LOOP_2_PH]] ]
+; CHECK-NEXT:    [[BC_RESUME_VAL1:%.*]] = phi ptr [ [[IND_END]], [[MIDDLE_BLOCK]] ], [ [[LCSSA_PTR_IV_1]], [[LOOP_2_PH]] ]
+; CHECK-NEXT:    br label [[LOOP_2:%.*]]
+; CHECK:       loop.2:
+; CHECK-NEXT:    [[IV_2:%.*]] = phi i64 [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ], [ [[IV_2_NEXT:%.*]], [[LOOP_2]] ]
+; CHECK-NEXT:    [[PTR_IV_2:%.*]] = phi ptr [ [[BC_RESUME_VAL1]], [[SCALAR_PH]] ], [ [[PTR_IV_2_NEXT:%.*]], [[LOOP_2]] ]
+; CHECK-NEXT:    store double 0.000000e+00, ptr [[PTR_IV_2]], align 8
+; CHECK-NEXT:    [[PTR_IV_2_NEXT]] = getelementptr inbounds double, ptr [[PTR_IV_2]], i64 1
+; CHECK-NEXT:    [[IV_2_NEXT]] = add nuw nsw i64 [[IV_2]], 1
+; CHECK-NEXT:    [[EXITCOND_1_NOT:%.*]] = icmp eq i64 [[IV_2_NEXT]], [[N]]
+; CHECK-NEXT:    br i1 [[EXITCOND_1_NOT]], label [[EXIT_LOOPEXIT:%.*]], label [[LOOP_2]], !llvm.loop [[LOOP2:![0-9]+]]
+; CHECK:       exit.loopexit:
+; CHECK-NEXT:    br label [[EXIT]]
+; CHECK:       exit:
+; CHECK-NEXT:    ret void
+;
+entry:
+  br label %loop.1
+
+loop.1:
+  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop.1 ]
+  %ptr.iv.1 = phi ptr [ @glob.1, %entry ], [ %ptr.iv.1.next, %loop.1 ]
+  %gep.iv = getelementptr inbounds double, ptr @glob.2, i64 %iv
+  %l.1 = load double, ptr %gep.iv, align 8
+  %gep.iv.1 = getelementptr inbounds double, ptr getelementptr inbounds (double, ptr @glob.2, i64 1), i64 %iv
+  store double 0.000000e+00, ptr %gep.iv.1, align 8
+  store double 0.000000e+00, ptr %dst.1, align 8
+  %ptr.iv.1.next = getelementptr inbounds double, ptr %ptr.iv.1, i64 1
+  %iv.next = add nuw nsw i64 %iv, 1
+  %exitcond.not = icmp eq i64 %iv, %N
+  br i1 %exitcond.not, label %loop.2.ph, label %loop.1
+
+loop.2.ph:
+  %lcssa.ptr.iv.1 = phi ptr [ %ptr.iv.1, %loop.1 ]
+  br label %loop.2
+
+loop.2:
+  %iv.2 = phi i64 [ 0, %loop.2.ph ] , [ %iv.2.next, %loop.2 ]
+  %ptr.iv.2 = phi ptr [ %lcssa.ptr.iv.1, %loop.2.ph ], [ %ptr.iv.2.next, %loop.2 ]
+  store double 0.000000e+00, ptr %ptr.iv.2, align 8
+  %ptr.iv.2.next = getelementptr inbounds double, ptr %ptr.iv.2, i64 1
+  %iv.2.next = add nuw nsw i64 %iv.2, 1
+  %exitcond.1.not = icmp eq i64 %iv.2.next, %N
+  br i1 %exitcond.1.not, label %exit, label %loop.2
+
+exit:
+  ret void
+}

From 73ea64f30411bcb9a2f32649a49d4c23780ee045 Mon Sep 17 00:00:00 2001
From: Sam McCall <sam.mccall@gmail.com>
Date: Wed, 5 Oct 2022 22:23:10 +0200
Subject: [PATCH 03/84] [clangd] Avoid scanning up to end of file on each
 comment!

Assigning char* (pointing at comment start) to StringRef was causing us
to scan the rest of the source file looking for the null terminator.

This seems to be eating about 8% of our *total* CPU!

While fixing this, factor out the common bits from the two places we're
parsing IWYU pragmas.

Differential Revision: https://reviews.llvm.org/D135314

(cherry picked from commit 5d2d527c32da2081b814ef8b446bc3e037f74b0a)
---
 clang-tools-extra/clangd/Headers.cpp          | 26 ++++++++++++-------
 clang-tools-extra/clangd/Headers.h            |  6 +++++
 .../clangd/index/CanonicalIncludes.cpp        | 16 +++++-------
 .../clangd/unittests/HeadersTests.cpp         | 14 ++++++++++
 4 files changed, 43 insertions(+), 19 deletions(-)

diff --git a/clang-tools-extra/clangd/Headers.cpp b/clang-tools-extra/clangd/Headers.cpp
index cb7abac3e9f9e3..af22a446b03cea 100644
--- a/clang-tools-extra/clangd/Headers.cpp
+++ b/clang-tools-extra/clangd/Headers.cpp
@@ -22,9 +22,17 @@
 namespace clang {
 namespace clangd {
 
-const char IWYUPragmaKeep[] = "// IWYU pragma: keep";
-const char IWYUPragmaExport[] = "// IWYU pragma: export";
-const char IWYUPragmaBeginExports[] = "// IWYU pragma: begin_exports";
+llvm::Optional<StringRef> parseIWYUPragma(const char *Text) {
+  // This gets called for every comment seen in the preamble, so it's quite hot.
+  constexpr llvm::StringLiteral IWYUPragma = "// IWYU pragma: ";
+  if (strncmp(Text, IWYUPragma.data(), IWYUPragma.size()))
+    return llvm::None;
+  Text += IWYUPragma.size();
+  const char *End = Text;
+  while (*End != 0 && *End != '\n')
+    ++End;
+  return StringRef(Text, End - Text);
+}
 
 class IncludeStructure::RecordHeaders : public PPCallbacks,
                                         public CommentHandler {
@@ -129,10 +137,10 @@ class IncludeStructure::RecordHeaders : public PPCallbacks,
   }
 
   bool HandleComment(Preprocessor &PP, SourceRange Range) override {
-    bool Err = false;
-    llvm::StringRef Text = SM.getCharacterData(Range.getBegin(), &Err);
-    if (Err)
+    auto Pragma = parseIWYUPragma(SM.getCharacterData(Range.getBegin()));
+    if (!Pragma)
       return false;
+
     if (inMainFile()) {
       // Given:
       //
@@ -150,8 +158,7 @@ class IncludeStructure::RecordHeaders : public PPCallbacks,
       // will know that the next inclusion is behind the IWYU pragma.
       // FIXME: Support "IWYU pragma: begin_exports" and "IWYU pragma:
       // end_exports".
-      if (!Text.startswith(IWYUPragmaExport) &&
-          !Text.startswith(IWYUPragmaKeep))
+      if (!Pragma->startswith("export") && !Pragma->startswith("keep"))
         return false;
       unsigned Offset = SM.getFileOffset(Range.getBegin());
       LastPragmaKeepInMainFileLine =
@@ -161,8 +168,7 @@ class IncludeStructure::RecordHeaders : public PPCallbacks,
       // does not support them properly yet, so they will be not marked as
       // unused.
       // FIXME: Once IncludeCleaner supports export pragmas, remove this.
-      if (!Text.startswith(IWYUPragmaExport) &&
-          !Text.startswith(IWYUPragmaBeginExports))
+      if (!Pragma->startswith("export") && !Pragma->startswith("begin_exports"))
         return false;
       Out->HasIWYUExport.insert(
           *Out->getID(SM.getFileEntryForID(SM.getFileID(Range.getBegin()))));
diff --git a/clang-tools-extra/clangd/Headers.h b/clang-tools-extra/clangd/Headers.h
index ff3f0631683259..ba72ad397bf8f7 100644
--- a/clang-tools-extra/clangd/Headers.h
+++ b/clang-tools-extra/clangd/Headers.h
@@ -35,6 +35,12 @@ namespace clangd {
 /// Returns true if \p Include is literal include like "path" or <path>.
 bool isLiteralInclude(llvm::StringRef Include);
 
+/// If Text begins an Include-What-You-Use directive, returns it.
+/// Given "// IWYU pragma: keep", returns "keep".
+/// Input is a null-terminated char* as provided by SM.getCharacterData().
+/// (This should not be StringRef as we do *not* want to scan for its length).
+llvm::Optional<StringRef> parseIWYUPragma(const char *Text);
+
 /// Represents a header file to be #include'd.
 struct HeaderFile {
   std::string File;
diff --git a/clang-tools-extra/clangd/index/CanonicalIncludes.cpp b/clang-tools-extra/clangd/index/CanonicalIncludes.cpp
index 145d98d57ca83d..bbc80e7e0d1396 100644
--- a/clang-tools-extra/clangd/index/CanonicalIncludes.cpp
+++ b/clang-tools-extra/clangd/index/CanonicalIncludes.cpp
@@ -17,8 +17,6 @@
 namespace clang {
 namespace clangd {
 namespace {
-const char IWYUPragma[] = "// IWYU pragma: private, include ";
-
 const std::pair<llvm::StringRef, llvm::StringRef> IncludeMappings[] = {
     {"include/__stddef_max_align_t.h", "<cstddef>"},
     {"include/__wmmintrin_aes.h", "<wmmintrin.h>"},
@@ -712,17 +710,17 @@ collectIWYUHeaderMaps(CanonicalIncludes *Includes) {
     PragmaCommentHandler(CanonicalIncludes *Includes) : Includes(Includes) {}
 
     bool HandleComment(Preprocessor &PP, SourceRange Range) override {
-      llvm::StringRef Text =
-          Lexer::getSourceText(CharSourceRange::getCharRange(Range),
-                               PP.getSourceManager(), PP.getLangOpts());
-      if (!Text.consume_front(IWYUPragma))
+      auto Pragma = parseIWYUPragma(
+          PP.getSourceManager().getCharacterData(Range.getBegin()));
+      if (!Pragma || !Pragma->consume_front("private, include "))
         return false;
       auto &SM = PP.getSourceManager();
       // We always insert using the spelling from the pragma.
       if (auto *FE = SM.getFileEntryForID(SM.getFileID(Range.getBegin())))
-        Includes->addMapping(
-            FE->getLastRef(),
-            isLiteralInclude(Text) ? Text.str() : ("\"" + Text + "\"").str());
+        Includes->addMapping(FE->getLastRef(),
+                             isLiteralInclude(*Pragma)
+                                 ? Pragma->str()
+                                 : ("\"" + *Pragma + "\"").str());
       return false;
     }
 
diff --git a/clang-tools-extra/clangd/unittests/HeadersTests.cpp b/clang-tools-extra/clangd/unittests/HeadersTests.cpp
index 32e4aea15490bd..324d4b58a1ef1b 100644
--- a/clang-tools-extra/clangd/unittests/HeadersTests.cpp
+++ b/clang-tools-extra/clangd/unittests/HeadersTests.cpp
@@ -9,6 +9,7 @@
 #include "Headers.h"
 
 #include "Compiler.h"
+#include "Matchers.h"
 #include "TestFS.h"
 #include "TestTU.h"
 #include "clang/Basic/TokenKinds.h"
@@ -30,6 +31,7 @@ namespace {
 using ::testing::AllOf;
 using ::testing::Contains;
 using ::testing::ElementsAre;
+using ::testing::Eq;
 using ::testing::IsEmpty;
 using ::testing::Not;
 using ::testing::UnorderedElementsAre;
@@ -445,6 +447,18 @@ TEST_F(HeadersTest, HasIWYUPragmas) {
   EXPECT_FALSE(Includes.hasIWYUExport(getID("none.h", Includes)));
 }
 
+TEST(Headers, ParseIWYUPragma) {
+  EXPECT_THAT(parseIWYUPragma("// IWYU pragma: keep"), HasValue(Eq("keep")));
+  EXPECT_THAT(parseIWYUPragma("// IWYU pragma: keep\netc"),
+              HasValue(Eq("keep")));
+  EXPECT_EQ(parseIWYUPragma("/* IWYU pragma: keep"), llvm::None)
+      << "Only // comments supported!";
+  EXPECT_EQ(parseIWYUPragma("//  IWYU pragma: keep"), llvm::None)
+      << "Sensitive to whitespace";
+  EXPECT_EQ(parseIWYUPragma("// IWYU pragma:keep"), llvm::None)
+      << "Sensitive to whitespace";
+}
+
 } // namespace
 } // namespace clangd
 } // namespace clang

From bd5722b87b5aa1b8286762af7f29b6aae669dee1 Mon Sep 17 00:00:00 2001
From: Freddy Ye <freddy.ye@intel.com>
Date: Sat, 8 Oct 2022 14:27:06 +0800
Subject: [PATCH 04/84] [X86] Remove AVX512VP2INTERSECT from Sapphire Rapids.

For more details, please refer to the latest ISE document: https://www.intel.com/content/www/us/en/develop/download/intel-architecture-instruction-set-extensions-programming-reference.html

Reviewed By: pengfei

Differential Revision: https://reviews.llvm.org/D135509

(cherry picked from commit 566c277c64f8f76d8911aa5fd931903a357ed7be)
---
 llvm/lib/Support/X86TargetParser.cpp | 10 +++++-----
 llvm/lib/Target/X86/X86.td           |  1 -
 2 files changed, 5 insertions(+), 6 deletions(-)

diff --git a/llvm/lib/Support/X86TargetParser.cpp b/llvm/lib/Support/X86TargetParser.cpp
index 2567f3ed8034bb..0daaa6d815bf07 100644
--- a/llvm/lib/Support/X86TargetParser.cpp
+++ b/llvm/lib/Support/X86TargetParser.cpp
@@ -203,10 +203,10 @@ constexpr FeatureBitset FeaturesTigerlake =
     FeatureCLWB | FeatureMOVDIRI | FeatureSHSTK | FeatureKL | FeatureWIDEKL;
 constexpr FeatureBitset FeaturesSapphireRapids =
     FeaturesICLServer | FeatureAMX_BF16 | FeatureAMX_INT8 | FeatureAMX_TILE |
-    FeatureAVX512BF16 | FeatureAVX512FP16 | FeatureAVX512VP2INTERSECT |
-    FeatureAVXVNNI | FeatureCLDEMOTE | FeatureENQCMD | FeatureMOVDIR64B |
-    FeatureMOVDIRI | FeaturePTWRITE | FeatureSERIALIZE | FeatureSHSTK |
-    FeatureTSXLDTRK | FeatureUINTR | FeatureWAITPKG;
+    FeatureAVX512BF16 | FeatureAVX512FP16 | FeatureAVXVNNI | FeatureCLDEMOTE |
+    FeatureENQCMD | FeatureMOVDIR64B | FeatureMOVDIRI | FeaturePTWRITE |
+    FeatureSERIALIZE | FeatureSHSTK | FeatureTSXLDTRK | FeatureUINTR |
+    FeatureWAITPKG;
 
 // Intel Atom processors.
 // Bonnell has feature parity with Core2 and adds MOVBE.
@@ -367,7 +367,7 @@ constexpr ProcInfo Processors[] = {
   // Tigerlake microarchitecture based processors.
   { {"tigerlake"}, CK_Tigerlake, FEATURE_AVX512VP2INTERSECT, FeaturesTigerlake },
   // Sapphire Rapids microarchitecture based processors.
-  { {"sapphirerapids"}, CK_SapphireRapids, FEATURE_AVX512VP2INTERSECT, FeaturesSapphireRapids },
+  { {"sapphirerapids"}, CK_SapphireRapids, FEATURE_AVX512BF16, FeaturesSapphireRapids },
   // Alderlake microarchitecture based processors.
   { {"alderlake"}, CK_Alderlake, FEATURE_AVX2, FeaturesAlderlake },
   // Knights Landing processor.
diff --git a/llvm/lib/Target/X86/X86.td b/llvm/lib/Target/X86/X86.td
index fa0a6bd415dc0a..f98916e81cee9f 100644
--- a/llvm/lib/Target/X86/X86.td
+++ b/llvm/lib/Target/X86/X86.td
@@ -909,7 +909,6 @@ def ProcessorFeatures {
                                                   FeatureTSXLDTRK,
                                                   FeatureENQCMD,
                                                   FeatureSHSTK,
-                                                  FeatureVP2INTERSECT,
                                                   FeatureMOVDIRI,
                                                   FeatureMOVDIR64B,
                                                   FeatureUINTR];

From 359ef0c932404d31347ce25895fdcadee1004381 Mon Sep 17 00:00:00 2001
From: Sam McCall <sam.mccall@gmail.com>
Date: Fri, 16 Sep 2022 00:41:32 +0200
Subject: [PATCH 05/84] [clangd] Improve inlay hints of things expanded from
 macros

When we aim a hint at some expanded tokens, we're only willing to attach it
to spelled tokens that exactly corresponde.

e.g.
int zoom(int x, int y, int z);
int dummy = zoom(NUMBERS);

Here we want to place a hint "x:" on the expanded "1", but we shouldn't
be willing to place it on NUMBERS, because it doesn't *exactly*
correspond (it has more tokens).

Fortunately we don't even have to implement this algorithm from scratch,
TokenBuffer has it.

Fixes https://github.com/clangd/clangd/issues/1289
Fixes https://github.com/clangd/clangd/issues/1118
Fixes https://github.com/clangd/clangd/issues/1018

Differential Revision: https://reviews.llvm.org/D133982

(cherry picked from commit 924974a3a13b03090d04860f209ce11b3d9d00a6)
---
 clang-tools-extra/clangd/InlayHints.cpp       | 59 +++++++++----------
 .../clangd/unittests/InlayHintTests.cpp       |  9 +++
 2 files changed, 38 insertions(+), 30 deletions(-)

diff --git a/clang-tools-extra/clangd/InlayHints.cpp b/clang-tools-extra/clangd/InlayHints.cpp
index 7be05fbc3b3483..16c6b1cecc0313 100644
--- a/clang-tools-extra/clangd/InlayHints.cpp
+++ b/clang-tools-extra/clangd/InlayHints.cpp
@@ -10,6 +10,7 @@
 #include "Config.h"
 #include "HeuristicResolver.h"
 #include "ParsedAST.h"
+#include "SourceCode.h"
 #include "clang/AST/Decl.h"
 #include "clang/AST/DeclarationName.h"
 #include "clang/AST/ExprCXX.h"
@@ -192,8 +193,8 @@ class InlayHintVisitor : public RecursiveASTVisitor<InlayHintVisitor> {
 public:
   InlayHintVisitor(std::vector<InlayHint> &Results, ParsedAST &AST,
                    const Config &Cfg, llvm::Optional<Range> RestrictRange)
-      : Results(Results), AST(AST.getASTContext()), Cfg(Cfg),
-        RestrictRange(std::move(RestrictRange)),
+      : Results(Results), AST(AST.getASTContext()), Tokens(AST.getTokens()),
+        Cfg(Cfg), RestrictRange(std::move(RestrictRange)),
         MainFileID(AST.getSourceManager().getMainFileID()),
         Resolver(AST.getHeuristicResolver()),
         TypeHintPolicy(this->AST.getPrintingPolicy()),
@@ -227,8 +228,7 @@ class InlayHintVisitor : public RecursiveASTVisitor<InlayHintVisitor> {
       return true;
     }
 
-    processCall(E->getParenOrBraceRange().getBegin(), E->getConstructor(),
-                {E->getArgs(), E->getNumArgs()});
+    processCall(E->getConstructor(), {E->getArgs(), E->getNumArgs()});
     return true;
   }
 
@@ -254,7 +254,7 @@ class InlayHintVisitor : public RecursiveASTVisitor<InlayHintVisitor> {
     if (!Callee)
       return true;
 
-    processCall(E->getRParenLoc(), Callee, {E->getArgs(), E->getNumArgs()});
+    processCall(Callee, {E->getArgs(), E->getNumArgs()});
     return true;
   }
 
@@ -278,11 +278,11 @@ class InlayHintVisitor : public RecursiveASTVisitor<InlayHintVisitor> {
     return true;
   }
 
-  void addReturnTypeHint(FunctionDecl *D, SourceLocation Loc) {
+  void addReturnTypeHint(FunctionDecl *D, SourceRange Range) {
     auto *AT = D->getReturnType()->getContainedAutoType();
     if (!AT || AT->getDeducedType().isNull())
       return;
-    addTypeHint(Loc, D->getReturnType(), /*Prefix=*/"-> ");
+    addTypeHint(Range, D->getReturnType(), /*Prefix=*/"-> ");
   }
 
   bool VisitVarDecl(VarDecl *D) {
@@ -375,21 +375,11 @@ class InlayHintVisitor : public RecursiveASTVisitor<InlayHintVisitor> {
 private:
   using NameVec = SmallVector<StringRef, 8>;
 
-  // The purpose of Anchor is to deal with macros. It should be the call's
-  // opening or closing parenthesis or brace. (Always using the opening would
-  // make more sense but CallExpr only exposes the closing.) We heuristically
-  // assume that if this location does not come from a macro definition, then
-  // the entire argument list likely appears in the main file and can be hinted.
-  void processCall(SourceLocation Anchor, const FunctionDecl *Callee,
+  void processCall(const FunctionDecl *Callee,
                    llvm::ArrayRef<const Expr *> Args) {
     if (!Cfg.InlayHints.Parameters || Args.size() == 0 || !Callee)
       return;
 
-    // If the anchor location comes from a macro defintion, there's nowhere to
-    // put hints.
-    if (!AST.getSourceManager().getTopMacroCallerLoc(Anchor).isFileID())
-      return;
-
     // The parameter name of a move or copy constructor is not very interesting.
     if (auto *Ctor = dyn_cast<CXXConstructorDecl>(Callee))
       if (Ctor->isCopyOrMoveConstructor())
@@ -637,25 +627,33 @@ class InlayHintVisitor : public RecursiveASTVisitor<InlayHintVisitor> {
 #undef CHECK_KIND
     }
 
-    auto FileRange =
-        toHalfOpenFileRange(AST.getSourceManager(), AST.getLangOpts(), R);
-    if (!FileRange)
+    auto LSPRange = getHintRange(R);
+    if (!LSPRange)
       return;
-    Range LSPRange{
-        sourceLocToPosition(AST.getSourceManager(), FileRange->getBegin()),
-        sourceLocToPosition(AST.getSourceManager(), FileRange->getEnd())};
-    Position LSPPos = Side == HintSide::Left ? LSPRange.start : LSPRange.end;
+    Position LSPPos = Side == HintSide::Left ? LSPRange->start : LSPRange->end;
     if (RestrictRange &&
         (LSPPos < RestrictRange->start || !(LSPPos < RestrictRange->end)))
       return;
-    // The hint may be in a file other than the main file (for example, a header
-    // file that was included after the preamble), do not show in that case.
-    if (!AST.getSourceManager().isWrittenInMainFile(FileRange->getBegin()))
-      return;
     bool PadLeft = Prefix.consume_front(" ");
     bool PadRight = Suffix.consume_back(" ");
     Results.push_back(InlayHint{LSPPos, (Prefix + Label + Suffix).str(), Kind,
-                                PadLeft, PadRight, LSPRange});
+                                PadLeft, PadRight, *LSPRange});
+  }
+
+  // Get the range of the main file that *exactly* corresponds to R.
+  llvm::Optional<Range> getHintRange(SourceRange R) {
+    const auto &SM = AST.getSourceManager();
+    auto Spelled = Tokens.spelledForExpanded(Tokens.expandedTokens(R));
+    // TokenBuffer will return null if e.g. R corresponds to only part of a
+    // macro expansion.
+    if (!Spelled || Spelled->empty())
+      return llvm::None;
+    // Hint must be within the main file, not e.g. a non-preamble include.
+    if (SM.getFileID(Spelled->front().location()) != SM.getMainFileID() ||
+        SM.getFileID(Spelled->back().location()) != SM.getMainFileID())
+      return llvm::None;
+    return Range{sourceLocToPosition(SM, Spelled->front().location()),
+                 sourceLocToPosition(SM, Spelled->back().endLocation())};
   }
 
   void addTypeHint(SourceRange R, QualType T, llvm::StringRef Prefix) {
@@ -680,6 +678,7 @@ class InlayHintVisitor : public RecursiveASTVisitor<InlayHintVisitor> {
 
   std::vector<InlayHint> &Results;
   ASTContext &AST;
+  const syntax::TokenBuffer &Tokens;
   const Config &Cfg;
   llvm::Optional<Range> RestrictRange;
   FileID MainFileID;
diff --git a/clang-tools-extra/clangd/unittests/InlayHintTests.cpp b/clang-tools-extra/clangd/unittests/InlayHintTests.cpp
index a429c089918794..7127f6cc54c539 100644
--- a/clang-tools-extra/clangd/unittests/InlayHintTests.cpp
+++ b/clang-tools-extra/clangd/unittests/InlayHintTests.cpp
@@ -820,6 +820,15 @@ TEST(ParameterHints, Macros) {
     }
   )cpp",
                        ExpectedHint{"param: ", "param"});
+
+  // If the macro expands to multiple arguments, don't hint it.
+  assertParameterHints(R"cpp(
+    void foo(double x, double y);
+    #define CONSTANTS 3.14, 2.72
+    void bar() {
+      foo(CONSTANTS);
+    }
+  )cpp");
 }
 
 TEST(ParameterHints, ConstructorParens) {

From 27e075fcfad137b43367734052c63abe12555403 Mon Sep 17 00:00:00 2001
From: Sam McCall <sam.mccall@gmail.com>
Date: Mon, 26 Sep 2022 03:22:09 +0200
Subject: [PATCH 06/84] [Syntax] Fix macro-arg handling in
 TokenBuffer::spelledForExpanded

A few cases were not handled correctly. Notably:
  #define ID(X) X
  #define HIDE a ID(b)
  HIDE
spelledForExpanded() would claim HIDE is an equivalent range of the 'b' it
contains, despite the fact that HIDE also covers 'a'.

While trying to fix this bug, I found findCommonRangeForMacroArgs hard
to understand (both the implementation and how it's used in spelledForExpanded).
It relies on details of the SourceLocation graph that are IMO fairly obscure.
So I've added/revised quite a lot of comments and made some naming tweaks.

Fixes https://github.com/clangd/clangd/issues/1289

Differential Revision: https://reviews.llvm.org/D134618

(cherry picked from commit 67268ee11c220b1dfdf84afb10a12371c5ae6400)
---
 clang/lib/Tooling/Syntax/Tokens.cpp           | 218 +++++++++++++-----
 clang/unittests/Tooling/Syntax/TokensTest.cpp |  56 +++++
 2 files changed, 211 insertions(+), 63 deletions(-)

diff --git a/clang/lib/Tooling/Syntax/Tokens.cpp b/clang/lib/Tooling/Syntax/Tokens.cpp
index e2014f965c9004..9a30e3692ee548 100644
--- a/clang/lib/Tooling/Syntax/Tokens.cpp
+++ b/clang/lib/Tooling/Syntax/Tokens.cpp
@@ -55,45 +55,140 @@ getTokensCovering(llvm::ArrayRef<syntax::Token> Toks, SourceRange R,
   return {Begin, End};
 }
 
-// Finds the smallest expansion range that contains expanded tokens First and
-// Last, e.g.:
+// Finds the range within FID corresponding to expanded tokens [First, Last].
+// Prev precedes First and Next follows Last, these must *not* be included.
+// If no range satisfies the criteria, returns an invalid range.
+//
 // #define ID(x) x
 // ID(ID(ID(a1) a2))
 //          ~~       -> a1
 //              ~~   -> a2
 //       ~~~~~~~~~   -> a1 a2
-SourceRange findCommonRangeForMacroArgs(const syntax::Token &First,
-                                        const syntax::Token &Last,
-                                        const SourceManager &SM) {
-  SourceRange Res;
-  auto FirstLoc = First.location(), LastLoc = Last.location();
-  // Keep traversing up the spelling chain as longs as tokens are part of the
-  // same expansion.
-  while (!FirstLoc.isFileID() && !LastLoc.isFileID()) {
-    auto ExpInfoFirst = SM.getSLocEntry(SM.getFileID(FirstLoc)).getExpansion();
-    auto ExpInfoLast = SM.getSLocEntry(SM.getFileID(LastLoc)).getExpansion();
-    // Stop if expansions have diverged.
-    if (ExpInfoFirst.getExpansionLocStart() !=
-        ExpInfoLast.getExpansionLocStart())
+SourceRange spelledForExpandedSlow(SourceLocation First, SourceLocation Last,
+                                   SourceLocation Prev, SourceLocation Next,
+                                   FileID TargetFile,
+                                   const SourceManager &SM) {
+  // There are two main parts to this algorithm:
+  //  - identifying which spelled range covers the expanded tokens
+  //  - validating that this range doesn't cover any extra tokens (First/Last)
+  //
+  // We do these in order. However as we transform the expanded range into the
+  // spelled one, we adjust First/Last so the validation remains simple.
+
+  assert(SM.getSLocEntry(TargetFile).isFile());
+  // In most cases, to select First and Last we must return their expansion
+  // range, i.e. the whole of any macros they are included in.
+  //
+  // When First and Last are part of the *same macro arg* of a macro written
+  // in TargetFile, we that slice of the arg, i.e. their spelling range.
+  //
+  // Unwrap such macro calls. If the target file has A(B(C)), the
+  // SourceLocation stack of a token inside C shows us the expansion of A first,
+  // then B, then any macros inside C's body, then C itself.
+  // (This is the reverse of the order the PP applies the expansions in).
+  while (First.isMacroID() && Last.isMacroID()) {
+    auto DecFirst = SM.getDecomposedLoc(First);
+    auto DecLast = SM.getDecomposedLoc(Last);
+    auto &ExpFirst = SM.getSLocEntry(DecFirst.first).getExpansion();
+    auto &ExpLast = SM.getSLocEntry(DecLast.first).getExpansion();
+
+    if (!ExpFirst.isMacroArgExpansion() || !ExpLast.isMacroArgExpansion())
+      break;
+    // Locations are in the same macro arg if they expand to the same place.
+    // (They may still have different FileIDs - an arg can have >1 chunks!)
+    if (ExpFirst.getExpansionLocStart() != ExpLast.getExpansionLocStart())
       break;
-    // Do not continue into macro bodies.
-    if (!ExpInfoFirst.isMacroArgExpansion() ||
-        !ExpInfoLast.isMacroArgExpansion())
+    // Careful, given:
+    //   #define HIDE ID(ID(a))
+    //   ID(ID(HIDE))
+    // The token `a` is wrapped in 4 arg-expansions, we only want to unwrap 2.
+    // We distinguish them by whether the macro expands into the target file.
+    // Fortunately, the target file ones will always appear first.
+    auto &ExpMacro =
+        SM.getSLocEntry(SM.getFileID(ExpFirst.getExpansionLocStart()))
+            .getExpansion();
+    if (ExpMacro.getExpansionLocStart().isMacroID())
       break;
-    FirstLoc = SM.getImmediateSpellingLoc(FirstLoc);
-    LastLoc = SM.getImmediateSpellingLoc(LastLoc);
-    // Update the result afterwards, as we want the tokens that triggered the
-    // expansion.
-    Res = {FirstLoc, LastLoc};
+    // Replace each endpoint with its spelling inside the macro arg.
+    // (This is getImmediateSpellingLoc without repeating lookups).
+    First = ExpFirst.getSpellingLoc().getLocWithOffset(DecFirst.second);
+    Last = ExpLast.getSpellingLoc().getLocWithOffset(DecLast.second);
+
+    // Now: how do we adjust the previous/next bounds? Three cases:
+    // A) If they are also part of the same macro arg, we translate them too.
+    //   This will ensure that we don't select any macros nested within the
+    //   macro arg that cover extra tokens. Critical case:
+    //      #define ID(X) X
+    //      ID(prev target) // selecting 'target' succeeds
+    //      #define LARGE ID(prev target)
+    //      LARGE // selecting 'target' fails.
+    // B) They are not in the macro at all, then their expansion range is a
+    //    sibling to it, and we can safely substitute that.
+    //      #define PREV prev
+    //      #define ID(X) X
+    //      PREV ID(target) // selecting 'target' succeeds.
+    //      #define LARGE PREV ID(target)
+    //      LARGE // selecting 'target' fails.
+    // C) They are in a different arg of this macro, or the macro body.
+    //    Now selecting the whole macro arg is fine, but the whole macro is not.
+    //    Model this by setting using the edge of the macro call as the bound.
+    //      #define ID2(X, Y) X Y
+    //      ID2(prev, target) // selecting 'target' succeeds
+    //      #define LARGE ID2(prev, target)
+    //      LARGE // selecting 'target' fails
+    auto AdjustBound = [&](SourceLocation &Bound) {
+      if (Bound.isInvalid() || !Bound.isMacroID()) // Non-macro must be case B.
+        return;
+      auto DecBound = SM.getDecomposedLoc(Bound);
+      auto &ExpBound = SM.getSLocEntry(DecBound.first).getExpansion();
+      if (ExpBound.isMacroArgExpansion() &&
+          ExpBound.getExpansionLocStart() == ExpFirst.getExpansionLocStart()) {
+        // Case A: translate to (spelling) loc within the macro arg.
+        Bound = ExpBound.getSpellingLoc().getLocWithOffset(DecBound.second);
+        return;
+      }
+      while (Bound.isMacroID()) {
+        SourceRange Exp = SM.getImmediateExpansionRange(Bound).getAsRange();
+        if (Exp.getBegin() == ExpMacro.getExpansionLocStart()) {
+          // Case B: bounds become the macro call itself.
+          Bound = (&Bound == &Prev) ? Exp.getBegin() : Exp.getEnd();
+          return;
+        }
+        // Either case C, or expansion location will later find case B.
+        // We choose the upper bound for Prev and the lower one for Next:
+        //   ID(prev) target ID(next)
+        //          ^        ^
+        //      new-prev  new-next
+        Bound = (&Bound == &Prev) ? Exp.getEnd() : Exp.getBegin();
+      }
+    };
+    AdjustBound(Prev);
+    AdjustBound(Next);
   }
-  // Normally mapping back to expansion location here only changes FileID, as
-  // we've already found some tokens expanded from the same macro argument, and
-  // they should map to a consecutive subset of spelled tokens. Unfortunately
-  // SourceManager::isBeforeInTranslationUnit discriminates sourcelocations
-  // based on their FileID in addition to offsets. So even though we are
-  // referring to same tokens, SourceManager might tell us that one is before
-  // the other if they've got different FileIDs.
-  return SM.getExpansionRange(CharSourceRange(Res, true)).getAsRange();
+
+  // In all remaining cases we need the full containing macros.
+  // If this overlaps Prev or Next, then no range is possible.
+  SourceRange Candidate =
+      SM.getExpansionRange(SourceRange(First, Last)).getAsRange();
+  auto DecFirst = SM.getDecomposedExpansionLoc(Candidate.getBegin());
+  auto DecLast = SM.getDecomposedLoc(Candidate.getEnd());
+  // Can end up in the wrong file due to bad input or token-pasting shenanigans.
+  if (Candidate.isInvalid() || DecFirst.first != TargetFile || DecLast.first != TargetFile)
+    return SourceRange();
+  // Check bounds, which may still be inside macros.
+  if (Prev.isValid()) {
+    auto Dec = SM.getDecomposedLoc(SM.getExpansionRange(Prev).getBegin());
+    if (Dec.first != DecFirst.first || Dec.second >= DecFirst.second)
+      return SourceRange();
+  }
+  if (Next.isValid()) {
+    auto Dec = SM.getDecomposedLoc(SM.getExpansionRange(Next).getEnd());
+    if (Dec.first != DecLast.first || Dec.second <= DecLast.second)
+      return SourceRange();
+  }
+  // Now we know that Candidate is a file range that covers [First, Last]
+  // without encroaching on {Prev, Next}. Ship it!
+  return Candidate;
 }
 
 } // namespace
@@ -363,51 +458,48 @@ TokenBuffer::spelledForExpanded(llvm::ArrayRef<syntax::Token> Expanded) const {
   // of the range, bail out in that case.
   if (Expanded.empty())
     return llvm::None;
+  const syntax::Token *First = &Expanded.front();
+  const syntax::Token *Last = &Expanded.back();
+  auto [FirstSpelled, FirstMapping] = spelledForExpandedToken(First);
+  auto [LastSpelled, LastMapping] = spelledForExpandedToken(Last);
 
-  const syntax::Token *BeginSpelled;
-  const Mapping *BeginMapping;
-  std::tie(BeginSpelled, BeginMapping) =
-      spelledForExpandedToken(&Expanded.front());
-
-  const syntax::Token *LastSpelled;
-  const Mapping *LastMapping;
-  std::tie(LastSpelled, LastMapping) =
-      spelledForExpandedToken(&Expanded.back());
-
-  FileID FID = SourceMgr->getFileID(BeginSpelled->location());
+  FileID FID = SourceMgr->getFileID(FirstSpelled->location());
   // FIXME: Handle multi-file changes by trying to map onto a common root.
   if (FID != SourceMgr->getFileID(LastSpelled->location()))
     return llvm::None;
 
   const MarkedFile &File = Files.find(FID)->second;
 
-  // If both tokens are coming from a macro argument expansion, try and map to
-  // smallest part of the macro argument. BeginMapping && LastMapping check is
-  // only for performance, they are a prerequisite for Expanded.front() and
-  // Expanded.back() being part of a macro arg expansion.
-  if (BeginMapping && LastMapping &&
-      SourceMgr->isMacroArgExpansion(Expanded.front().location()) &&
-      SourceMgr->isMacroArgExpansion(Expanded.back().location())) {
-    auto CommonRange = findCommonRangeForMacroArgs(Expanded.front(),
-                                                   Expanded.back(), *SourceMgr);
-    // It might be the case that tokens are arguments of different macro calls,
-    // in that case we should continue with the logic below instead of returning
-    // an empty range.
-    if (CommonRange.isValid())
-      return getTokensCovering(File.SpelledTokens, CommonRange, *SourceMgr);
+  // If the range is within one macro argument, the result may be only part of a
+  // Mapping. We must use the general (SourceManager-based) algorithm.
+  if (FirstMapping && FirstMapping == LastMapping &&
+      SourceMgr->isMacroArgExpansion(First->location()) &&
+      SourceMgr->isMacroArgExpansion(Last->location())) {
+    // We use excluded Prev/Next token for bounds checking.
+    SourceLocation Prev = (First == &ExpandedTokens.front())
+                              ? SourceLocation()
+                              : (First - 1)->location();
+    SourceLocation Next = (Last == &ExpandedTokens.back())
+                              ? SourceLocation()
+                              : (Last + 1)->location();
+    SourceRange Range = spelledForExpandedSlow(
+        First->location(), Last->location(), Prev, Next, FID, *SourceMgr);
+    if (Range.isInvalid())
+      return llvm::None;
+    return getTokensCovering(File.SpelledTokens, Range, *SourceMgr);
   }
 
+  // Otherwise, use the fast version based on Mappings.
   // Do not allow changes that doesn't cover full expansion.
-  unsigned BeginExpanded = Expanded.begin() - ExpandedTokens.data();
-  unsigned EndExpanded = Expanded.end() - ExpandedTokens.data();
-  if (BeginMapping && BeginExpanded != BeginMapping->BeginExpanded)
+  unsigned FirstExpanded = Expanded.begin() - ExpandedTokens.data();
+  unsigned LastExpanded = Expanded.end() - ExpandedTokens.data();
+  if (FirstMapping && FirstExpanded != FirstMapping->BeginExpanded)
     return llvm::None;
-  if (LastMapping && LastMapping->EndExpanded != EndExpanded)
+  if (LastMapping && LastMapping->EndExpanded != LastExpanded)
     return llvm::None;
-  // All is good, return the result.
   return llvm::makeArrayRef(
-      BeginMapping ? File.SpelledTokens.data() + BeginMapping->BeginSpelled
-                   : BeginSpelled,
+      FirstMapping ? File.SpelledTokens.data() + FirstMapping->BeginSpelled
+                   : FirstSpelled,
       LastMapping ? File.SpelledTokens.data() + LastMapping->EndSpelled
                   : LastSpelled + 1);
 }
diff --git a/clang/unittests/Tooling/Syntax/TokensTest.cpp b/clang/unittests/Tooling/Syntax/TokensTest.cpp
index 77f719ce28cd07..85fc837fbe2be8 100644
--- a/clang/unittests/Tooling/Syntax/TokensTest.cpp
+++ b/clang/unittests/Tooling/Syntax/TokensTest.cpp
@@ -743,6 +743,62 @@ TEST_F(TokenBufferTest, SpelledByExpanded) {
               ValueIs(SameRange(findSpelled("ID2 ( a4 , a5 a6 a7 )"))));
   // Should fail, spans multiple invocations.
   EXPECT_EQ(Buffer.spelledForExpanded(findExpanded("a1 a2 a3 a4")), llvm::None);
+
+  // https://github.com/clangd/clangd/issues/1289
+  recordTokens(R"cpp(
+    #define FOO(X) foo(X)
+    #define INDIRECT FOO(y)
+    INDIRECT // expands to foo(y)
+  )cpp");
+  EXPECT_EQ(Buffer.spelledForExpanded(findExpanded("y")), llvm::None);
+
+  recordTokens(R"cpp(
+    #define FOO(X) a X b
+    FOO(y)
+  )cpp");
+  EXPECT_THAT(Buffer.spelledForExpanded(findExpanded("y")),
+              ValueIs(SameRange(findSpelled("y"))));
+
+  recordTokens(R"cpp(
+    #define ID(X) X
+    #define BAR ID(1)
+    BAR
+  )cpp");
+  EXPECT_THAT(Buffer.spelledForExpanded(findExpanded("1")),
+              ValueIs(SameRange(findSpelled(") BAR").drop_front())));
+
+  // Critical cases for mapping of Prev/Next in spelledForExpandedSlow.
+  recordTokens(R"cpp(
+    #define ID(X) X
+    ID(prev ID(good))
+    #define LARGE ID(prev ID(bad))
+    LARGE
+  )cpp");
+  EXPECT_THAT(Buffer.spelledForExpanded(findExpanded("good")),
+              ValueIs(SameRange(findSpelled("good"))));
+  EXPECT_EQ(Buffer.spelledForExpanded(findExpanded("bad")), llvm::None);
+
+  recordTokens(R"cpp(
+    #define PREV prev
+    #define ID(X) X
+    PREV ID(good)
+    #define LARGE PREV ID(bad)
+    LARGE
+  )cpp");
+  EXPECT_THAT(Buffer.spelledForExpanded(findExpanded("good")),
+            ValueIs(SameRange(findSpelled("good"))));
+  EXPECT_EQ(Buffer.spelledForExpanded(findExpanded("bad")), llvm::None);
+
+  recordTokens(R"cpp(
+    #define ID(X) X
+    #define ID2(X, Y) X Y
+    ID2(prev, ID(good))
+    #define LARGE ID2(prev, bad)
+    LARGE
+  )cpp");
+  EXPECT_THAT(Buffer.spelledForExpanded(findExpanded("good")),
+            ValueIs(SameRange(findSpelled("good"))));
+  EXPECT_EQ(Buffer.spelledForExpanded(findExpanded("bad")), llvm::None);
 }
 
 TEST_F(TokenBufferTest, ExpandedTokensForRange) {

From fc47af8c914012789db554ecb24e8344a4709ebf Mon Sep 17 00:00:00 2001
From: Tobias Hieta <tobias@hieta.se>
Date: Mon, 10 Oct 2022 08:53:34 +0200
Subject: [PATCH 07/84] Bump version to 15.0.3

---
 libcxx/include/__config                                     | 2 +-
 llvm/CMakeLists.txt                                         | 2 +-
 llvm/utils/gn/secondary/llvm/version.gni                    | 2 +-
 llvm/utils/lit/lit/__init__.py                              | 2 +-
 utils/bazel/llvm-project-overlay/clang/BUILD.bazel          | 6 +++---
 .../clang/include/clang/Config/config.h                     | 2 +-
 utils/bazel/llvm-project-overlay/lld/BUILD.bazel            | 2 +-
 .../llvm/include/llvm/Config/llvm-config.h                  | 4 ++--
 8 files changed, 11 insertions(+), 11 deletions(-)

diff --git a/libcxx/include/__config b/libcxx/include/__config
index 01377a9617ea41..589b5c3b2241e0 100644
--- a/libcxx/include/__config
+++ b/libcxx/include/__config
@@ -36,7 +36,7 @@
 
 #ifdef __cplusplus
 
-#  define _LIBCPP_VERSION 15002
+#  define _LIBCPP_VERSION 15003
 
 #  define _LIBCPP_CONCAT_IMPL(_X, _Y) _X##_Y
 #  define _LIBCPP_CONCAT(_X, _Y) _LIBCPP_CONCAT_IMPL(_X, _Y)
diff --git a/llvm/CMakeLists.txt b/llvm/CMakeLists.txt
index fddb8ffd0c169a..1a45f2eff0130f 100644
--- a/llvm/CMakeLists.txt
+++ b/llvm/CMakeLists.txt
@@ -22,7 +22,7 @@ if(NOT DEFINED LLVM_VERSION_MINOR)
   set(LLVM_VERSION_MINOR 0)
 endif()
 if(NOT DEFINED LLVM_VERSION_PATCH)
-  set(LLVM_VERSION_PATCH 2)
+  set(LLVM_VERSION_PATCH 3)
 endif()
 if(NOT DEFINED LLVM_VERSION_SUFFIX)
   set(LLVM_VERSION_SUFFIX)
diff --git a/llvm/utils/gn/secondary/llvm/version.gni b/llvm/utils/gn/secondary/llvm/version.gni
index ac79ba5bbc7746..6d64da0180dff7 100644
--- a/llvm/utils/gn/secondary/llvm/version.gni
+++ b/llvm/utils/gn/secondary/llvm/version.gni
@@ -1,4 +1,4 @@
 llvm_version_major = 15
 llvm_version_minor = 0
-llvm_version_patch = 2
+llvm_version_patch = 3
 llvm_version = "$llvm_version_major.$llvm_version_minor.$llvm_version_patch"
diff --git a/llvm/utils/lit/lit/__init__.py b/llvm/utils/lit/lit/__init__.py
index 2ee97f578f04a4..5cb7ccdc67dabb 100644
--- a/llvm/utils/lit/lit/__init__.py
+++ b/llvm/utils/lit/lit/__init__.py
@@ -2,7 +2,7 @@
 
 __author__ = 'Daniel Dunbar'
 __email__ = 'daniel@minormatter.com'
-__versioninfo__ = (15, 0, 2)
+__versioninfo__ = (15, 0, 3)
 __version__ = '.'.join(str(v) for v in __versioninfo__) + 'dev'
 
 __all__ = []
diff --git a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
index fe5223d3195a06..6cb8889bf50ff5 100644
--- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
@@ -358,11 +358,11 @@ genrule(
     name = "basic_version_gen",
     outs = ["include/clang/Basic/Version.inc"],
     cmd = (
-        "echo '#define CLANG_VERSION 15.0.2' >> $@\n" +
+        "echo '#define CLANG_VERSION 15.0.3' >> $@\n" +
         "echo '#define CLANG_VERSION_MAJOR 15' >> $@\n" +
         "echo '#define CLANG_VERSION_MINOR 0' >> $@\n" +
-        "echo '#define CLANG_VERSION_PATCHLEVEL 2' >> $@\n" +
-        "echo '#define CLANG_VERSION_STRING \"15.0.2\"' >> $@\n"
+        "echo '#define CLANG_VERSION_PATCHLEVEL 3' >> $@\n" +
+        "echo '#define CLANG_VERSION_STRING \"15.0.3\"' >> $@\n"
     ),
 )
 
diff --git a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
index a3fefb8fb2bc54..cedeb0a2c9511a 100644
--- a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
+++ b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
@@ -93,7 +93,7 @@
 /* CLANG_HAVE_RLIMITS defined conditionally below */
 
 /* The LLVM product name and version */
-#define BACKEND_PACKAGE_STRING "LLVM 15.0.2"
+#define BACKEND_PACKAGE_STRING "LLVM 15.0.3"
 
 /* Linker version detected at compile time. */
 /* #undef HOST_LINK_VERSION */
diff --git a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
index db46efe289e28f..139298d1533f32 100644
--- a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
@@ -13,7 +13,7 @@ package(
 genrule(
     name = "config_version_gen",
     outs = ["include/lld/Common/Version.inc"],
-    cmd = "echo '#define LLD_VERSION_STRING \"15.0.2\"' > $@",
+    cmd = "echo '#define LLD_VERSION_STRING \"15.0.3\"' > $@",
 )
 
 genrule(
diff --git a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
index 66f8eecc5ff044..37bb4cf22a8903 100644
--- a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
+++ b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
@@ -80,10 +80,10 @@
 #define LLVM_VERSION_MINOR 0
 
 /* Patch version of the LLVM API */
-#define LLVM_VERSION_PATCH 2
+#define LLVM_VERSION_PATCH 3
 
 /* LLVM version string */
-#define LLVM_VERSION_STRING "15.0.2"
+#define LLVM_VERSION_STRING "15.0.3"
 
 /* Whether LLVM records statistics for use with GetStatistics(),
  * PrintStatistics() or PrintStatisticsJSON()

From 02129eab7d58362ad5d187c73aff255710578e75 Mon Sep 17 00:00:00 2001
From: Sam McCall <sam.mccall@gmail.com>
Date: Mon, 10 Oct 2022 17:08:10 +0200
Subject: [PATCH 08/84] [Syntax] avoid using c++17 features on 15.x branch

---
 clang/lib/Tooling/Syntax/Tokens.cpp | 6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)

diff --git a/clang/lib/Tooling/Syntax/Tokens.cpp b/clang/lib/Tooling/Syntax/Tokens.cpp
index 9a30e3692ee548..1fa73c667b7f22 100644
--- a/clang/lib/Tooling/Syntax/Tokens.cpp
+++ b/clang/lib/Tooling/Syntax/Tokens.cpp
@@ -460,8 +460,10 @@ TokenBuffer::spelledForExpanded(llvm::ArrayRef<syntax::Token> Expanded) const {
     return llvm::None;
   const syntax::Token *First = &Expanded.front();
   const syntax::Token *Last = &Expanded.back();
-  auto [FirstSpelled, FirstMapping] = spelledForExpandedToken(First);
-  auto [LastSpelled, LastMapping] = spelledForExpandedToken(Last);
+  const syntax::Token *FirstSpelled, *LastSpelled;
+  const TokenBuffer::Mapping *FirstMapping, *LastMapping;
+  std::tie(FirstSpelled, FirstMapping) = spelledForExpandedToken(First);
+  std::tie(LastSpelled, LastMapping) = spelledForExpandedToken(Last);
 
   FileID FID = SourceMgr->getFileID(FirstSpelled->location());
   // FIXME: Handle multi-file changes by trying to map onto a common root.

From 6599b6e5ae9ea95c857aff33b65f5e25e0bf8c27 Mon Sep 17 00:00:00 2001
From: David Spickett <david.spickett@linaro.org>
Date: Wed, 5 Oct 2022 07:31:03 +0000
Subject: [PATCH 09/84] Fix LLDB build on old Linux kernels (pre-4.1)

These fields are guarded elsewhere, but were missing here.

Reviewed By: wallace

Differential Revision: https://reviews.llvm.org/D133778

(chery picked from a9ffb473453519bae158e5d9c72431aa0f6aac2b)
---
 lldb/source/Plugins/Process/Linux/Perf.cpp | 31 ++++++++++++++++++++--
 1 file changed, 29 insertions(+), 2 deletions(-)

diff --git a/lldb/source/Plugins/Process/Linux/Perf.cpp b/lldb/source/Plugins/Process/Linux/Perf.cpp
index fa4e8fb42e6cd9..c0a879555365af 100644
--- a/lldb/source/Plugins/Process/Linux/Perf.cpp
+++ b/lldb/source/Plugins/Process/Linux/Perf.cpp
@@ -127,6 +127,10 @@ llvm::Error PerfEvent::MmapMetadataAndDataBuffer(size_t num_data_pages,
 }
 
 llvm::Error PerfEvent::MmapAuxBuffer(size_t num_aux_pages) {
+#ifndef PERF_ATTR_SIZE_VER5
+  return createStringError(inconvertibleErrorCode(),
+                           "Intel PT Linux perf event not supported");
+#else
   if (num_aux_pages == 0)
     return Error::success();
 
@@ -143,6 +147,7 @@ llvm::Error PerfEvent::MmapAuxBuffer(size_t num_aux_pages) {
     return Error::success();
   } else
     return mmap_aux.takeError();
+#endif
 }
 
 llvm::Error PerfEvent::MmapMetadataAndBuffers(size_t num_data_pages,
@@ -172,16 +177,24 @@ perf_event_mmap_page &PerfEvent::GetMetadataPage() const {
 }
 
 ArrayRef<uint8_t> PerfEvent::GetDataBuffer() const {
+#ifndef PERF_ATTR_SIZE_VER5
+  llvm_unreachable("Intel PT Linux perf event not supported");
+#else
   perf_event_mmap_page &mmap_metadata = GetMetadataPage();
   return {reinterpret_cast<uint8_t *>(m_metadata_data_base.get()) +
               mmap_metadata.data_offset,
-           static_cast<size_t>(mmap_metadata.data_size)};
+          static_cast<size_t>(mmap_metadata.data_size)};
+#endif
 }
 
 ArrayRef<uint8_t> PerfEvent::GetAuxBuffer() const {
+#ifndef PERF_ATTR_SIZE_VER5
+  llvm_unreachable("Intel PT Linux perf event not supported");
+#else
   perf_event_mmap_page &mmap_metadata = GetMetadataPage();
   return {reinterpret_cast<uint8_t *>(m_aux_base.get()),
-           static_cast<size_t>(mmap_metadata.aux_size)};
+          static_cast<size_t>(mmap_metadata.aux_size)};
+#endif
 }
 
 Expected<std::vector<uint8_t>> PerfEvent::GetReadOnlyDataBuffer() {
@@ -190,6 +203,10 @@ Expected<std::vector<uint8_t>> PerfEvent::GetReadOnlyDataBuffer() {
   // this piece of code updates some pointers. See more about data_tail
   // in https://man7.org/linux/man-pages/man2/perf_event_open.2.html.
 
+#ifndef PERF_ATTR_SIZE_VER5
+  return createStringError(inconvertibleErrorCode(),
+                           "Intel PT Linux perf event not supported");
+#else
   bool was_enabled = m_enabled;
   if (Error err = DisableWithIoctl())
     return std::move(err);
@@ -226,6 +243,7 @@ Expected<std::vector<uint8_t>> PerfEvent::GetReadOnlyDataBuffer() {
   }
 
   return output;
+#endif
 }
 
 Expected<std::vector<uint8_t>> PerfEvent::GetReadOnlyAuxBuffer() {
@@ -234,6 +252,10 @@ Expected<std::vector<uint8_t>> PerfEvent::GetReadOnlyAuxBuffer() {
   // this piece of code updates some pointers. See more about aux_tail
   // in https://man7.org/linux/man-pages/man2/perf_event_open.2.html.
 
+#ifndef PERF_ATTR_SIZE_VER5
+  return createStringError(inconvertibleErrorCode(),
+                           "Intel PT Linux perf event not supported");
+#else
   bool was_enabled = m_enabled;
   if (Error err = DisableWithIoctl())
     return std::move(err);
@@ -266,6 +288,7 @@ Expected<std::vector<uint8_t>> PerfEvent::GetReadOnlyAuxBuffer() {
   }
 
   return output;
+#endif
 }
 
 Error PerfEvent::DisableWithIoctl() {
@@ -297,11 +320,15 @@ Error PerfEvent::EnableWithIoctl() {
 }
 
 size_t PerfEvent::GetEffectiveDataBufferSize() const {
+#ifndef PERF_ATTR_SIZE_VER5
+  llvm_unreachable("Intel PT Linux perf event not supported");
+#else
   perf_event_mmap_page &mmap_metadata = GetMetadataPage();
   if (mmap_metadata.data_head < mmap_metadata.data_size)
     return mmap_metadata.data_head;
   else
     return mmap_metadata.data_size; // The buffer has wrapped.
+#endif
 }
 
 Expected<PerfEvent>

From f3c5289e78462fb96015f79c954d95a0d527ba55 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Martin=20Storsj=C3=B6?= <martin@martin.st>
Date: Wed, 5 Oct 2022 14:44:21 +0300
Subject: [PATCH 10/84] Revert "Recommit "[SCEV] Look through single value
 PHIs." (take 3)"

This reverts commit 20d798bd47ec5191de1b2a8a031da06a04e612e1.

This commit caused crashes in some cases, see github issue #58152.
This is fixed on main, but backporting it requires multiple
nontrivial cherrypicks.

Updating llvm/test/Transforms/LoopVectorize/create-induction-resume.ll
with update_test_checks.py, so this isn't an exact automatic revert,
as that test case was added after the reverted commit.

This fixes #58152 for the release branch.
---
 llvm/lib/Analysis/ScalarEvolution.cpp         |  7 ++-
 .../test/Analysis/DependenceAnalysis/lcssa.ll |  2 +-
 .../Analysis/ScalarEvolution/cycled_phis.ll   |  4 +-
 .../ScalarEvolution/incorrect-exit-count.ll   |  2 +-
 .../ScalarEvolution/solve-quadratic-i1.ll     |  4 +-
 .../solve-quadratic-overflow.ll               |  6 +-
 .../Analysis/ScalarEvolution/trivial-phis.ll  |  2 +-
 .../Transforms/LoopStrengthReduce/funclet.ll  | 40 ++++++++------
 .../LoopVectorize/create-induction-resume.ll  | 24 +++-----
 llvm/test/Transforms/LoopVectorize/pr45259.ll | 55 +++++++++----------
 10 files changed, 75 insertions(+), 71 deletions(-)

diff --git a/llvm/lib/Analysis/ScalarEvolution.cpp b/llvm/lib/Analysis/ScalarEvolution.cpp
index 2958a5054afc7a..c784c27d36b42d 100644
--- a/llvm/lib/Analysis/ScalarEvolution.cpp
+++ b/llvm/lib/Analysis/ScalarEvolution.cpp
@@ -5917,8 +5917,13 @@ const SCEV *ScalarEvolution::createNodeForPHI(PHINode *PN) {
   if (const SCEV *S = createNodeFromSelectLikePHI(PN))
     return S;
 
+  // If the PHI has a single incoming value, follow that value, unless the
+  // PHI's incoming blocks are in a different loop, in which case doing so
+  // risks breaking LCSSA form. Instcombine would normally zap these, but
+  // it doesn't have DominatorTree information, so it may miss cases.
   if (Value *V = simplifyInstruction(PN, {getDataLayout(), &TLI, &DT, &AC}))
-    return getSCEV(V);
+    if (LI.replacementPreservesLCSSAForm(PN, V))
+      return getSCEV(V);
 
   // If it's not a loop phi, we can't handle it yet.
   return getUnknown(PN);
diff --git a/llvm/test/Analysis/DependenceAnalysis/lcssa.ll b/llvm/test/Analysis/DependenceAnalysis/lcssa.ll
index 801b24276f5b55..2bd20f39f4a7e6 100644
--- a/llvm/test/Analysis/DependenceAnalysis/lcssa.ll
+++ b/llvm/test/Analysis/DependenceAnalysis/lcssa.ll
@@ -2,7 +2,7 @@
 ; RUN: "-aa-pipeline=basic-aa,tbaa" 2>&1 | FileCheck %s
 
 ; CHECK:      Src:  %v = load i32, i32* %arrayidx1, align 4 --> Dst:  store i32 %add, i32* %a.lcssa, align 4
-; CHECK-NEXT: da analyze - anti [*|<]!
+; CHECK-NEXT: da analyze - confused!
 
 define void @f(i32 *%a, i32 %n, i64 %n2) {
 entry:
diff --git a/llvm/test/Analysis/ScalarEvolution/cycled_phis.ll b/llvm/test/Analysis/ScalarEvolution/cycled_phis.ll
index 80cf153c913bba..7183bb8c0a634d 100644
--- a/llvm/test/Analysis/ScalarEvolution/cycled_phis.ll
+++ b/llvm/test/Analysis/ScalarEvolution/cycled_phis.ll
@@ -46,7 +46,7 @@ define void @test_02(i32* %p, i32* %q) {
 ; CHECK-NEXT:    %inner_cond = call i1 @cond()
 ; CHECK-NEXT:    --> %inner_cond U: full-set S: full-set Exits: <<Unknown>> LoopDispositions: { %inner_loop: Variant, %outer_loop: Variant }
 ; CHECK-NEXT:    %inner_lcssa = phi i32 [ %inner_phi, %inner_loop ]
-; CHECK-NEXT:    --> %inner_phi U: full-set S: full-set Exits: <<Unknown>> LoopDispositions: { %outer_loop: Variant, %inner_loop: Variant }
+; CHECK-NEXT:    --> %inner_lcssa U: full-set S: full-set Exits: <<Unknown>> LoopDispositions: { %outer_loop: Variant, %inner_loop: Invariant }
 ; CHECK-NEXT:    %outer_cond = call i1 @cond()
 ; CHECK-NEXT:    --> %outer_cond U: full-set S: full-set Exits: <<Unknown>> LoopDispositions: { %outer_loop: Variant, %inner_loop: Invariant }
 ; CHECK-NEXT:  Determining loop execution counts for: @test_02
@@ -97,7 +97,7 @@ define void @test_03(i32* %p, i32* %q) {
 ; CHECK-NEXT:    %inner_cond = call i1 @cond()
 ; CHECK-NEXT:    --> %inner_cond U: full-set S: full-set Exits: <<Unknown>> LoopDispositions: { %inner_loop: Variant, %outer_loop: Variant }
 ; CHECK-NEXT:    %inner_lcssa = phi i32 [ %inner_phi_1, %inner_loop ]
-; CHECK-NEXT:    --> %inner_phi_1 U: full-set S: full-set Exits: <<Unknown>> LoopDispositions: { %outer_loop: Variant, %inner_loop: Variant }
+; CHECK-NEXT:    --> %inner_lcssa U: full-set S: full-set Exits: <<Unknown>> LoopDispositions: { %outer_loop: Variant, %inner_loop: Invariant }
 ; CHECK-NEXT:    %outer_cond = call i1 @cond()
 ; CHECK-NEXT:    --> %outer_cond U: full-set S: full-set Exits: <<Unknown>> LoopDispositions: { %outer_loop: Variant, %inner_loop: Invariant }
 ; CHECK-NEXT:  Determining loop execution counts for: @test_03
diff --git a/llvm/test/Analysis/ScalarEvolution/incorrect-exit-count.ll b/llvm/test/Analysis/ScalarEvolution/incorrect-exit-count.ll
index daf12d0dc710c5..11a053f5e5fc3e 100644
--- a/llvm/test/Analysis/ScalarEvolution/incorrect-exit-count.ll
+++ b/llvm/test/Analysis/ScalarEvolution/incorrect-exit-count.ll
@@ -53,7 +53,7 @@ define dso_local i32 @f() {
 ; CHECK-NEXT:    %dec.3 = add nsw i32 %storemerge1921.3, -1
 ; CHECK-NEXT:    --> {2,+,-1}<nsw><%inner.loop> U: [2,3) S: [2,3) Exits: <<Unknown>> LoopDispositions: { %inner.loop: Computable, %outer.loop: Variant }
 ; CHECK-NEXT:    %storemerge1921.lcssa25.3 = phi i32 [ %storemerge1921.3, %for.end.3 ]
-; CHECK-NEXT:    --> {3,+,-1}<nuw><nsw><%inner.loop> U: [3,4) S: [3,4) Exits: <<Unknown>> LoopDispositions: { %outer.loop: Variant, %for.cond6: Variant, %inner.loop: Computable }
+; CHECK-NEXT:    --> %storemerge1921.lcssa25.3 U: [3,4) S: [3,4) Exits: <<Unknown>> LoopDispositions: { %outer.loop: Variant, %for.cond6: Invariant, %inner.loop: Invariant }
 ; CHECK-NEXT:    %dec16 = add nsw i32 %storemerge23, -1
 ; CHECK-NEXT:    --> {2,+,-1}<nsw><%outer.loop> U: [0,3) S: [0,3) Exits: <<Unknown>> LoopDispositions: { %outer.loop: Computable, %for.cond6: Invariant, %inner.loop: Invariant }
 ; CHECK-NEXT:  Determining loop execution counts for: @f
diff --git a/llvm/test/Analysis/ScalarEvolution/solve-quadratic-i1.ll b/llvm/test/Analysis/ScalarEvolution/solve-quadratic-i1.ll
index bc6f14135b1ad0..490ba57a92dfc2 100644
--- a/llvm/test/Analysis/ScalarEvolution/solve-quadratic-i1.ll
+++ b/llvm/test/Analysis/ScalarEvolution/solve-quadratic-i1.ll
@@ -59,9 +59,9 @@ define void @f1() #0 {
 ; CHECK-NEXT:    %v6 = add nuw nsw i32 %v1, 1
 ; CHECK-NEXT:    --> {4,+,1}<nuw><nsw><%b1> U: [4,7) S: [4,7) Exits: 6 LoopDispositions: { %b1: Computable }
 ; CHECK-NEXT:    %v7 = phi i32 [ %v1, %b1 ]
-; CHECK-NEXT:    --> {3,+,1}<nuw><nsw><%b1> U: [3,6) S: [3,6) --> 5 U: [5,6) S: [5,6)
+; CHECK-NEXT:    --> %v7 U: [3,6) S: [3,6) --> 5 U: [5,6) S: [5,6)
 ; CHECK-NEXT:    %v8 = phi i16 [ %v3, %b1 ]
-; CHECK-NEXT:    --> {3,+,4,+,1}<%b1> U: full-set S: full-set --> 12 U: [12,13) S: [12,13)
+; CHECK-NEXT:    --> %v8 U: full-set S: full-set --> 12 U: [12,13) S: [12,13)
 ; CHECK-NEXT:  Determining loop execution counts for: @f1
 ; CHECK-NEXT:  Loop %b3: <multiple exits> Unpredictable backedge-taken count.
 ; CHECK-NEXT:  Loop %b3: Unpredictable max backedge-taken count.
diff --git a/llvm/test/Analysis/ScalarEvolution/solve-quadratic-overflow.ll b/llvm/test/Analysis/ScalarEvolution/solve-quadratic-overflow.ll
index 10473e238583a1..519450720cded8 100644
--- a/llvm/test/Analysis/ScalarEvolution/solve-quadratic-overflow.ll
+++ b/llvm/test/Analysis/ScalarEvolution/solve-quadratic-overflow.ll
@@ -12,11 +12,11 @@
 ; CHECK-NEXT:   %v3 = mul i16 %v2, %v2
 ; CHECK-NEXT:   -->  {1,+,3,+,2}<%b1> U: full-set S: full-set         Exits: 0               LoopDispositions: { %b1: Computable }
 ; CHECK-NEXT:   %v5 = phi i16 [ %v2, %b1 ]
-; CHECK-NEXT:   -->  {-1,+,-1}<%b1> U: [-256,0) S: [-256,0)  -->  -256 U: [-256,-255) S: [-256,-255)
+; CHECK-NEXT:   -->  %v5 U: [-256,0) S: [-256,0)
 ; CHECK-NEXT:   %v6 = phi i16 [ %v3, %b1 ]
-; CHECK-NEXT:   -->  {1,+,3,+,2}<%b1> U: full-set S: full-set  -->  0 U: [0,1) S: [0,1)
+; CHECK-NEXT:   -->  %v6 U: full-set S: full-set
 ; CHECK-NEXT:   %v7 = sext i16 %v5 to i32
-; CHECK-NEXT:   -->  {-1,+,-1}<nsw><%b1> U: [-256,0) S: [-256,0)  -->  -256 U: [-256,-255) S: [-256,-255)
+; CHECK-NEXT:   -->  (sext i16 %v5 to i32) U: [-256,0) S: [-256,0)
 ; CHECK-NEXT: Determining loop execution counts for: @f0
 ; CHECK-NEXT: Loop %b1: backedge-taken count is 255
 ; CHECK-NEXT: Loop %b1: max backedge-taken count is 255
diff --git a/llvm/test/Analysis/ScalarEvolution/trivial-phis.ll b/llvm/test/Analysis/ScalarEvolution/trivial-phis.ll
index 45a567bfbe3c2e..b3192cbf16d224 100644
--- a/llvm/test/Analysis/ScalarEvolution/trivial-phis.ll
+++ b/llvm/test/Analysis/ScalarEvolution/trivial-phis.ll
@@ -2,7 +2,7 @@
 
 ; CHECK-LABEL: @test1
 ; CHECK:       %add.lcssa.wide = phi i64 [ %indvars.iv.next, %do.body ]
-; CHECK-NEXT:  -->  {1,+,1}<nuw><nsw><%do.body> U: [1,2147483648) S: [1,2147483648)
+; CHECK-NEXT:  -->  %add.lcssa.wide U: [1,2147483648) S: [1,2147483648)
 
 define i64 @test1(i32 signext %n, float* %A) {
 entry:
diff --git a/llvm/test/Transforms/LoopStrengthReduce/funclet.ll b/llvm/test/Transforms/LoopStrengthReduce/funclet.ll
index ca0a86635ec0c5..c6b2029fc18d76 100644
--- a/llvm/test/Transforms/LoopStrengthReduce/funclet.ll
+++ b/llvm/test/Transforms/LoopStrengthReduce/funclet.ll
@@ -15,21 +15,23 @@ define void @f() personality i32 (...)* @_except_handler3 {
 ; CHECK-NEXT:  entry:
 ; CHECK-NEXT:    br label [[THROW:%.*]]
 ; CHECK:       throw:
+; CHECK-NEXT:    [[TMP96:%.*]] = getelementptr inbounds i8, i8* undef, i32 1
 ; CHECK-NEXT:    invoke void @reserve()
 ; CHECK-NEXT:    to label [[THROW]] unwind label [[PAD:%.*]]
 ; CHECK:       pad:
+; CHECK-NEXT:    [[PHI2:%.*]] = phi i8* [ [[TMP96]], [[THROW]] ]
 ; CHECK-NEXT:    [[CS:%.*]] = catchswitch within none [label %unreachable] unwind label [[BLAH2:%.*]]
 ; CHECK:       unreachable:
 ; CHECK-NEXT:    [[TMP0:%.*]] = catchpad within [[CS]] []
 ; CHECK-NEXT:    unreachable
 ; CHECK:       blah2:
 ; CHECK-NEXT:    [[CLEANUPPADI4_I_I_I:%.*]] = cleanuppad within none []
+; CHECK-NEXT:    [[SCEVGEP:%.*]] = getelementptr i8, i8* [[PHI2]], i32 -1
 ; CHECK-NEXT:    br label [[LOOP_BODY:%.*]]
 ; CHECK:       loop_body:
-; CHECK-NEXT:    [[LSR_IV:%.*]] = phi i32 [ [[LSR_IV_NEXT:%.*]], [[ITER:%.*]] ], [ 0, [[BLAH2]] ]
-; CHECK-NEXT:    [[LSR_IV_NEXT]] = add nuw nsw i32 [[LSR_IV]], -1
-; CHECK-NEXT:    [[LSR_IV_NEXT1:%.*]] = inttoptr i32 [[LSR_IV_NEXT]] to i8*
-; CHECK-NEXT:    [[TMP100:%.*]] = icmp eq i8* [[LSR_IV_NEXT1]], null
+; CHECK-NEXT:    [[LSR_IV:%.*]] = phi i8* [ [[SCEVGEP1:%.*]], [[ITER:%.*]] ], [ [[SCEVGEP]], [[BLAH2]] ]
+; CHECK-NEXT:    [[SCEVGEP1]] = getelementptr i8, i8* [[LSR_IV]], i32 1
+; CHECK-NEXT:    [[TMP100:%.*]] = icmp eq i8* [[SCEVGEP1]], undef
 ; CHECK-NEXT:    br i1 [[TMP100]], label [[UNWIND_OUT:%.*]], label [[ITER]]
 ; CHECK:       iter:
 ; CHECK-NEXT:    br i1 true, label [[UNWIND_OUT]], label [[LOOP_BODY]]
@@ -74,25 +76,27 @@ define void @g() personality i32 (...)* @_except_handler3 {
 ; CHECK-NEXT:  entry:
 ; CHECK-NEXT:    br label [[THROW:%.*]]
 ; CHECK:       throw:
+; CHECK-NEXT:    [[TMP96:%.*]] = getelementptr inbounds i8, i8* undef, i32 1
 ; CHECK-NEXT:    invoke void @reserve()
 ; CHECK-NEXT:    to label [[THROW]] unwind label [[PAD:%.*]]
 ; CHECK:       pad:
+; CHECK-NEXT:    [[PHI2:%.*]] = phi i8* [ [[TMP96]], [[THROW]] ]
 ; CHECK-NEXT:    [[CS:%.*]] = catchswitch within none [label [[UNREACHABLE:%.*]], label %blah] unwind to caller
 ; CHECK:       unreachable:
 ; CHECK-NEXT:    [[TMP0:%.*]] = catchpad within [[CS]] []
 ; CHECK-NEXT:    unreachable
 ; CHECK:       blah:
 ; CHECK-NEXT:    [[CATCHPAD:%.*]] = catchpad within [[CS]] []
+; CHECK-NEXT:    [[SCEVGEP:%.*]] = getelementptr i8, i8* [[PHI2]], i32 -1
 ; CHECK-NEXT:    br label [[LOOP_BODY:%.*]]
 ; CHECK:       unwind_out:
 ; CHECK-NEXT:    catchret from [[CATCHPAD]] to label [[LEAVE:%.*]]
 ; CHECK:       leave:
 ; CHECK-NEXT:    ret void
 ; CHECK:       loop_body:
-; CHECK-NEXT:    [[LSR_IV:%.*]] = phi i32 [ [[LSR_IV_NEXT:%.*]], [[ITER:%.*]] ], [ 0, [[BLAH:%.*]] ]
-; CHECK-NEXT:    [[LSR_IV_NEXT]] = add nuw nsw i32 [[LSR_IV]], -1
-; CHECK-NEXT:    [[LSR_IV_NEXT1:%.*]] = inttoptr i32 [[LSR_IV_NEXT]] to i8*
-; CHECK-NEXT:    [[TMP100:%.*]] = icmp eq i8* [[LSR_IV_NEXT1]], null
+; CHECK-NEXT:    [[LSR_IV:%.*]] = phi i8* [ [[SCEVGEP1:%.*]], [[ITER:%.*]] ], [ [[SCEVGEP]], [[BLAH:%.*]] ]
+; CHECK-NEXT:    [[SCEVGEP1]] = getelementptr i8, i8* [[LSR_IV]], i32 1
+; CHECK-NEXT:    [[TMP100:%.*]] = icmp eq i8* [[SCEVGEP1]], undef
 ; CHECK-NEXT:    br i1 [[TMP100]], label [[UNWIND_OUT:%.*]], label [[ITER]]
 ; CHECK:       iter:
 ; CHECK-NEXT:    br i1 true, label [[UNWIND_OUT]], label [[LOOP_BODY]]
@@ -138,6 +142,7 @@ define void @h() personality i32 (...)* @_except_handler3 {
 ; CHECK-NEXT:  entry:
 ; CHECK-NEXT:    br label [[THROW:%.*]]
 ; CHECK:       throw:
+; CHECK-NEXT:    [[TMP96:%.*]] = getelementptr inbounds i8, i8* undef, i32 1
 ; CHECK-NEXT:    invoke void @reserve()
 ; CHECK-NEXT:    to label [[THROW]] unwind label [[PAD:%.*]]
 ; CHECK:       pad:
@@ -146,17 +151,18 @@ define void @h() personality i32 (...)* @_except_handler3 {
 ; CHECK-NEXT:    [[TMP0:%.*]] = catchpad within [[CS]] []
 ; CHECK-NEXT:    unreachable
 ; CHECK:       blug:
+; CHECK-NEXT:    [[PHI2:%.*]] = phi i8* [ [[TMP96]], [[PAD]] ]
 ; CHECK-NEXT:    [[CATCHPAD:%.*]] = catchpad within [[CS]] []
+; CHECK-NEXT:    [[SCEVGEP:%.*]] = getelementptr i8, i8* [[PHI2]], i32 -1
 ; CHECK-NEXT:    br label [[LOOP_BODY:%.*]]
 ; CHECK:       unwind_out:
 ; CHECK-NEXT:    catchret from [[CATCHPAD]] to label [[LEAVE:%.*]]
 ; CHECK:       leave:
 ; CHECK-NEXT:    ret void
 ; CHECK:       loop_body:
-; CHECK-NEXT:    [[LSR_IV:%.*]] = phi i32 [ [[LSR_IV_NEXT:%.*]], [[ITER:%.*]] ], [ 0, [[BLUG:%.*]] ]
-; CHECK-NEXT:    [[LSR_IV_NEXT]] = add nuw nsw i32 [[LSR_IV]], -1
-; CHECK-NEXT:    [[LSR_IV_NEXT1:%.*]] = inttoptr i32 [[LSR_IV_NEXT]] to i8*
-; CHECK-NEXT:    [[TMP100:%.*]] = icmp eq i8* [[LSR_IV_NEXT1]], null
+; CHECK-NEXT:    [[LSR_IV:%.*]] = phi i8* [ [[SCEVGEP1:%.*]], [[ITER:%.*]] ], [ [[SCEVGEP]], [[BLUG:%.*]] ]
+; CHECK-NEXT:    [[SCEVGEP1]] = getelementptr i8, i8* [[LSR_IV]], i32 1
+; CHECK-NEXT:    [[TMP100:%.*]] = icmp eq i8* [[SCEVGEP1]], undef
 ; CHECK-NEXT:    br i1 [[TMP100]], label [[UNWIND_OUT:%.*]], label [[ITER]]
 ; CHECK:       iter:
 ; CHECK-NEXT:    br i1 true, label [[UNWIND_OUT]], label [[LOOP_BODY]]
@@ -202,9 +208,11 @@ define void @i() personality i32 (...)* @_except_handler3 {
 ; CHECK-NEXT:  entry:
 ; CHECK-NEXT:    br label [[THROW:%.*]]
 ; CHECK:       throw:
+; CHECK-NEXT:    [[TMP96:%.*]] = getelementptr inbounds i8, i8* undef, i32 1
 ; CHECK-NEXT:    invoke void @reserve()
 ; CHECK-NEXT:    to label [[THROW]] unwind label [[CATCHPAD:%.*]]
 ; CHECK:       catchpad:
+; CHECK-NEXT:    [[PHI2:%.*]] = phi i8* [ [[TMP96]], [[THROW]] ]
 ; CHECK-NEXT:    [[CS:%.*]] = catchswitch within none [label %cp_body] unwind label [[CLEANUPPAD:%.*]]
 ; CHECK:       cp_body:
 ; CHECK-NEXT:    [[TMP0:%.*]] = catchpad within [[CS]] []
@@ -213,12 +221,12 @@ define void @i() personality i32 (...)* @_except_handler3 {
 ; CHECK-NEXT:    [[TMP1:%.*]] = cleanuppad within none []
 ; CHECK-NEXT:    br label [[LOOP_HEAD]]
 ; CHECK:       loop_head:
+; CHECK-NEXT:    [[SCEVGEP:%.*]] = getelementptr i8, i8* [[PHI2]], i32 -1
 ; CHECK-NEXT:    br label [[LOOP_BODY:%.*]]
 ; CHECK:       loop_body:
-; CHECK-NEXT:    [[LSR_IV:%.*]] = phi i32 [ [[LSR_IV_NEXT:%.*]], [[ITER:%.*]] ], [ 0, [[LOOP_HEAD]] ]
-; CHECK-NEXT:    [[LSR_IV_NEXT]] = add nuw nsw i32 [[LSR_IV]], -1
-; CHECK-NEXT:    [[LSR_IV_NEXT1:%.*]] = inttoptr i32 [[LSR_IV_NEXT]] to i8*
-; CHECK-NEXT:    [[TMP100:%.*]] = icmp eq i8* [[LSR_IV_NEXT1]], null
+; CHECK-NEXT:    [[LSR_IV:%.*]] = phi i8* [ [[SCEVGEP1:%.*]], [[ITER:%.*]] ], [ [[SCEVGEP]], [[LOOP_HEAD]] ]
+; CHECK-NEXT:    [[SCEVGEP1]] = getelementptr i8, i8* [[LSR_IV]], i32 1
+; CHECK-NEXT:    [[TMP100:%.*]] = icmp eq i8* [[SCEVGEP1]], undef
 ; CHECK-NEXT:    br i1 [[TMP100]], label [[UNWIND_OUT:%.*]], label [[ITER]]
 ; CHECK:       iter:
 ; CHECK-NEXT:    br i1 true, label [[UNWIND_OUT]], label [[LOOP_BODY]]
diff --git a/llvm/test/Transforms/LoopVectorize/create-induction-resume.ll b/llvm/test/Transforms/LoopVectorize/create-induction-resume.ll
index 6aec21ead0fd42..2e59e856d3ea65 100644
--- a/llvm/test/Transforms/LoopVectorize/create-induction-resume.ll
+++ b/llvm/test/Transforms/LoopVectorize/create-induction-resume.ll
@@ -9,29 +9,21 @@ target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16
 define void @test(i32 %arg, i32 %L1.limit, i32 %L2.switch, i1 %c) {
 ; CHECK-LABEL: @test(
 ; CHECK-NEXT:  L1.preheader:
-; CHECK-NEXT:    [[TMP0:%.*]] = sub i32 -1, [[ARG:%.*]]
 ; CHECK-NEXT:    br label [[L1_HEADER:%.*]]
 ; CHECK:       L1.header:
-; CHECK-NEXT:    [[INDUCTION_IV:%.*]] = phi i32 [ [[INDUCTION_IV_NEXT:%.*]], [[L1_BACKEDGE:%.*]] ], [ [[TMP0]], [[L1_PREHEADER:%.*]] ]
-; CHECK-NEXT:    [[INDVAR:%.*]] = phi i32 [ [[INDVAR_NEXT:%.*]], [[L1_BACKEDGE]] ], [ 0, [[L1_PREHEADER]] ]
-; CHECK-NEXT:    [[L1_SUM:%.*]] = phi i32 [ [[ARG]], [[L1_PREHEADER]] ], [ [[L1_SUM_NEXT:%.*]], [[L1_BACKEDGE]] ]
+; CHECK-NEXT:    [[L1_SUM:%.*]] = phi i32 [ [[ARG:%.*]], [[L1_PREHEADER:%.*]] ], [ [[L1_SUM_NEXT:%.*]], [[L1_BACKEDGE:%.*]] ]
 ; CHECK-NEXT:    [[L1_IV:%.*]] = phi i32 [ 1, [[L1_PREHEADER]] ], [ [[L1_IV_NEXT:%.*]], [[L1_BACKEDGE]] ]
-; CHECK-NEXT:    [[TMP1:%.*]] = mul nsw i32 [[INDVAR]], -1
-; CHECK-NEXT:    [[TMP2:%.*]] = add i32 [[TMP1]], -2
 ; CHECK-NEXT:    br i1 [[C:%.*]], label [[L1_BACKEDGE]], label [[L1_EARLY_EXIT:%.*]]
 ; CHECK:       L1.backedge:
 ; CHECK-NEXT:    [[L1_SUM_NEXT]] = add i32 [[L1_IV]], [[L1_SUM]]
 ; CHECK-NEXT:    [[L1_IV_NEXT]] = add nuw nsw i32 [[L1_IV]], 1
 ; CHECK-NEXT:    [[L1_EXIT_COND:%.*]] = icmp ult i32 [[L1_IV_NEXT]], [[L1_LIMIT:%.*]]
-; CHECK-NEXT:    [[INDVAR_NEXT]] = add i32 [[INDVAR]], 1
-; CHECK-NEXT:    [[INDUCTION_IV_NEXT]] = add i32 [[INDUCTION_IV]], [[TMP2]]
 ; CHECK-NEXT:    br i1 [[L1_EXIT_COND]], label [[L1_HEADER]], label [[L1_EXIT:%.*]]
 ; CHECK:       L1.early.exit:
 ; CHECK-NEXT:    ret void
 ; CHECK:       L1.exit:
-; CHECK-NEXT:    [[INDUCTION_IV_LCSSA3:%.*]] = phi i32 [ [[INDUCTION_IV]], [[L1_BACKEDGE]] ]
-; CHECK-NEXT:    [[INDUCTION_IV_LCSSA1:%.*]] = phi i32 [ [[INDUCTION_IV]], [[L1_BACKEDGE]] ]
 ; CHECK-NEXT:    [[L1_EXIT_VAL:%.*]] = phi i32 [ [[L1_SUM_NEXT]], [[L1_BACKEDGE]] ]
+; CHECK-NEXT:    [[TMP0:%.*]] = sub i32 0, [[L1_EXIT_VAL]]
 ; CHECK-NEXT:    br label [[L2_HEADER:%.*]]
 ; CHECK:       L2.header.loopexit:
 ; CHECK-NEXT:    br label [[L2_HEADER_BACKEDGE:%.*]]
@@ -45,24 +37,24 @@ define void @test(i32 %arg, i32 %L1.limit, i32 %L2.switch, i1 %c) {
 ; CHECK:       L2.Inner.header.preheader:
 ; CHECK-NEXT:    br i1 false, label [[SCALAR_PH:%.*]], label [[VECTOR_PH:%.*]]
 ; CHECK:       vector.ph:
-; CHECK-NEXT:    [[TMP3:%.*]] = mul i32 12, [[INDUCTION_IV_LCSSA1]]
-; CHECK-NEXT:    [[IND_END:%.*]] = add i32 1, [[TMP3]]
+; CHECK-NEXT:    [[TMP1:%.*]] = mul i32 12, [[TMP0]]
+; CHECK-NEXT:    [[IND_END:%.*]] = add i32 1, [[TMP1]]
 ; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
 ; CHECK:       vector.body:
 ; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
 ; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
-; CHECK-NEXT:    [[TMP4:%.*]] = icmp eq i64 [[INDEX_NEXT]], 12
-; CHECK-NEXT:    br i1 [[TMP4]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
+; CHECK-NEXT:    [[TMP2:%.*]] = icmp eq i64 [[INDEX_NEXT]], 12
+; CHECK-NEXT:    br i1 [[TMP2]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
 ; CHECK:       middle.block:
 ; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 12, 12
 ; CHECK-NEXT:    br i1 [[CMP_N]], label [[L2_HEADER_LOOPEXIT:%.*]], label [[SCALAR_PH]]
 ; CHECK:       scalar.ph:
 ; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i32 [ [[IND_END]], [[MIDDLE_BLOCK]] ], [ 1, [[L2_INNER_HEADER_PREHEADER]] ]
-; CHECK-NEXT:    [[BC_RESUME_VAL2:%.*]] = phi i64 [ 13, [[MIDDLE_BLOCK]] ], [ 1, [[L2_INNER_HEADER_PREHEADER]] ]
+; CHECK-NEXT:    [[BC_RESUME_VAL1:%.*]] = phi i64 [ 13, [[MIDDLE_BLOCK]] ], [ 1, [[L2_INNER_HEADER_PREHEADER]] ]
 ; CHECK-NEXT:    br label [[L2_INNER_HEADER:%.*]]
 ; CHECK:       L2.Inner.header:
 ; CHECK-NEXT:    [[L2_ACCUM:%.*]] = phi i32 [ [[L2_ACCUM_NEXT:%.*]], [[L2_INNER_HEADER]] ], [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ]
-; CHECK-NEXT:    [[L2_IV:%.*]] = phi i64 [ [[L2_IV_NEXT:%.*]], [[L2_INNER_HEADER]] ], [ [[BC_RESUME_VAL2]], [[SCALAR_PH]] ]
+; CHECK-NEXT:    [[L2_IV:%.*]] = phi i64 [ [[L2_IV_NEXT:%.*]], [[L2_INNER_HEADER]] ], [ [[BC_RESUME_VAL1]], [[SCALAR_PH]] ]
 ; CHECK-NEXT:    [[L2_ACCUM_NEXT]] = sub i32 [[L2_ACCUM]], [[L1_EXIT_VAL]]
 ; CHECK-NEXT:    [[L2_DUMMY_BUT_NEED_IT:%.*]] = sext i32 [[L2_ACCUM_NEXT]] to i64
 ; CHECK-NEXT:    [[L2_IV_NEXT]] = add nuw nsw i64 [[L2_IV]], 1
diff --git a/llvm/test/Transforms/LoopVectorize/pr45259.ll b/llvm/test/Transforms/LoopVectorize/pr45259.ll
index aa7df10bc82883..dc6a4b9e3d9a14 100644
--- a/llvm/test/Transforms/LoopVectorize/pr45259.ll
+++ b/llvm/test/Transforms/LoopVectorize/pr45259.ll
@@ -6,7 +6,7 @@
 define i8 @widget(i8* %arr, i8 %t9) {
 ; CHECK-LABEL: @widget(
 ; CHECK-NEXT:  bb:
-; CHECK-NEXT:    [[ARR1:%.*]] = ptrtoint i8* [[ARR:%.*]] to i64
+; CHECK-NEXT:    [[ARR2:%.*]] = ptrtoint i8* [[ARR:%.*]] to i64
 ; CHECK-NEXT:    br label [[BB6:%.*]]
 ; CHECK:       bb6:
 ; CHECK-NEXT:    [[T1_0:%.*]] = phi i8* [ [[ARR]], [[BB:%.*]] ], [ null, [[BB6]] ]
@@ -14,25 +14,24 @@ define i8 @widget(i8* %arr, i8 %t9) {
 ; CHECK-NEXT:    br i1 [[C]], label [[FOR_PREHEADER:%.*]], label [[BB6]]
 ; CHECK:       for.preheader:
 ; CHECK-NEXT:    [[T1_0_LCSSA:%.*]] = phi i8* [ [[T1_0]], [[BB6]] ]
-; CHECK-NEXT:    [[T1_0_LCSSA2:%.*]] = ptrtoint i8* [[T1_0_LCSSA]] to i64
-; CHECK-NEXT:    [[TMP0:%.*]] = trunc i64 [[ARR1]] to i32
-; CHECK-NEXT:    [[TMP1:%.*]] = sub i32 0, [[TMP0]]
-; CHECK-NEXT:    [[TMP2:%.*]] = trunc i64 [[T1_0_LCSSA2]] to i32
-; CHECK-NEXT:    [[TMP3:%.*]] = add i32 [[TMP1]], [[TMP2]]
-; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i32 [[TMP3]], 4
+; CHECK-NEXT:    [[T1_0_LCSSA1:%.*]] = ptrtoint i8* [[T1_0_LCSSA]] to i64
+; CHECK-NEXT:    [[TMP0:%.*]] = trunc i64 [[T1_0_LCSSA1]] to i32
+; CHECK-NEXT:    [[TMP1:%.*]] = trunc i64 [[ARR2]] to i32
+; CHECK-NEXT:    [[TMP2:%.*]] = sub i32 [[TMP0]], [[TMP1]]
+; CHECK-NEXT:    [[MIN_ITERS_CHECK:%.*]] = icmp ult i32 [[TMP2]], 4
 ; CHECK-NEXT:    br i1 [[MIN_ITERS_CHECK]], label [[SCALAR_PH:%.*]], label [[VECTOR_SCEVCHECK:%.*]]
 ; CHECK:       vector.scevcheck:
-; CHECK-NEXT:    [[TMP4:%.*]] = sub i64 -1, [[ARR1]]
-; CHECK-NEXT:    [[TMP5:%.*]] = add i64 [[TMP4]], [[T1_0_LCSSA2]]
-; CHECK-NEXT:    [[TMP6:%.*]] = trunc i64 [[TMP5]] to i8
-; CHECK-NEXT:    [[TMP7:%.*]] = add i8 1, [[TMP6]]
-; CHECK-NEXT:    [[TMP8:%.*]] = icmp slt i8 [[TMP7]], 1
-; CHECK-NEXT:    [[TMP9:%.*]] = icmp ugt i64 [[TMP5]], 255
-; CHECK-NEXT:    [[TMP10:%.*]] = or i1 [[TMP8]], [[TMP9]]
-; CHECK-NEXT:    br i1 [[TMP10]], label [[SCALAR_PH]], label [[VECTOR_PH:%.*]]
+; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[T1_0_LCSSA1]], -1
+; CHECK-NEXT:    [[TMP4:%.*]] = sub i64 [[TMP3]], [[ARR2]]
+; CHECK-NEXT:    [[TMP5:%.*]] = trunc i64 [[TMP4]] to i8
+; CHECK-NEXT:    [[TMP6:%.*]] = add i8 1, [[TMP5]]
+; CHECK-NEXT:    [[TMP9:%.*]] = icmp slt i8 [[TMP6]], 1
+; CHECK-NEXT:    [[TMP11:%.*]] = icmp ugt i64 [[TMP4]], 255
+; CHECK-NEXT:    [[TMP12:%.*]] = or i1 [[TMP9]], [[TMP11]]
+; CHECK-NEXT:    br i1 [[TMP12]], label [[SCALAR_PH]], label [[VECTOR_PH:%.*]]
 ; CHECK:       vector.ph:
-; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i32 [[TMP3]], 4
-; CHECK-NEXT:    [[N_VEC:%.*]] = sub i32 [[TMP3]], [[N_MOD_VF]]
+; CHECK-NEXT:    [[N_MOD_VF:%.*]] = urem i32 [[TMP2]], 4
+; CHECK-NEXT:    [[N_VEC:%.*]] = sub i32 [[TMP2]], [[N_MOD_VF]]
 ; CHECK-NEXT:    [[IND_END:%.*]] = trunc i32 [[N_VEC]] to i8
 ; CHECK-NEXT:    [[BROADCAST_SPLATINSERT:%.*]] = insertelement <4 x i8> poison, i8 [[T9:%.*]], i32 0
 ; CHECK-NEXT:    [[BROADCAST_SPLAT:%.*]] = shufflevector <4 x i8> [[BROADCAST_SPLATINSERT]], <4 x i8> poison, <4 x i32> zeroinitializer
@@ -40,20 +39,20 @@ define i8 @widget(i8* %arr, i8 %t9) {
 ; CHECK:       vector.body:
 ; CHECK-NEXT:    [[INDEX:%.*]] = phi i32 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
 ; CHECK-NEXT:    [[VEC_IND:%.*]] = phi <4 x i8> [ <i8 0, i8 1, i8 2, i8 3>, [[VECTOR_PH]] ], [ [[VEC_IND_NEXT:%.*]], [[VECTOR_BODY]] ]
-; CHECK-NEXT:    [[TMP11:%.*]] = add <4 x i8> [[VEC_IND]], <i8 1, i8 1, i8 1, i8 1>
-; CHECK-NEXT:    [[TMP12:%.*]] = extractelement <4 x i8> [[TMP11]], i32 0
-; CHECK-NEXT:    [[TMP13:%.*]] = getelementptr inbounds i8, i8* [[ARR]], i8 [[TMP12]]
-; CHECK-NEXT:    [[TMP14:%.*]] = icmp slt <4 x i8> [[TMP11]], [[BROADCAST_SPLAT]]
-; CHECK-NEXT:    [[TMP15:%.*]] = zext <4 x i1> [[TMP14]] to <4 x i8>
-; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i8, i8* [[TMP13]], i32 0
-; CHECK-NEXT:    [[TMP17:%.*]] = bitcast i8* [[TMP16]] to <4 x i8>*
-; CHECK-NEXT:    store <4 x i8> [[TMP15]], <4 x i8>* [[TMP17]], align 1
+; CHECK-NEXT:    [[TMP14:%.*]] = add <4 x i8> [[VEC_IND]], <i8 1, i8 1, i8 1, i8 1>
+; CHECK-NEXT:    [[TMP15:%.*]] = extractelement <4 x i8> [[TMP14]], i32 0
+; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i8, i8* [[ARR]], i8 [[TMP15]]
+; CHECK-NEXT:    [[TMP17:%.*]] = icmp slt <4 x i8> [[TMP14]], [[BROADCAST_SPLAT]]
+; CHECK-NEXT:    [[TMP18:%.*]] = zext <4 x i1> [[TMP17]] to <4 x i8>
+; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr inbounds i8, i8* [[TMP16]], i32 0
+; CHECK-NEXT:    [[TMP20:%.*]] = bitcast i8* [[TMP19]] to <4 x i8>*
+; CHECK-NEXT:    store <4 x i8> [[TMP18]], <4 x i8>* [[TMP20]], align 1
 ; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i32 [[INDEX]], 4
 ; CHECK-NEXT:    [[VEC_IND_NEXT]] = add <4 x i8> [[VEC_IND]], <i8 4, i8 4, i8 4, i8 4>
-; CHECK-NEXT:    [[TMP18:%.*]] = icmp eq i32 [[INDEX_NEXT]], [[N_VEC]]
-; CHECK-NEXT:    br i1 [[TMP18]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
+; CHECK-NEXT:    [[TMP21:%.*]] = icmp eq i32 [[INDEX_NEXT]], [[N_VEC]]
+; CHECK-NEXT:    br i1 [[TMP21]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP0:![0-9]+]]
 ; CHECK:       middle.block:
-; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i32 [[TMP3]], [[N_VEC]]
+; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i32 [[TMP2]], [[N_VEC]]
 ; CHECK-NEXT:    br i1 [[CMP_N]], label [[FOR_EXIT:%.*]], label [[SCALAR_PH]]
 ; CHECK:       scalar.ph:
 ; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i8 [ [[IND_END]], [[MIDDLE_BLOCK]] ], [ 0, [[FOR_PREHEADER]] ], [ 0, [[VECTOR_SCEVCHECK]] ]

From d35bc70e82511b38c55872ab33d3a950d2c8bbc4 Mon Sep 17 00:00:00 2001
From: Matt Devereau <matthew.devereau@arm.com>
Date: Thu, 8 Sep 2022 11:22:11 +0000
Subject: [PATCH 11/84] [AArch64][SVE] Fix AArch64_SVE_VectorCall calling
 convention

This fixes the case where callees with SVE arguments outside of the z0-z7
range were incorrectly deduced as SVE calling convention functions
---
 .../Target/AArch64/AArch64ISelLowering.cpp    |  67 ++--
 llvm/lib/Target/AArch64/AArch64ISelLowering.h |   2 +-
 .../AArch64/sve-calling-convention-mixed.ll   | 297 +++++++++++++++++-
 3 files changed, 330 insertions(+), 36 deletions(-)

diff --git a/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp b/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp
index c28216048d7cb3..06e21f90ebf13d 100644
--- a/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp
+++ b/llvm/lib/Target/AArch64/AArch64ISelLowering.cpp
@@ -5805,7 +5805,7 @@ SDValue AArch64TargetLowering::LowerFormalArguments(
     assert(!Res && "Call operand has unhandled type");
     (void)Res;
   }
-  SmallVector<SDValue, 16> ArgValues;
+
   unsigned ExtraArgLocs = 0;
   for (unsigned i = 0, e = Ins.size(); i != e; ++i) {
     CCValAssign &VA = ArgLocs[i - ExtraArgLocs];
@@ -6157,17 +6157,10 @@ void AArch64TargetLowering::saveVarArgRegisters(CCState &CCInfo,
 /// appropriate copies out of appropriate physical registers.
 SDValue AArch64TargetLowering::LowerCallResult(
     SDValue Chain, SDValue InFlag, CallingConv::ID CallConv, bool isVarArg,
-    const SmallVectorImpl<ISD::InputArg> &Ins, const SDLoc &DL,
+    const SmallVectorImpl<CCValAssign> &RVLocs, const SDLoc &DL,
     SelectionDAG &DAG, SmallVectorImpl<SDValue> &InVals, bool isThisReturn,
     SDValue ThisVal) const {
-  CCAssignFn *RetCC = CCAssignFnForReturn(CallConv);
-  // Assign locations to each value returned by this call.
-  SmallVector<CCValAssign, 16> RVLocs;
   DenseMap<unsigned, SDValue> CopiedRegs;
-  CCState CCInfo(CallConv, isVarArg, DAG.getMachineFunction(), RVLocs,
-                 *DAG.getContext());
-  CCInfo.AnalyzeCallResult(Ins, RetCC);
-
   // Copy all of the result registers out of their specified physreg.
   for (unsigned i = 0; i != RVLocs.size(); ++i) {
     CCValAssign VA = RVLocs[i];
@@ -6508,17 +6501,39 @@ AArch64TargetLowering::LowerCall(CallLoweringInfo &CLI,
     GuardWithBTI = FuncInfo->branchTargetEnforcement();
   }
 
+  // Analyze operands of the call, assigning locations to each operand.
+  SmallVector<CCValAssign, 16> ArgLocs;
+  CCState CCInfo(CallConv, IsVarArg, MF, ArgLocs, *DAG.getContext());
+
+  if (IsVarArg) {
+    unsigned NumArgs = Outs.size();
+
+    for (unsigned i = 0; i != NumArgs; ++i) {
+      if (!Outs[i].IsFixed && Outs[i].VT.isScalableVector())
+        report_fatal_error("Passing SVE types to variadic functions is "
+                           "currently not supported");
+    }
+  }
+
+  analyzeCallOperands(*this, Subtarget, CLI, CCInfo);
+
+  CCAssignFn *RetCC = CCAssignFnForReturn(CallConv);
+  // Assign locations to each value returned by this call.
+  SmallVector<CCValAssign, 16> RVLocs;
+  CCState RetCCInfo(CallConv, IsVarArg, DAG.getMachineFunction(), RVLocs,
+                    *DAG.getContext());
+  RetCCInfo.AnalyzeCallResult(Ins, RetCC);
+
   // Check callee args/returns for SVE registers and set calling convention
   // accordingly.
   if (CallConv == CallingConv::C || CallConv == CallingConv::Fast) {
-    bool CalleeOutSVE = any_of(Outs, [](ISD::OutputArg &Out){
-      return Out.VT.isScalableVector();
-    });
-    bool CalleeInSVE = any_of(Ins, [](ISD::InputArg &In){
-      return In.VT.isScalableVector();
-    });
-
-    if (CalleeInSVE || CalleeOutSVE)
+    auto HasSVERegLoc = [](CCValAssign &Loc) {
+      if (!Loc.isRegLoc())
+        return false;
+      return AArch64::ZPRRegClass.contains(Loc.getLocReg()) ||
+             AArch64::PPRRegClass.contains(Loc.getLocReg());
+    };
+    if (any_of(RVLocs, HasSVERegLoc) || any_of(ArgLocs, HasSVERegLoc))
       CallConv = CallingConv::AArch64_SVE_VectorCall;
   }
 
@@ -6540,22 +6555,6 @@ AArch64TargetLowering::LowerCall(CallLoweringInfo &CLI,
     report_fatal_error("failed to perform tail call elimination on a call "
                        "site marked musttail");
 
-  // Analyze operands of the call, assigning locations to each operand.
-  SmallVector<CCValAssign, 16> ArgLocs;
-  CCState CCInfo(CallConv, IsVarArg, MF, ArgLocs, *DAG.getContext());
-
-  if (IsVarArg) {
-    unsigned NumArgs = Outs.size();
-
-    for (unsigned i = 0; i != NumArgs; ++i) {
-      if (!Outs[i].IsFixed && Outs[i].VT.isScalableVector())
-        report_fatal_error("Passing SVE types to variadic functions is "
-                           "currently not supported");
-    }
-  }
-
-  analyzeCallOperands(*this, Subtarget, CLI, CCInfo);
-
   // Get a count of how many bytes are to be pushed on the stack.
   unsigned NumBytes = CCInfo.getNextStackOffset();
 
@@ -6961,7 +6960,7 @@ AArch64TargetLowering::LowerCall(CallLoweringInfo &CLI,
 
   // Handle result values, copying them out of physregs into vregs that we
   // return.
-  return LowerCallResult(Chain, InFlag, CallConv, IsVarArg, Ins, DL, DAG,
+  return LowerCallResult(Chain, InFlag, CallConv, IsVarArg, RVLocs, DL, DAG,
                          InVals, IsThisReturn,
                          IsThisReturn ? OutVals[0] : SDValue());
 }
diff --git a/llvm/lib/Target/AArch64/AArch64ISelLowering.h b/llvm/lib/Target/AArch64/AArch64ISelLowering.h
index 1ba2e2f315ec99..ff3bfe89786918 100644
--- a/llvm/lib/Target/AArch64/AArch64ISelLowering.h
+++ b/llvm/lib/Target/AArch64/AArch64ISelLowering.h
@@ -894,7 +894,7 @@ class AArch64TargetLowering : public TargetLowering {
 
   SDValue LowerCallResult(SDValue Chain, SDValue InFlag,
                           CallingConv::ID CallConv, bool isVarArg,
-                          const SmallVectorImpl<ISD::InputArg> &Ins,
+                          const SmallVectorImpl<CCValAssign> &RVLocs,
                           const SDLoc &DL, SelectionDAG &DAG,
                           SmallVectorImpl<SDValue> &InVals, bool isThisReturn,
                           SDValue ThisVal) const;
diff --git a/llvm/test/CodeGen/AArch64/sve-calling-convention-mixed.ll b/llvm/test/CodeGen/AArch64/sve-calling-convention-mixed.ll
index 1a159558ba5d45..8648a6863c521a 100644
--- a/llvm/test/CodeGen/AArch64/sve-calling-convention-mixed.ll
+++ b/llvm/test/CodeGen/AArch64/sve-calling-convention-mixed.ll
@@ -334,7 +334,46 @@ entry:
   ret void
 }
 
-; Use AAPCS, no SVE register in z0-7 used (floats occupy z0-z7)
+; Use AAVPCS, SVE register used in return
+
+define <vscale x 4 x float> @aavpcs5(float %s0, float %s1, float %s2, float %s3, float %s4, float %s5, float %s6, float %s7, <vscale x 4 x float> %s8, <vscale x 4 x float> %s9, <vscale x 4 x float> %s10, <vscale x 4 x float> %s11, <vscale x 4 x float> %s12, <vscale x 4 x float> %s13, <vscale x 4 x float> %s14, <vscale x 4 x float> %s15, <vscale x 4 x float> %s16, <vscale x 4 x float> %s17, float * %ptr) nounwind {
+; CHECK-LABEL: aavpcs5:
+; CHECK:       // %bb.0: // %entry
+; CHECK-NEXT:    ldr x8, [sp]
+; CHECK-NEXT:    ptrue p0.s
+; CHECK-NEXT:    ld1w { z1.s }, p0/z, [x8]
+; CHECK-NEXT:    ld1w { z2.s }, p0/z, [x7]
+; CHECK-NEXT:    ld1w { z3.s }, p0/z, [x6]
+; CHECK-NEXT:    ld1w { z4.s }, p0/z, [x5]
+; CHECK-NEXT:    ld1w { z5.s }, p0/z, [x4]
+; CHECK-NEXT:    ld1w { z6.s }, p0/z, [x3]
+; CHECK-NEXT:    ld1w { z7.s }, p0/z, [x2]
+; CHECK-NEXT:    ld1w { z24.s }, p0/z, [x1]
+; CHECK-NEXT:    ld1w { z0.s }, p0/z, [x0]
+; CHECK-NEXT:    ldr x8, [sp, #16]
+; CHECK-NEXT:    st1w { z0.s }, p0, [x8]
+; CHECK-NEXT:    st1w { z24.s }, p0, [x8]
+; CHECK-NEXT:    st1w { z7.s }, p0, [x8]
+; CHECK-NEXT:    st1w { z6.s }, p0, [x8]
+; CHECK-NEXT:    st1w { z5.s }, p0, [x8]
+; CHECK-NEXT:    st1w { z4.s }, p0, [x8]
+; CHECK-NEXT:    st1w { z3.s }, p0, [x8]
+; CHECK-NEXT:    st1w { z2.s }, p0, [x8]
+; CHECK-NEXT:    st1w { z1.s }, p0, [x8]
+; CHECK-NEXT:    ret
+entry:
+  %ptr1.bc = bitcast float * %ptr to <vscale x 4 x float> *
+  store volatile <vscale x 4 x float> %s8, <vscale x 4 x float>* %ptr1.bc
+  store volatile <vscale x 4 x float> %s9, <vscale x 4 x float>* %ptr1.bc
+  store volatile <vscale x 4 x float> %s10, <vscale x 4 x float>* %ptr1.bc
+  store volatile <vscale x 4 x float> %s11, <vscale x 4 x float>* %ptr1.bc
+  store volatile <vscale x 4 x float> %s12, <vscale x 4 x float>* %ptr1.bc
+  store volatile <vscale x 4 x float> %s13, <vscale x 4 x float>* %ptr1.bc
+  store volatile <vscale x 4 x float> %s14, <vscale x 4 x float>* %ptr1.bc
+  store volatile <vscale x 4 x float> %s15, <vscale x 4 x float>* %ptr1.bc
+  store volatile <vscale x 4 x float> %s16, <vscale x 4 x float>* %ptr1.bc
+  ret <vscale x 4 x float> %s8
+}
 
 define void @aapcs1(float %s0, float %s1, float %s2, float %s3, float %s4, float %s5, float %s6, float %s7, <vscale x 4 x float> %s8, <vscale x 4 x float> %s9, <vscale x 4 x float> %s10, <vscale x 4 x float> %s11, <vscale x 4 x float> %s12, <vscale x 4 x float> %s13, <vscale x 4 x float> %s14, <vscale x 4 x float> %s15, <vscale x 4 x float> %s16, <vscale x 4 x float> %s17, float * %ptr) nounwind {
 ; CHECK-LABEL: aapcs1:
@@ -375,6 +414,262 @@ entry:
   ret void
 }
 
+declare void @non_sve_callee_high_range(float %f0, float %f1, float %f2, float %f3, float %f4, float %f5, float %f6, float %f7, <vscale x 4 x float> %v0, <vscale x 4 x float> %v1)
+
+define void @non_sve_caller_non_sve_callee_high_range()  {
+; CHECK-LABEL: non_sve_caller_non_sve_callee_high_range:
+; CHECK:       // %bb.0:
+; CHECK-NEXT:    stp x29, x30, [sp, #-16]! // 16-byte Folded Spill
+; CHECK-NEXT:    .cfi_def_cfa_offset 16
+; CHECK-NEXT:    .cfi_offset w30, -8
+; CHECK-NEXT:    .cfi_offset w29, -16
+; CHECK-NEXT:    addvl sp, sp, #-2
+; CHECK-NEXT:    .cfi_escape 0x0f, 0x0c, 0x8f, 0x00, 0x11, 0x10, 0x22, 0x11, 0x10, 0x92, 0x2e, 0x00, 0x1e, 0x22 // sp + 16 + 16 * VG
+; CHECK-NEXT:    movi d0, #0000000000000000
+; CHECK-NEXT:    fmov s1, #1.00000000
+; CHECK-NEXT:    fmov s2, #2.00000000
+; CHECK-NEXT:    fmov s3, #3.00000000
+; CHECK-NEXT:    fmov s4, #4.00000000
+; CHECK-NEXT:    fmov s5, #5.00000000
+; CHECK-NEXT:    fmov s6, #6.00000000
+; CHECK-NEXT:    fmov s7, #7.00000000
+; CHECK-NEXT:    mov x1, sp
+; CHECK-NEXT:    addvl x0, sp, #1
+; CHECK-NEXT:    bl non_sve_callee_high_range
+; CHECK-NEXT:    addvl sp, sp, #2
+; CHECK-NEXT:    ldp x29, x30, [sp], #16 // 16-byte Folded Reload
+; CHECK-NEXT:    ret
+  call void @non_sve_callee_high_range(float 0.0, float 1.0, float 2.0, float 3.0, float 4.0, float 5.0, float 6.0, float 7.0, <vscale x 4 x float> undef, <vscale x 4 x float> undef)
+  ret void
+}
+
+define void @non_sve_caller_high_range_non_sve_callee_high_range(float %f0, float %f1, float %f2, float %f3, float %f4, float %f5, float %f6, float %f7, <vscale x 4 x float> %v0, <vscale x 4 x float> %v1)  {
+; CHECK-LABEL: non_sve_caller_high_range_non_sve_callee_high_range:
+; CHECK:       // %bb.0:
+; CHECK-NEXT:    stp x29, x30, [sp, #-16]! // 16-byte Folded Spill
+; CHECK-NEXT:    .cfi_def_cfa_offset 16
+; CHECK-NEXT:    .cfi_offset w30, -8
+; CHECK-NEXT:    .cfi_offset w29, -16
+; CHECK-NEXT:    addvl sp, sp, #-2
+; CHECK-NEXT:    .cfi_escape 0x0f, 0x0c, 0x8f, 0x00, 0x11, 0x10, 0x22, 0x11, 0x10, 0x92, 0x2e, 0x00, 0x1e, 0x22 // sp + 16 + 16 * VG
+; CHECK-NEXT:    ptrue p0.s
+; CHECK-NEXT:    movi d0, #0000000000000000
+; CHECK-NEXT:    ld1w { z16.s }, p0/z, [x0]
+; CHECK-NEXT:    ld1w { z17.s }, p0/z, [x1]
+; CHECK-NEXT:    fmov s1, #1.00000000
+; CHECK-NEXT:    fmov s2, #2.00000000
+; CHECK-NEXT:    fmov s3, #3.00000000
+; CHECK-NEXT:    fmov s4, #4.00000000
+; CHECK-NEXT:    fmov s5, #5.00000000
+; CHECK-NEXT:    fmov s6, #6.00000000
+; CHECK-NEXT:    fmov s7, #7.00000000
+; CHECK-NEXT:    mov x1, sp
+; CHECK-NEXT:    addvl x0, sp, #1
+; CHECK-NEXT:    st1w { z17.s }, p0, [sp]
+; CHECK-NEXT:    st1w { z16.s }, p0, [sp, #1, mul vl]
+; CHECK-NEXT:    bl non_sve_callee_high_range
+; CHECK-NEXT:    addvl sp, sp, #2
+; CHECK-NEXT:    ldp x29, x30, [sp], #16 // 16-byte Folded Reload
+; CHECK-NEXT:    ret
+  call void @non_sve_callee_high_range(float 0.0, float 1.0, float 2.0, float 3.0, float 4.0, float 5.0, float 6.0, float 7.0, <vscale x 4 x float> %v0, <vscale x 4 x float> %v1)
+  ret void
+}
+
+define <vscale x 4 x float> @sve_caller_non_sve_callee_high_range(<vscale x 4 x float> %v0, <vscale x 4 x float> %v1)  {
+; CHECK-LABEL: sve_caller_non_sve_callee_high_range:
+; CHECK:       // %bb.0:
+; CHECK-NEXT:    stp x29, x30, [sp, #-16]! // 16-byte Folded Spill
+; CHECK-NEXT:    .cfi_def_cfa_offset 16
+; CHECK-NEXT:    .cfi_offset w30, -8
+; CHECK-NEXT:    .cfi_offset w29, -16
+; CHECK-NEXT:    addvl sp, sp, #-18
+; CHECK-NEXT:    .cfi_escape 0x0f, 0x0d, 0x8f, 0x00, 0x11, 0x10, 0x22, 0x11, 0x90, 0x01, 0x92, 0x2e, 0x00, 0x1e, 0x22 // sp + 16 + 144 * VG
+; CHECK-NEXT:    str p15, [sp, #4, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p14, [sp, #5, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p13, [sp, #6, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p12, [sp, #7, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p11, [sp, #8, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p10, [sp, #9, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p9, [sp, #10, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p8, [sp, #11, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p7, [sp, #12, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p6, [sp, #13, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p5, [sp, #14, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p4, [sp, #15, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str z23, [sp, #2, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z22, [sp, #3, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z21, [sp, #4, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z20, [sp, #5, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z19, [sp, #6, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z18, [sp, #7, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z17, [sp, #8, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z16, [sp, #9, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z15, [sp, #10, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z14, [sp, #11, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z13, [sp, #12, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z12, [sp, #13, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z11, [sp, #14, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z10, [sp, #15, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z9, [sp, #16, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z8, [sp, #17, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    .cfi_escape 0x10, 0x48, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x78, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d8 @ cfa - 16 - 8 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x49, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x70, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d9 @ cfa - 16 - 16 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4a, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x68, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d10 @ cfa - 16 - 24 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4b, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x60, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d11 @ cfa - 16 - 32 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4c, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x58, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d12 @ cfa - 16 - 40 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4d, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x50, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d13 @ cfa - 16 - 48 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4e, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x48, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d14 @ cfa - 16 - 56 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4f, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x40, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d15 @ cfa - 16 - 64 * VG
+; CHECK-NEXT:    addvl sp, sp, #-3
+; CHECK-NEXT:    .cfi_escape 0x0f, 0x0d, 0x8f, 0x00, 0x11, 0x10, 0x22, 0x11, 0xa8, 0x01, 0x92, 0x2e, 0x00, 0x1e, 0x22 // sp + 16 + 168 * VG
+; CHECK-NEXT:    mov z25.d, z0.d
+; CHECK-NEXT:    str z0, [sp] // 16-byte Folded Spill
+; CHECK-NEXT:    movi d0, #0000000000000000
+; CHECK-NEXT:    mov z24.d, z1.d
+; CHECK-NEXT:    fmov s1, #1.00000000
+; CHECK-NEXT:    fmov s2, #2.00000000
+; CHECK-NEXT:    fmov s3, #3.00000000
+; CHECK-NEXT:    fmov s4, #4.00000000
+; CHECK-NEXT:    fmov s5, #5.00000000
+; CHECK-NEXT:    fmov s6, #6.00000000
+; CHECK-NEXT:    fmov s7, #7.00000000
+; CHECK-NEXT:    addvl x0, sp, #2
+; CHECK-NEXT:    addvl x1, sp, #1
+; CHECK-NEXT:    ptrue p0.s
+; CHECK-NEXT:    st1w { z24.s }, p0, [sp, #1, mul vl]
+; CHECK-NEXT:    st1w { z25.s }, p0, [sp, #2, mul vl]
+; CHECK-NEXT:    bl non_sve_callee_high_range
+; CHECK-NEXT:    ldr z0, [sp] // 16-byte Folded Reload
+; CHECK-NEXT:    addvl sp, sp, #3
+; CHECK-NEXT:    ldr p15, [sp, #4, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p14, [sp, #5, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p13, [sp, #6, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p12, [sp, #7, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p11, [sp, #8, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p10, [sp, #9, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p9, [sp, #10, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p8, [sp, #11, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p7, [sp, #12, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p6, [sp, #13, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p5, [sp, #14, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p4, [sp, #15, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr z23, [sp, #2, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z22, [sp, #3, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z21, [sp, #4, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z20, [sp, #5, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z19, [sp, #6, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z18, [sp, #7, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z17, [sp, #8, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z16, [sp, #9, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z15, [sp, #10, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z14, [sp, #11, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z13, [sp, #12, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z12, [sp, #13, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z11, [sp, #14, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z10, [sp, #15, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z9, [sp, #16, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z8, [sp, #17, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    addvl sp, sp, #18
+; CHECK-NEXT:    ldp x29, x30, [sp], #16 // 16-byte Folded Reload
+; CHECK-NEXT:    ret
+  call void @non_sve_callee_high_range(float 0.0, float 1.0, float 2.0, float 3.0, float 4.0, float 5.0, float 6.0, float 7.0, <vscale x 4 x float> %v0, <vscale x 4 x float> %v1)
+  ret <vscale x 4 x float> %v0
+}
+
+define <vscale x 4 x float> @sve_ret_caller_non_sve_callee_high_range()  {
+; CHECK-LABEL: sve_ret_caller_non_sve_callee_high_range:
+; CHECK:       // %bb.0:
+; CHECK-NEXT:    stp x29, x30, [sp, #-16]! // 16-byte Folded Spill
+; CHECK-NEXT:    .cfi_def_cfa_offset 16
+; CHECK-NEXT:    .cfi_offset w30, -8
+; CHECK-NEXT:    .cfi_offset w29, -16
+; CHECK-NEXT:    addvl sp, sp, #-18
+; CHECK-NEXT:    .cfi_escape 0x0f, 0x0d, 0x8f, 0x00, 0x11, 0x10, 0x22, 0x11, 0x90, 0x01, 0x92, 0x2e, 0x00, 0x1e, 0x22 // sp + 16 + 144 * VG
+; CHECK-NEXT:    str p15, [sp, #4, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p14, [sp, #5, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p13, [sp, #6, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p12, [sp, #7, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p11, [sp, #8, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p10, [sp, #9, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p9, [sp, #10, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p8, [sp, #11, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p7, [sp, #12, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p6, [sp, #13, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p5, [sp, #14, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str p4, [sp, #15, mul vl] // 2-byte Folded Spill
+; CHECK-NEXT:    str z23, [sp, #2, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z22, [sp, #3, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z21, [sp, #4, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z20, [sp, #5, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z19, [sp, #6, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z18, [sp, #7, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z17, [sp, #8, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z16, [sp, #9, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z15, [sp, #10, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z14, [sp, #11, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z13, [sp, #12, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z12, [sp, #13, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z11, [sp, #14, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z10, [sp, #15, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z9, [sp, #16, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    str z8, [sp, #17, mul vl] // 16-byte Folded Spill
+; CHECK-NEXT:    .cfi_escape 0x10, 0x48, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x78, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d8 @ cfa - 16 - 8 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x49, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x70, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d9 @ cfa - 16 - 16 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4a, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x68, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d10 @ cfa - 16 - 24 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4b, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x60, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d11 @ cfa - 16 - 32 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4c, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x58, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d12 @ cfa - 16 - 40 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4d, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x50, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d13 @ cfa - 16 - 48 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4e, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x48, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d14 @ cfa - 16 - 56 * VG
+; CHECK-NEXT:    .cfi_escape 0x10, 0x4f, 0x0a, 0x11, 0x70, 0x22, 0x11, 0x40, 0x92, 0x2e, 0x00, 0x1e, 0x22 // $d15 @ cfa - 16 - 64 * VG
+; CHECK-NEXT:    addvl sp, sp, #-2
+; CHECK-NEXT:    .cfi_escape 0x0f, 0x0d, 0x8f, 0x00, 0x11, 0x10, 0x22, 0x11, 0xa0, 0x01, 0x92, 0x2e, 0x00, 0x1e, 0x22 // sp + 16 + 160 * VG
+; CHECK-NEXT:    movi d0, #0000000000000000
+; CHECK-NEXT:    fmov s1, #1.00000000
+; CHECK-NEXT:    fmov s2, #2.00000000
+; CHECK-NEXT:    fmov s3, #3.00000000
+; CHECK-NEXT:    fmov s4, #4.00000000
+; CHECK-NEXT:    fmov s5, #5.00000000
+; CHECK-NEXT:    fmov s6, #6.00000000
+; CHECK-NEXT:    fmov s7, #7.00000000
+; CHECK-NEXT:    mov x1, sp
+; CHECK-NEXT:    addvl x0, sp, #1
+; CHECK-NEXT:    bl non_sve_callee_high_range
+; CHECK-NEXT:    addvl sp, sp, #2
+; CHECK-NEXT:    ldr p15, [sp, #4, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p14, [sp, #5, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p13, [sp, #6, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p12, [sp, #7, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p11, [sp, #8, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p10, [sp, #9, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p9, [sp, #10, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p8, [sp, #11, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p7, [sp, #12, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p6, [sp, #13, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p5, [sp, #14, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr p4, [sp, #15, mul vl] // 2-byte Folded Reload
+; CHECK-NEXT:    ldr z23, [sp, #2, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z22, [sp, #3, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z21, [sp, #4, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z20, [sp, #5, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z19, [sp, #6, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z18, [sp, #7, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z17, [sp, #8, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z16, [sp, #9, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z15, [sp, #10, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z14, [sp, #11, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z13, [sp, #12, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z12, [sp, #13, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z11, [sp, #14, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z10, [sp, #15, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z9, [sp, #16, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    ldr z8, [sp, #17, mul vl] // 16-byte Folded Reload
+; CHECK-NEXT:    addvl sp, sp, #18
+; CHECK-NEXT:    ldp x29, x30, [sp], #16 // 16-byte Folded Reload
+; CHECK-NEXT:    ret
+  call void @non_sve_callee_high_range(float 0.0, float 1.0, float 2.0, float 3.0, float 4.0, float 5.0, float 6.0, float 7.0, <vscale x 4 x float> undef, <vscale x 4 x float> undef)
+  ret <vscale x 4 x float> undef
+}
+
 declare float @callee1(float, <vscale x 8 x double>, <vscale x 8 x double>, <vscale x 2 x double>)
 declare float @callee2(i32, i32, i32, i32, i32, i32, i32, i32, float, <vscale x 8 x double>, <vscale x 8 x double>)
 declare float @callee3(float, float, <vscale x 8 x double>, <vscale x 6 x double>, <vscale x 2 x double>)

From dfef316bb3d60edcb7a9f78abc62be78473458dc Mon Sep 17 00:00:00 2001
From: Nathan James <n.james93@hotmail.co.uk>
Date: Sat, 24 Sep 2022 18:29:17 +0100
Subject: [PATCH 12/84] [clang-tidy] Fix a false positive in
 readability-simplify-boolean-expr

Reviewed By: LegalizeAdulthood

Differential Revision: https://reviews.llvm.org/D134590

(cherry picked from commit 8c783b8ec78ec857e446a89a35463baed8026f40)
---
 .../readability/SimplifyBooleanExprCheck.cpp          |  4 ++--
 .../simplify-bool-expr-chained-conditional-return.cpp | 11 +++++++++++
 2 files changed, 13 insertions(+), 2 deletions(-)

diff --git a/clang-tools-extra/clang-tidy/readability/SimplifyBooleanExprCheck.cpp b/clang-tools-extra/clang-tidy/readability/SimplifyBooleanExprCheck.cpp
index 8ae990a929dfdd..afb4a1044a79ad 100644
--- a/clang-tools-extra/clang-tidy/readability/SimplifyBooleanExprCheck.cpp
+++ b/clang-tools-extra/clang-tidy/readability/SimplifyBooleanExprCheck.cpp
@@ -472,8 +472,8 @@ class SimplifyBooleanExprCheck::Visitor : public RecursiveASTVisitor<Visitor> {
               checkSingleStatement(If->getThen(), parseReturnLiteralBool);
           if (ThenReturnBool &&
               ThenReturnBool.Bool != TrailingReturnBool.Bool) {
-            if (Check->ChainedConditionalReturn ||
-                (!PrevIf && If->getElse() == nullptr)) {
+            if ((Check->ChainedConditionalReturn || !PrevIf) &&
+                If->getElse() == nullptr) {
               Check->replaceCompoundReturnWithCondition(
                   Context, cast<ReturnStmt>(*Second), TrailingReturnBool.Bool,
                   If, ThenReturnBool.Item);
diff --git a/clang-tools-extra/test/clang-tidy/checkers/readability/simplify-bool-expr-chained-conditional-return.cpp b/clang-tools-extra/test/clang-tidy/checkers/readability/simplify-bool-expr-chained-conditional-return.cpp
index 7e97e9f717fbf9..ff50528c215f41 100644
--- a/clang-tools-extra/test/clang-tidy/checkers/readability/simplify-bool-expr-chained-conditional-return.cpp
+++ b/clang-tools-extra/test/clang-tidy/checkers/readability/simplify-bool-expr-chained-conditional-return.cpp
@@ -92,3 +92,14 @@ bool complex_chained_if_return_return_negated(int i) {
 // CHECK-FIXES: {{^}}  }{{$}}
 // CHECK-FIXES: {{^  return i <= 10;$}}
 // CHECK-FIXES: {{^}$}}
+
+
+bool PR57819(int x) {
+  // False positive introduced in clang-tidy-15
+  // Expect no warning here.
+  if (x > 0)
+    return false;
+  else {
+  }
+  return true;
+}

From e3b0721b5b7371b2f13196997f9aa096d2179369 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Micha=C5=82=20G=C3=B3rny?= <mgorny@gentoo.org>
Date: Thu, 6 Oct 2022 16:41:04 +0200
Subject: [PATCH 13/84] [llvm] [lit] Fix use_lld() to respect llvm_shlib_dir

Fix the use_lld() to use llvm_shlib_dir similarly to how use_clang()
does it.  This fixes use_lld() wrongly prepending llvm_libs_dir,
i.e. the directory with system-installed LLVM libraries before
the build directory of standalone build.  As a result, the shared
libraries from an earlier version of clang end up being used instead of
the newly built version when running the test suite prior to installing.

To reproduce the problem, build and install LLVM with dylibs first,
e.g.:

    cmake ../llvm -G Ninja -DCMAKE_BUILD_TYPE=MinSizeRel \
      -DCMAKE_INSTALL_PREFIX="${HOME}"/llvm-test \
      -DLLVM_BUILD_LLVM_DYLIB=ON -DLLVM_LINK_LLVM_DYLIB=ON \
      -DLLVM_INSTALL_UTILS=ON
    ninja install

Then build clang against that installation and run tests:

    export LD_LIBRARY_PATH=~/llvm-test/lib
    export PATh=~/llvm-test/bin:"${PATH}"
    cmake ../clang -G Ninja -DCMAKE_BUILD_TYPE=MinSizeRel \
      -DCMAKE_INSTALL_PREFIX="${HOME}"/llvm-test \
      -DCLANG_LINK_CLANG_DYLIB=ON -DLLVM_BUILD_TESTS=ON \
      -DLLVM_EXTERNAL_LIT="${PWD}"/bin/llvm-lit
    ninja check-clang

The tests will be run with LD_LIBRARY_PATH of:

    /home/${USER}/llvm-test/lib:/home/${USER}/llvm-project/build-clang/lib

As a result, installed libclang-cpp will take precedence over the one
from build dir.  With the patch, the correct path is used, i.e.:

    /home/${USER}/llvm-project/build-clang/lib:/home/${USER}/llvm-test/lib

Differential Revision: https://reviews.llvm.org/D135368

(cherry picked from commit a64ea173d7b152678780d5443407d1071277642b)
---
 llvm/utils/lit/lit/llvm/config.py | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/llvm/utils/lit/lit/llvm/config.py b/llvm/utils/lit/lit/llvm/config.py
index b6531612814648..7dae83733f31e7 100644
--- a/llvm/utils/lit/lit/llvm/config.py
+++ b/llvm/utils/lit/lit/llvm/config.py
@@ -609,7 +609,7 @@ def use_lld(self, additional_tool_dirs=[], required=True,
         self.with_environment('PATH', paths, append_path=True)
 
         lib_dir_props = [self.config.name.lower() + '_libs_dir',
-                         'lld_libs_dir', 'llvm_libs_dir']
+                         'lld_libs_dir', 'llvm_shlib_dir', 'llvm_libs_dir']
         lib_paths = [getattr(self.config, pp) for pp in lib_dir_props
                      if getattr(self.config, pp, None)]
 

From 6fba7854a2f0b6b3899bb156c1a0c4ae35c96e24 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Micha=C5=82=20G=C3=B3rny?= <mgorny@gentoo.org>
Date: Thu, 6 Oct 2022 14:41:52 +0200
Subject: [PATCH 14/84] [llvm] [test] Add missing canonicalization of
 LLVM_ENABLE_ZSTD

Add LLVM_ENABLE_ZSTD to llvm_canonicalize_cmake_booleans().  This is
needed to ensure that the substitutions in lit.site.cfg.py resolve
to correct Python booleans.

Differential Revision: https://reviews.llvm.org/D135357

(cherry picked from commit bc4bcbcfc820b324f680e8f260691c38052eedc9)
---
 llvm/test/CMakeLists.txt | 1 +
 1 file changed, 1 insertion(+)

diff --git a/llvm/test/CMakeLists.txt b/llvm/test/CMakeLists.txt
index 86ca20ada7b80a..e7dd22261cc487 100644
--- a/llvm/test/CMakeLists.txt
+++ b/llvm/test/CMakeLists.txt
@@ -8,6 +8,7 @@ llvm_canonicalize_cmake_booleans(
   LLVM_ENABLE_CURL
   LLVM_ENABLE_HTTPLIB
   LLVM_ENABLE_ZLIB
+  LLVM_ENABLE_ZSTD
   LLVM_ENABLE_LIBXML2
   LLVM_INCLUDE_GO_TESTS
   LLVM_LINK_LLVM_DYLIB

From b4840279846e1eea44c3dca575395a90c9d77ca0 Mon Sep 17 00:00:00 2001
From: Petr Hosek <phosek@google.com>
Date: Fri, 30 Sep 2022 20:33:13 +0000
Subject: [PATCH 15/84] [CMake] Provide Findzstd module

This module is used to find the system zstd library. The imported
targets intentionally use the same name as the generate zstd config
CMake file so these can be used interchangeably.

Differential Revision: https://reviews.llvm.org/D134990

(cherry picked from commit 2d4fd0b6d5d5582ebb8b521d807104235d67aee4)
---
 llvm/cmake/modules/Findzstd.cmake | 49 +++++++++++++++++++++++++++++++
 1 file changed, 49 insertions(+)
 create mode 100644 llvm/cmake/modules/Findzstd.cmake

diff --git a/llvm/cmake/modules/Findzstd.cmake b/llvm/cmake/modules/Findzstd.cmake
new file mode 100644
index 00000000000000..fab9ea803261b1
--- /dev/null
+++ b/llvm/cmake/modules/Findzstd.cmake
@@ -0,0 +1,49 @@
+# Try to find the zstd library
+#
+# If successful, the following variables will be defined:
+# zstd_INCLUDE_DIR
+# zstd_LIBRARY
+# zstd_FOUND
+#
+# Additionally, one of the following import targets will be defined:
+# zstd::libzstd_shared
+# zstd::libzstd_static
+
+if(MSVC)
+  set(zstd_SHARED_LIBRARY_SUFFIX "\\${CMAKE_LINK_LIBRARY_SUFFIX}$")
+  set(zstd_STATIC_LIBRARY_SUFFIX "_static\\${CMAKE_STATIC_LIBRARY_SUFFIX}$")
+else()
+  set(zstd_SHARED_LIBRARY_SUFFIX "\\${CMAKE_SHARED_LIBRARY_SUFFIX}$")
+  set(zstd_STATIC_LIBRARY_SUFFIX "\\${CMAKE_STATIC_LIBRARY_SUFFIX}$")
+endif()
+
+find_path(zstd_INCLUDE_DIR NAMES zstd.h)
+find_library(zstd_LIBRARY NAMES zstd zstd_static)
+
+include(FindPackageHandleStandardArgs)
+find_package_handle_standard_args(
+    zstd DEFAULT_MSG
+    zstd_LIBRARY zstd_INCLUDE_DIR
+)
+
+if(zstd_FOUND)
+  if(zstd_LIBRARY MATCHES "${zstd_SHARED_LIBRARY_SUFFIX}$" AND
+     NOT TARGET zstd::libzstd_shared)
+    add_library(zstd::libzstd_shared SHARED IMPORTED)
+    set_target_properties(zstd::libzstd_shared PROPERTIES
+          INTERFACE_INCLUDE_DIRECTORIES "${zstd_INCLUDE_DIR}"
+          IMPORTED_LOCATION "${zstd_LIBRARY}")
+  endif()
+  if(zstd_LIBRARY MATCHES "${zstd_STATIC_LIBRARY_SUFFIX}$" AND
+     NOT TARGET zstd::libzstd_static)
+    add_library(zstd::libzstd_static STATIC IMPORTED)
+    set_target_properties(zstd::libzstd_static PROPERTIES
+        INTERFACE_INCLUDE_DIRECTORIES "${zstd_INCLUDE_DIR}"
+        IMPORTED_LOCATION "${zstd_LIBRARY}")
+  endif()
+endif()
+
+unset(zstd_SHARED_LIBRARY_SUFFIX)
+unset(zstd_STATIC_LIBRARY_SUFFIX)
+
+mark_as_advanced(zstd_INCLUDE_DIR zstd_LIBRARY)

From 687250913265a0160c8fba2c0bd93ddd933ec9c2 Mon Sep 17 00:00:00 2001
From: Louis Dionne <ldionne.2@gmail.com>
Date: Tue, 11 Oct 2022 14:53:14 -0400
Subject: [PATCH 16/84] [libc++] Fix std::function's handling of blocks under
 Objc ARC

Previously, some uses of std::function with blocks would crash when ARC was enabled.

rdar://100907096

Differential Revision: https://reviews.llvm.org/D135706

(cherry picked from commit 0e4802bf45952b1120c52d4d1bf6bfa2800fd102)
---
 libcxx/include/__functional/function.h        | 14 ++-
 .../function.objects/func.blocks.arc.pass.mm  | 89 +++++++++++++++++++
 ...unc.blocks.sh.cpp => func.blocks.pass.cpp} |  3 +-
 3 files changed, 102 insertions(+), 4 deletions(-)
 create mode 100644 libcxx/test/libcxx/utilities/function.objects/func.blocks.arc.pass.mm
 rename libcxx/test/libcxx/utilities/function.objects/{func.blocks.sh.cpp => func.blocks.pass.cpp} (98%)

diff --git a/libcxx/include/__functional/function.h b/libcxx/include/__functional/function.h
index db3af6e24101bf..55b607f3f8047d 100644
--- a/libcxx/include/__functional/function.h
+++ b/libcxx/include/__functional/function.h
@@ -883,7 +883,7 @@ template <class _Rp, class... _ArgTypes> class __policy_func<_Rp(_ArgTypes...)>
 #endif // _LIBCPP_NO_RTTI
 };
 
-#if defined(_LIBCPP_HAS_BLOCKS_RUNTIME) && !defined(_LIBCPP_HAS_OBJC_ARC)
+#if defined(_LIBCPP_HAS_BLOCKS_RUNTIME)
 
 extern "C" void *_Block_copy(const void *);
 extern "C" void _Block_release(const void *);
@@ -898,14 +898,22 @@ class __func<_Rp1(^)(_ArgTypes1...), _Alloc, _Rp(_ArgTypes...)>
 public:
     _LIBCPP_INLINE_VISIBILITY
     explicit __func(__block_type const& __f)
+#ifdef _LIBCPP_HAS_OBJC_ARC
+        : __f_(__f)
+#else
         : __f_(reinterpret_cast<__block_type>(__f ? _Block_copy(__f) : nullptr))
+#endif
     { }
 
     // [TODO] add && to save on a retain
 
     _LIBCPP_INLINE_VISIBILITY
     explicit __func(__block_type __f, const _Alloc& /* unused */)
+#ifdef _LIBCPP_HAS_OBJC_ARC
+        : __f_(__f)
+#else
         : __f_(reinterpret_cast<__block_type>(__f ? _Block_copy(__f) : nullptr))
+#endif
     { }
 
     virtual __base<_Rp(_ArgTypes...)>* __clone() const {
@@ -921,8 +929,10 @@ class __func<_Rp1(^)(_ArgTypes1...), _Alloc, _Rp(_ArgTypes...)>
     }
 
     virtual void destroy() _NOEXCEPT {
+#ifndef _LIBCPP_HAS_OBJC_ARC
         if (__f_)
             _Block_release(__f_);
+#endif
         __f_ = 0;
     }
 
@@ -950,7 +960,7 @@ class __func<_Rp1(^)(_ArgTypes1...), _Alloc, _Rp(_ArgTypes...)>
 #endif // _LIBCPP_NO_RTTI
 };
 
-#endif // _LIBCPP_HAS_EXTENSION_BLOCKS && !_LIBCPP_HAS_OBJC_ARC
+#endif // _LIBCPP_HAS_EXTENSION_BLOCKS
 
 } // namespace __function
 
diff --git a/libcxx/test/libcxx/utilities/function.objects/func.blocks.arc.pass.mm b/libcxx/test/libcxx/utilities/function.objects/func.blocks.arc.pass.mm
new file mode 100644
index 00000000000000..186fe22e6e4762
--- /dev/null
+++ b/libcxx/test/libcxx/utilities/function.objects/func.blocks.arc.pass.mm
@@ -0,0 +1,89 @@
+//===----------------------------------------------------------------------===//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+// std::function support for "blocks" when ARC is enabled
+
+// UNSUPPORTED: c++03
+
+// This test requires the Blocks runtime, which is (only?) available on Darwin
+// out-of-the-box.
+// REQUIRES: has-fblocks && darwin
+
+// ADDITIONAL_COMPILE_FLAGS: -fblocks -fobjc-arc
+
+#include <functional>
+
+#include <cassert>
+#include <cstddef>
+#include <string>
+
+struct Foo {
+  Foo() = default;
+  Foo(std::size_t (^bl)()) : f(bl) {}
+
+  std::function<int()> f;
+};
+
+Foo Factory(std::size_t (^bl)()) {
+  Foo result(bl);
+  return result;
+}
+
+Foo Factory2() {
+  auto hello = std::string("Hello world");
+  return Factory(^() {
+    return hello.size();
+  });
+}
+
+Foo AssignmentFactory(std::size_t (^bl)()) {
+  Foo result;
+  result.f = bl;
+  return result;
+}
+
+Foo AssignmentFactory2() {
+  auto hello = std::string("Hello world");
+  return AssignmentFactory(^() {
+    return hello.size();
+  });
+}
+
+int main(int, char **) {
+  // Case 1, works
+  {
+    auto hello = std::string("Hello world");
+    auto f = AssignmentFactory(^() {
+      return hello.size();
+    });
+    assert(f.f() == 11);
+  }
+
+  // Case 2, works
+  {
+    auto f = AssignmentFactory2();
+    assert(f.f() == 11);
+  }
+
+  // Case 3, works
+  {
+    auto hello = std::string("Hello world");
+    auto f = Factory(^() {
+      return hello.size();
+    });
+    assert(f.f() == 11);
+  }
+
+  // Case 4, used to crash under ARC
+  {
+    auto f = Factory2();
+    assert(f.f() == 11);
+  }
+
+  return 0;
+}
diff --git a/libcxx/test/libcxx/utilities/function.objects/func.blocks.sh.cpp b/libcxx/test/libcxx/utilities/function.objects/func.blocks.pass.cpp
similarity index 98%
rename from libcxx/test/libcxx/utilities/function.objects/func.blocks.sh.cpp
rename to libcxx/test/libcxx/utilities/function.objects/func.blocks.pass.cpp
index ecebc7c9800fff..b95b6ebb534a19 100644
--- a/libcxx/test/libcxx/utilities/function.objects/func.blocks.sh.cpp
+++ b/libcxx/test/libcxx/utilities/function.objects/func.blocks.pass.cpp
@@ -14,8 +14,7 @@
 // on Darwin out-of-the-box.
 // REQUIRES: has-fblocks && darwin
 
-// RUN: %{build} -fblocks
-// RUN: %{run}
+// ADDITIONAL_COMPILE_FLAGS: -fblocks
 
 #include <functional>
 #include <cstdlib>

From f6af95770615c2218084c82c62c10459feebbfbf Mon Sep 17 00:00:00 2001
From: Sam McCall <sam.mccall@gmail.com>
Date: Thu, 13 Oct 2022 01:43:49 +0200
Subject: [PATCH 17/84] [clangd] Block clang-tidy misc-const-correctness check

This check performs an extremely large amount of work (for each variable, it
runs very many full matcher-driven traversals of the whole scope the variable
is defined in).

When (inadvertently) enabled for Fuchsia, it regressed BuildAST times by >10x
(400ms -> 7s on my machine).

Differential Revision: https://reviews.llvm.org/D135829

(cherry picked from commit e78165f0ba1e2fbf72b36a36c8560645b69a168a)
---
 clang-tools-extra/clangd/TidyProvider.cpp | 10 ++++++++--
 1 file changed, 8 insertions(+), 2 deletions(-)

diff --git a/clang-tools-extra/clangd/TidyProvider.cpp b/clang-tools-extra/clangd/TidyProvider.cpp
index 32a4d6a3065368..a0a37e86ba010d 100644
--- a/clang-tools-extra/clangd/TidyProvider.cpp
+++ b/clang-tools-extra/clangd/TidyProvider.cpp
@@ -212,8 +212,14 @@ TidyProvider disableUnusableChecks(llvm::ArrayRef<std::string> ExtraBadChecks) {
                        // code, which is often the case when clangd
                        // tries to build an AST.
                        "-bugprone-use-after-move",
-                       // Alias for bugprone-use-after-moe.
-                       "-hicpp-invalid-access-moved");
+                       // Alias for bugprone-use-after-move.
+                       "-hicpp-invalid-access-moved",
+
+                       // ----- Performance problems -----
+
+                       // This check runs expensive analysis for each variable.
+                       // It has been observed to increase reparse time by 10x.
+                       "-misc-const-correctness");
 
   size_t Size = BadChecks.size();
   for (const std::string &Str : ExtraBadChecks) {

From 4a2c05b05ed07f1f620e94f6524a8b4b2760a0b1 Mon Sep 17 00:00:00 2001
From: David Green <david.green@arm.com>
Date: Fri, 14 Oct 2022 18:49:25 +0100
Subject: [PATCH 18/84] [ARM] Fix for MVE i128 vector icmp costs.

We were hitting an assert as the legalied type needn't be a vector.

Fixes #58364

(cherry picked from commit de6dfbbb300e552efa1cd86a023063a39d408b06)
---
 llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp | 2 +-
 llvm/test/Analysis/CostModel/ARM/mve-cmp.ll    | 5 +++++
 2 files changed, 6 insertions(+), 1 deletion(-)

diff --git a/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp b/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp
index 3c102463ba0806..cbfd2bc68f185f 100644
--- a/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp
+++ b/llvm/lib/Target/ARM/ARMTargetTransformInfo.cpp
@@ -1036,7 +1036,7 @@ InstructionCost ARMTTIImpl::getCmpSelInstrCost(unsigned Opcode, Type *ValTy,
     // split, we may need an expensive shuffle to get two in sync. This has the
     // effect of making larger than legal compares (v8i32 for example)
     // expensive.
-    if (LT.second.getVectorNumElements() > 2) {
+    if (LT.second.isVector() && LT.second.getVectorNumElements() > 2) {
       if (LT.first > 1)
         return LT.first * BaseCost +
                BaseT::getScalarizationOverhead(VecCondTy, true, false);
diff --git a/llvm/test/Analysis/CostModel/ARM/mve-cmp.ll b/llvm/test/Analysis/CostModel/ARM/mve-cmp.ll
index 17dd26cdc6cc79..bb517fa47d89a7 100644
--- a/llvm/test/Analysis/CostModel/ARM/mve-cmp.ll
+++ b/llvm/test/Analysis/CostModel/ARM/mve-cmp.ll
@@ -22,6 +22,8 @@ define void @icmp() {
 ; CHECK-NEXT:  Cost Model: Found an estimated cost of 36 for instruction: %v2i64 = icmp slt <2 x i64> undef, undef
 ; CHECK-NEXT:  Cost Model: Found an estimated cost of 72 for instruction: %v4i64 = icmp slt <4 x i64> undef, undef
 ; CHECK-NEXT:  Cost Model: Found an estimated cost of 144 for instruction: %v8i64 = icmp slt <8 x i64> undef, undef
+; CHECK-NEXT:  Cost Model: Found an estimated cost of 68 for instruction: %v2i128 = icmp slt <2 x i128> undef, undef
+; CHECK-NEXT:  Cost Model: Found an estimated cost of 136 for instruction: %v4i128 = icmp slt <4 x i128> undef, undef
 ; CHECK-NEXT:  Cost Model: Found an estimated cost of 0 for instruction: ret void
 ;
   %v2i8 = icmp slt <2 x i8> undef, undef
@@ -44,6 +46,9 @@ define void @icmp() {
   %v4i64 = icmp slt <4 x i64> undef, undef
   %v8i64 = icmp slt <8 x i64> undef, undef
 
+  %v2i128 = icmp slt <2 x i128> undef, undef
+  %v4i128 = icmp slt <4 x i128> undef, undef
+
   ret void
 }
 

From 086365be7ce0aaeb159fa80d02c426989d5115f3 Mon Sep 17 00:00:00 2001
From: Fangrui Song <i@maskray.me>
Date: Sun, 2 Oct 2022 00:47:10 -0700
Subject: [PATCH 19/84] [test] Make Linux/sem_init_glibc.cpp robust

and fix it for 32-bit ports defining sem_init@GLIBC_2.0 (i386, mips32, powerpc32) for glibc>=2.36.

Fix https://github.com/llvm/llvm-project/issues/58079

Reviewed By: mgorny

Differential Revision: https://reviews.llvm.org/D135023

(cherry picked from commit 6f46ff3765dcdc178b9cf52ebd8c03437806798a)
---
 .../sanitizer_common_interceptors.inc         |  2 +-
 .../TestCases/Linux/sem_init_glibc.cpp        | 43 +++++++++----------
 2 files changed, 21 insertions(+), 24 deletions(-)

diff --git a/compiler-rt/lib/sanitizer_common/sanitizer_common_interceptors.inc b/compiler-rt/lib/sanitizer_common/sanitizer_common_interceptors.inc
index 9af296b1853a9f..b29665a633907d 100644
--- a/compiler-rt/lib/sanitizer_common/sanitizer_common_interceptors.inc
+++ b/compiler-rt/lib/sanitizer_common/sanitizer_common_interceptors.inc
@@ -6703,7 +6703,7 @@ INTERCEPTOR(int, sem_init, __sanitizer_sem_t *s, int pshared, unsigned value) {
   COMMON_INTERCEPTOR_ENTER(ctx, sem_init, s, pshared, value);
   // Workaround a bug in glibc's "old" semaphore implementation by
   // zero-initializing the sem_t contents. This has to be done here because
-  // interceptors bind to the lowest symbols version by default, hitting the
+  // interceptors bind to the lowest version before glibc 2.36, hitting the
   // buggy code path while the non-sanitized build of the same code works fine.
   REAL(memset)(s, 0, sizeof(*s));
   int res = REAL(sem_init)(s, pshared, value);
diff --git a/compiler-rt/test/sanitizer_common/TestCases/Linux/sem_init_glibc.cpp b/compiler-rt/test/sanitizer_common/TestCases/Linux/sem_init_glibc.cpp
index d623ccabb5b55e..234c5019f69200 100644
--- a/compiler-rt/test/sanitizer_common/TestCases/Linux/sem_init_glibc.cpp
+++ b/compiler-rt/test/sanitizer_common/TestCases/Linux/sem_init_glibc.cpp
@@ -1,39 +1,36 @@
 // RUN: %clangxx -O0 -g %s -lutil -o %t && %run %t
 // This test depends on the glibc layout of struct sem_t and checks that we
 // don't leave sem_t::private uninitialized.
-// UNSUPPORTED: android, lsan-x86, ubsan, target-is-mips64, target-is-mips64el
+// UNSUPPORTED: android, lsan-x86, ubsan
 #include <features.h>
 #include <assert.h>
 #include <semaphore.h>
 #include <string.h>
 #include <stdint.h>
 
-// On powerpc64be semval_t must be 64 bits even with "old" versions of glibc.
-#if __PPC64__ && __BIG_ENDIAN__
-typedef uint64_t semval_t;
-
-// This condition needs to correspond to __HAVE_64B_ATOMICS macro in glibc.
-#elif (defined(__x86_64__) || defined(__aarch64__) || defined(__powerpc64__) || \
-     defined(__s390x__) || defined(__sparc64__) || defined(__alpha__) || \
-     defined(__ia64__) || defined(__m68k__)) && __GLIBC_PREREQ(2, 21)
-typedef uint64_t semval_t;
-#else
+// musl and glibc's __HAVE_64B_ATOMICS==0 ports (e.g. arm, i386) use 32-bit sem
+// values. 64-bit glibc ports defining sem_init@GLIBC_2.0 (mips64) use 32-bit as
+// well, if the sem_init interceptor picks the oldest versioned symbol
+// (glibc<2.36, see https://sourceware.org/PR14932).
+#if !defined(__GLIBC__) || defined(__ILP32__) ||                               \
+    !__GLIBC_PREREQ(2, 36) && defined(__mips64__)
 typedef unsigned semval_t;
+#else
+typedef uint64_t semval_t;
 #endif
 
-// glibc 2.21 has introduced some changes in the way the semaphore value is
-// handled for 32-bit platforms, but since these changes are not ABI-breaking
-// they are not versioned. On newer platforms such as ARM, there is only one
-// version of the symbol, so it's enough to check the glibc version. However,
-// for old platforms such as i386, glibc contains two or even three versions of
-// the sem_init symbol, and the sanitizers always pick the oldest one.
-// Therefore, it is not enough to rely on the __GLIBC_PREREQ macro - we should
-// instead check the platform as well to make sure we only expect the new
-// behavior on platforms where the older symbols do not exist.
-#if defined(__arm__) && __GLIBC_PREREQ(2, 21)
-#define GET_SEM_VALUE(V) ((V) >> 1)
+// glibc __HAVE_64B_ATOMICS==0 ports define a sem_init which shifts the value by
+// 1 (https://sourceware.org/PR12674 glibc 2.21). The version is picked if
+// either glibc>=2.36 or sem_init@GLIBC_2.0 is absent (arm and newer ports).
+//
+// The __GLIBC_PREREQ check is brittle in that it requires matched
+// __GLIBC_PREREQ values for build time and run time.
+#if defined(__GLIBC__) && defined(__ILP32__) &&                                \
+    (__GLIBC_PREREQ(2, 36) || (__GLIBC_PREREQ(2, 21) && !defined(__i386__) &&  \
+                               !defined(__mips__) && !defined(__powerpc__)))
+#  define GET_SEM_VALUE(V) ((V) >> 1)
 #else
-#define GET_SEM_VALUE(V) (V)
+#  define GET_SEM_VALUE(V) (V)
 #endif
 
 void my_sem_init(bool priv, int value, semval_t *a, unsigned char *b) {

From ceee53ce564c3034ea9636b3c416182efadc5967 Mon Sep 17 00:00:00 2001
From: Arthur Eubanks <aeubanks@google.com>
Date: Mon, 17 Oct 2022 17:03:35 -0700
Subject: [PATCH 20/84] [SROA] Don't speculate phis with different load user
 types

Fixes an SROA crash.

Fallout from opaque pointers since with typed pointers we'd bail out at the bitcast.

Reviewed By: nikic

Differential Revision: https://reviews.llvm.org/D136119

(cherry picked from commit 6219ec07c6f8d1ead51beca7cf21fbf2323c51d7)
---
 llvm/lib/Transforms/Scalar/SROA.cpp           | 19 +++++----
 .../phi-speculate-different-load-types.ll     | 41 +++++++++++++++++++
 2 files changed, 53 insertions(+), 7 deletions(-)
 create mode 100644 llvm/test/Transforms/SROA/phi-speculate-different-load-types.ll

diff --git a/llvm/lib/Transforms/Scalar/SROA.cpp b/llvm/lib/Transforms/Scalar/SROA.cpp
index 143a035749c752..644c5c82e58e67 100644
--- a/llvm/lib/Transforms/Scalar/SROA.cpp
+++ b/llvm/lib/Transforms/Scalar/SROA.cpp
@@ -1210,8 +1210,7 @@ static bool isSafePHIToSpeculate(PHINode &PN) {
   BasicBlock *BB = PN.getParent();
   Align MaxAlign;
   uint64_t APWidth = DL.getIndexTypeSizeInBits(PN.getType());
-  APInt MaxSize(APWidth, 0);
-  bool HaveLoad = false;
+  Type *LoadType = nullptr;
   for (User *U : PN.users()) {
     LoadInst *LI = dyn_cast<LoadInst>(U);
     if (!LI || !LI->isSimple())
@@ -1223,21 +1222,27 @@ static bool isSafePHIToSpeculate(PHINode &PN) {
     if (LI->getParent() != BB)
       return false;
 
+    if (LoadType) {
+      if (LoadType != LI->getType())
+        return false;
+    } else {
+      LoadType = LI->getType();
+    }
+
     // Ensure that there are no instructions between the PHI and the load that
     // could store.
     for (BasicBlock::iterator BBI(PN); &*BBI != LI; ++BBI)
       if (BBI->mayWriteToMemory())
         return false;
 
-    uint64_t Size = DL.getTypeStoreSize(LI->getType()).getFixedSize();
     MaxAlign = std::max(MaxAlign, LI->getAlign());
-    MaxSize = MaxSize.ult(Size) ? APInt(APWidth, Size) : MaxSize;
-    HaveLoad = true;
   }
 
-  if (!HaveLoad)
+  if (!LoadType)
     return false;
 
+  APInt LoadSize = APInt(APWidth, DL.getTypeStoreSize(LoadType).getFixedSize());
+
   // We can only transform this if it is safe to push the loads into the
   // predecessor blocks. The only thing to watch out for is that we can't put
   // a possibly trapping load in the predecessor if it is a critical edge.
@@ -1259,7 +1264,7 @@ static bool isSafePHIToSpeculate(PHINode &PN) {
     // If this pointer is always safe to load, or if we can prove that there
     // is already a load in the block, then we can move the load to the pred
     // block.
-    if (isSafeToLoadUnconditionally(InVal, MaxAlign, MaxSize, DL, TI))
+    if (isSafeToLoadUnconditionally(InVal, MaxAlign, LoadSize, DL, TI))
       continue;
 
     return false;
diff --git a/llvm/test/Transforms/SROA/phi-speculate-different-load-types.ll b/llvm/test/Transforms/SROA/phi-speculate-different-load-types.ll
new file mode 100644
index 00000000000000..7893da340736f1
--- /dev/null
+++ b/llvm/test/Transforms/SROA/phi-speculate-different-load-types.ll
@@ -0,0 +1,41 @@
+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
+; RUN: opt -passes=sroa < %s -S | FileCheck %s
+
+define void @f(i1 %i) {
+; CHECK-LABEL: @f(
+; CHECK-NEXT:    [[A1:%.*]] = alloca i64, align 8
+; CHECK-NEXT:    [[A2:%.*]] = alloca i64, align 8
+; CHECK-NEXT:    br i1 [[I:%.*]], label [[BB1:%.*]], label [[BB:%.*]]
+; CHECK:       bb:
+; CHECK-NEXT:    br label [[BB2:%.*]]
+; CHECK:       bb1:
+; CHECK-NEXT:    br label [[BB2]]
+; CHECK:       bb2:
+; CHECK-NEXT:    [[TMP3:%.*]] = phi ptr [ [[A1]], [[BB1]] ], [ [[A2]], [[BB]] ]
+; CHECK-NEXT:    [[TMP5:%.*]] = load i32, ptr [[TMP3]], align 4
+; CHECK-NEXT:    [[TMP4:%.*]] = load i64, ptr [[TMP3]], align 4
+; CHECK-NEXT:    call void @use32(i32 [[TMP5]])
+; CHECK-NEXT:    call void @use64(i64 [[TMP4]])
+; CHECK-NEXT:    ret void
+;
+  %a1 = alloca i64
+  %a2 = alloca i64
+  br i1 %i, label %bb1, label %bb
+
+bb:
+  br label %bb2
+
+bb1:
+  br label %bb2
+
+bb2:
+  %tmp3 = phi ptr [ %a1, %bb1 ], [ %a2, %bb ]
+  %tmp5 = load i32, ptr %tmp3
+  %tmp4 = load i64, ptr %tmp3
+  call void @use32(i32 %tmp5)
+  call void @use64(i64 %tmp4)
+  ret void
+}
+
+declare void @use32(i32)
+declare void @use64(i64)

From 455e1d765ad6379c98a499917d16fc8d31da3b2a Mon Sep 17 00:00:00 2001
From: Mike Hommey <mh@glandium.org>
Date: Sun, 23 Oct 2022 09:49:16 +0200
Subject: [PATCH 21/84] [InstCombine] Bail out of casting calls when a
 conversion from/to byval is involved.

Fixes #58307

Reviewed By: nikic

Differential Revision: https://reviews.llvm.org/D135738

(cherry picked from commit 86e57e66da9380eaa90a9d0830d7f2c5fe87af99)
---
 .../InstCombine/InstCombineCalls.cpp          |  4 +++
 llvm/test/Transforms/InstCombine/byval.ll     |  3 +-
 .../test/Transforms/InstCombine/cast-byval.ll | 31 +++++++++++++++++++
 3 files changed, 36 insertions(+), 2 deletions(-)
 create mode 100644 llvm/test/Transforms/InstCombine/cast-byval.ll

diff --git a/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp b/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp
index bc01d2ef7fe206..52596b30494fa3 100644
--- a/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp
+++ b/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp
@@ -3289,6 +3289,10 @@ bool InstCombinerImpl::transformConstExprCastCall(CallBase &Call) {
     if (CallerPAL.hasParamAttr(i, Attribute::SwiftError))
       return false;
 
+    if (CallerPAL.hasParamAttr(i, Attribute::ByVal) !=
+        Callee->getAttributes().hasParamAttr(i, Attribute::ByVal))
+      return false; // Cannot transform to or from byval.
+
     // If the parameter is passed as a byval argument, then we have to have a
     // sized type and the sized type has to have the same size as the old type.
     if (ParamTy != ActTy && CallerPAL.hasParamAttr(i, Attribute::ByVal)) {
diff --git a/llvm/test/Transforms/InstCombine/byval.ll b/llvm/test/Transforms/InstCombine/byval.ll
index e62bbe21c80691..45750869524bb0 100644
--- a/llvm/test/Transforms/InstCombine/byval.ll
+++ b/llvm/test/Transforms/InstCombine/byval.ll
@@ -7,8 +7,7 @@ declare void @add_byval_callee_2(double* byval(double))
 
 define void @add_byval(i64* %in) {
 ; CHECK-LABEL: @add_byval(
-; CHECK-NEXT:    [[TMP1:%.*]] = bitcast i64* [[IN:%.*]] to double*
-; CHECK-NEXT:    call void @add_byval_callee(double* byval(double) [[TMP1]])
+; CHECK-NEXT:    call void bitcast (void (double*)* @add_byval_callee to void (i64*)*)(i64* byval(i64) [[IN:%.*]])
 ; CHECK-NEXT:    ret void
 ;
   %tmp = bitcast void (double*)* @add_byval_callee to void (i64*)*
diff --git a/llvm/test/Transforms/InstCombine/cast-byval.ll b/llvm/test/Transforms/InstCombine/cast-byval.ll
new file mode 100644
index 00000000000000..b3e3055837c246
--- /dev/null
+++ b/llvm/test/Transforms/InstCombine/cast-byval.ll
@@ -0,0 +1,31 @@
+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
+; Check that function calls involving conversion from/to byval aren't transformed.
+; RUN: opt < %s -passes=instcombine -S | FileCheck %s
+
+%Foo = type { i64 }
+define i64 @foo (ptr byval(%Foo) %foo) {
+; CHECK-LABEL: @foo(
+; CHECK-NEXT:    [[TMP1:%.*]] = load i64, ptr [[FOO:%.*]], align 4
+; CHECK-NEXT:    ret i64 [[TMP1]]
+;
+  %1 = load i64, ptr %foo, align 4
+  ret i64 %1
+}
+
+define i64 @bar(i64 %0) {
+; CHECK-LABEL: @bar(
+; CHECK-NEXT:    [[TMP2:%.*]] = tail call i64 @foo(i64 [[TMP0:%.*]])
+; CHECK-NEXT:    ret i64 [[TMP2]]
+;
+  %2 = tail call i64 @foo(i64 %0)
+  ret i64 %2
+}
+
+define i64 @qux(ptr byval(%Foo) %qux) {
+; CHECK-LABEL: @qux(
+; CHECK-NEXT:    [[TMP1:%.*]] = tail call i64 @bar(ptr nonnull byval([[FOO:%.*]]) [[QUX:%.*]])
+; CHECK-NEXT:    ret i64 [[TMP1]]
+;
+  %1 = tail call i64 @bar(ptr byval(%Foo) %qux)
+  ret i64 %1
+}

From 5388da13992c133de7ff510705564ae2d4b1a264 Mon Sep 17 00:00:00 2001
From: Tobias Hieta <tobias@hieta.se>
Date: Mon, 24 Oct 2022 13:45:36 +0200
Subject: [PATCH 22/84] Bump version to 15.0.4

---
 libcxx/include/__config                                     | 2 +-
 llvm/CMakeLists.txt                                         | 2 +-
 llvm/utils/gn/secondary/llvm/version.gni                    | 2 +-
 llvm/utils/lit/lit/__init__.py                              | 2 +-
 utils/bazel/llvm-project-overlay/clang/BUILD.bazel          | 6 +++---
 .../clang/include/clang/Config/config.h                     | 2 +-
 utils/bazel/llvm-project-overlay/lld/BUILD.bazel            | 2 +-
 .../llvm/include/llvm/Config/llvm-config.h                  | 4 ++--
 8 files changed, 11 insertions(+), 11 deletions(-)

diff --git a/libcxx/include/__config b/libcxx/include/__config
index 589b5c3b2241e0..810189c94a94c4 100644
--- a/libcxx/include/__config
+++ b/libcxx/include/__config
@@ -36,7 +36,7 @@
 
 #ifdef __cplusplus
 
-#  define _LIBCPP_VERSION 15003
+#  define _LIBCPP_VERSION 15004
 
 #  define _LIBCPP_CONCAT_IMPL(_X, _Y) _X##_Y
 #  define _LIBCPP_CONCAT(_X, _Y) _LIBCPP_CONCAT_IMPL(_X, _Y)
diff --git a/llvm/CMakeLists.txt b/llvm/CMakeLists.txt
index 1a45f2eff0130f..3d6f5e6f9d3dae 100644
--- a/llvm/CMakeLists.txt
+++ b/llvm/CMakeLists.txt
@@ -22,7 +22,7 @@ if(NOT DEFINED LLVM_VERSION_MINOR)
   set(LLVM_VERSION_MINOR 0)
 endif()
 if(NOT DEFINED LLVM_VERSION_PATCH)
-  set(LLVM_VERSION_PATCH 3)
+  set(LLVM_VERSION_PATCH 4)
 endif()
 if(NOT DEFINED LLVM_VERSION_SUFFIX)
   set(LLVM_VERSION_SUFFIX)
diff --git a/llvm/utils/gn/secondary/llvm/version.gni b/llvm/utils/gn/secondary/llvm/version.gni
index 6d64da0180dff7..3b890e00bec321 100644
--- a/llvm/utils/gn/secondary/llvm/version.gni
+++ b/llvm/utils/gn/secondary/llvm/version.gni
@@ -1,4 +1,4 @@
 llvm_version_major = 15
 llvm_version_minor = 0
-llvm_version_patch = 3
+llvm_version_patch = 4
 llvm_version = "$llvm_version_major.$llvm_version_minor.$llvm_version_patch"
diff --git a/llvm/utils/lit/lit/__init__.py b/llvm/utils/lit/lit/__init__.py
index 5cb7ccdc67dabb..04f6e94535e42d 100644
--- a/llvm/utils/lit/lit/__init__.py
+++ b/llvm/utils/lit/lit/__init__.py
@@ -2,7 +2,7 @@
 
 __author__ = 'Daniel Dunbar'
 __email__ = 'daniel@minormatter.com'
-__versioninfo__ = (15, 0, 3)
+__versioninfo__ = (15, 0, 4)
 __version__ = '.'.join(str(v) for v in __versioninfo__) + 'dev'
 
 __all__ = []
diff --git a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
index 6cb8889bf50ff5..96b462717be9a8 100644
--- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
@@ -358,11 +358,11 @@ genrule(
     name = "basic_version_gen",
     outs = ["include/clang/Basic/Version.inc"],
     cmd = (
-        "echo '#define CLANG_VERSION 15.0.3' >> $@\n" +
+        "echo '#define CLANG_VERSION 15.0.4' >> $@\n" +
         "echo '#define CLANG_VERSION_MAJOR 15' >> $@\n" +
         "echo '#define CLANG_VERSION_MINOR 0' >> $@\n" +
-        "echo '#define CLANG_VERSION_PATCHLEVEL 3' >> $@\n" +
-        "echo '#define CLANG_VERSION_STRING \"15.0.3\"' >> $@\n"
+        "echo '#define CLANG_VERSION_PATCHLEVEL 4' >> $@\n" +
+        "echo '#define CLANG_VERSION_STRING \"15.0.4\"' >> $@\n"
     ),
 )
 
diff --git a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
index cedeb0a2c9511a..5d157492eae377 100644
--- a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
+++ b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
@@ -93,7 +93,7 @@
 /* CLANG_HAVE_RLIMITS defined conditionally below */
 
 /* The LLVM product name and version */
-#define BACKEND_PACKAGE_STRING "LLVM 15.0.3"
+#define BACKEND_PACKAGE_STRING "LLVM 15.0.4"
 
 /* Linker version detected at compile time. */
 /* #undef HOST_LINK_VERSION */
diff --git a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
index 139298d1533f32..e3a8c98ffa2288 100644
--- a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
@@ -13,7 +13,7 @@ package(
 genrule(
     name = "config_version_gen",
     outs = ["include/lld/Common/Version.inc"],
-    cmd = "echo '#define LLD_VERSION_STRING \"15.0.3\"' > $@",
+    cmd = "echo '#define LLD_VERSION_STRING \"15.0.4\"' > $@",
 )
 
 genrule(
diff --git a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
index 37bb4cf22a8903..7a86202e8e0d5d 100644
--- a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
+++ b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
@@ -80,10 +80,10 @@
 #define LLVM_VERSION_MINOR 0
 
 /* Patch version of the LLVM API */
-#define LLVM_VERSION_PATCH 3
+#define LLVM_VERSION_PATCH 4
 
 /* LLVM version string */
-#define LLVM_VERSION_STRING "15.0.3"
+#define LLVM_VERSION_STRING "15.0.4"
 
 /* Whether LLVM records statistics for use with GetStatistics(),
  * PrintStatistics() or PrintStatisticsJSON()

From 5834fe66318b55a54024fd93f69ab801a4c61d33 Mon Sep 17 00:00:00 2001
From: Nikita Popov <npopov@redhat.com>
Date: Fri, 21 Oct 2022 11:05:53 +0200
Subject: [PATCH 23/84] [AutoUpgrade] Fix remangling when upgrading struct
 return type

This was remangling the old function rather than the new one, and
could result in failures when we were performing both a struct
return upgrade and an opaque pointer upgrade.

(cherry picked from commit c8938809d155682ef5eec170897b8c26b8cbf3ea)
---
 llvm/lib/IR/AutoUpgrade.cpp                   |  2 +-
 .../opaque-ptr-intrinsic-remangling.ll        | 19 +++++++++++++++++++
 2 files changed, 20 insertions(+), 1 deletion(-)

diff --git a/llvm/lib/IR/AutoUpgrade.cpp b/llvm/lib/IR/AutoUpgrade.cpp
index 75594f90c926bf..b9962da1d3026b 100644
--- a/llvm/lib/IR/AutoUpgrade.cpp
+++ b/llvm/lib/IR/AutoUpgrade.cpp
@@ -1040,7 +1040,7 @@ static bool UpgradeIntrinsicFunction1(Function *F, Function *&NewFn) {
                                Name, F->getParent());
 
       // The new function may also need remangling.
-      if (auto Result = llvm::Intrinsic::remangleIntrinsicFunction(F))
+      if (auto Result = llvm::Intrinsic::remangleIntrinsicFunction(NewFn))
         NewFn = *Result;
       return true;
     }
diff --git a/llvm/test/Assembler/opaque-ptr-intrinsic-remangling.ll b/llvm/test/Assembler/opaque-ptr-intrinsic-remangling.ll
index c885897f315558..04638b0ddac92e 100644
--- a/llvm/test/Assembler/opaque-ptr-intrinsic-remangling.ll
+++ b/llvm/test/Assembler/opaque-ptr-intrinsic-remangling.ll
@@ -3,6 +3,8 @@
 
 ; Make sure that opaque pointer intrinsic remangling upgrade works.
 
+%int8x16x2_t = type { <16 x i8>, <16 x i8> }
+
 declare i32* @fake_personality_function()
 declare void @func()
 
@@ -43,5 +45,22 @@ define i8* @test_ptr_annotation(i8* %p) {
   ret i8* %p2
 }
 
+
+define void @test_struct_return(%int8x16x2_t* %res.p, i8* %a) {
+; CHECK-LABEL: @test_struct_return(
+; CHECK-NEXT:    [[TMP1:%.*]] = call { <16 x i8>, <16 x i8> } @llvm.aarch64.neon.ld1x2.v16i8.p0(ptr [[A:%.*]])
+; CHECK-NEXT:    [[TMP2:%.*]] = extractvalue { <16 x i8>, <16 x i8> } [[TMP1]], 0
+; CHECK-NEXT:    [[TMP3:%.*]] = insertvalue [[INT8X16X2_T:%.*]] poison, <16 x i8> [[TMP2]], 0
+; CHECK-NEXT:    [[TMP4:%.*]] = extractvalue { <16 x i8>, <16 x i8> } [[TMP1]], 1
+; CHECK-NEXT:    [[TMP5:%.*]] = insertvalue [[INT8X16X2_T]] [[TMP3]], <16 x i8> [[TMP4]], 1
+; CHECK-NEXT:    store [[INT8X16X2_T]] [[TMP5]], ptr [[RES_P:%.*]], align 16
+; CHECK-NEXT:    ret void
+;
+  %res = call %int8x16x2_t @llvm.aarch64.neon.ld1x2.v16i8.p0i8(i8* %a)
+  store %int8x16x2_t %res, %int8x16x2_t* %res.p
+  ret void
+}
+
 declare token @llvm.experimental.gc.statepoint.p0f_isVoidf(i64, i32, void ()*, i32, i32, ...)
 declare i8* @llvm.ptr.annotation.p0i8(i8*, i8*, i8*, i32, i8*)
+declare %int8x16x2_t @llvm.aarch64.neon.ld1x2.v16i8.p0i8(i8*)

From dccd0613025a6284e2a2296a56099b00a9dadcfe Mon Sep 17 00:00:00 2001
From: Fangrui Song <i@maskray.me>
Date: Fri, 21 Oct 2022 09:43:25 -0700
Subject: [PATCH 24/84] [ELF] Suppress "duplicate symbol" when resolving
 STB_WEAK and STB_GNU_UNIQUE in different COMDATs

```
template <typename T> struct A {
  A() {}
  int value = 0;
};

template <typename Value> struct B {
  static A<int> a;
};

template <typename Value> A<int> B<Value>::a;

inline int foo() {
  return B<int>::a.value;
}
```

```
clang++ -c -fno-pic a.cc -o weak.o
g++ -c -fno-pic a.cc -o unique.o  # --enable-gnu-unique-object

# Duplicate symbol error. In postParse, we do not check `sym.binding`
ld.lld -e 0 weak.o unique.o
```

Mixing GCC and Clang object files in this case is not ideal. .bss._ZGVN1BIiE1aE
has different COMDAT groups. It appears to work in practice because the guard
variable prevents harm due to double initialization.

For the linker, we just stick with the rule that a weak binding does not cause
"duplicate symbol" errors.

Close https://github.com/llvm/llvm-project/issues/58232

Differential Revision: https://reviews.llvm.org/D136381

(cherry picked from commit 0051b6bb78772b0658f28e5f31ddf91c1589aab5)
---
 lld/ELF/InputFiles.cpp         |  2 +-
 lld/test/ELF/comdat-binding2.s | 42 ++++++++++++++++++++++++++++++++++
 2 files changed, 43 insertions(+), 1 deletion(-)
 create mode 100644 lld/test/ELF/comdat-binding2.s

diff --git a/lld/ELF/InputFiles.cpp b/lld/ELF/InputFiles.cpp
index 927dc272b53269..473809b05e9c2a 100644
--- a/lld/ELF/InputFiles.cpp
+++ b/lld/ELF/InputFiles.cpp
@@ -1157,7 +1157,7 @@ template <class ELFT> void ObjFile<ELFT>::postParse() {
       continue;
     }
 
-    if (binding == STB_WEAK)
+    if (sym.binding == STB_WEAK || binding == STB_WEAK)
       continue;
     std::lock_guard<std::mutex> lock(mu);
     ctx->duplicates.push_back({&sym, this, sec, eSym.st_value});
diff --git a/lld/test/ELF/comdat-binding2.s b/lld/test/ELF/comdat-binding2.s
new file mode 100644
index 00000000000000..3ffd7252836c9b
--- /dev/null
+++ b/lld/test/ELF/comdat-binding2.s
@@ -0,0 +1,42 @@
+# REQUIRES: x86
+## Test we don't report duplicate definition errors when mixing Clang STB_WEAK
+## and GCC STB_GNU_UNIQUE symbols.
+
+# RUN: rm -rf %t && split-file %s %t && cd %t
+# RUN: llvm-mc -filetype=obj -triple=x86_64 weak.s -o weak.o
+# RUN: llvm-mc -filetype=obj -triple=x86_64 unique.s -o unique.o
+# RUN: ld.lld weak.o unique.o -o weak
+# RUN: llvm-readelf -s weak | FileCheck %s --check-prefix=WEAK
+# RUN: ld.lld unique.o weak.o -o unique
+# RUN: llvm-readelf -s unique | FileCheck %s --check-prefix=UNIQUE
+
+# WEAK:   OBJECT  WEAK   DEFAULT [[#]] _ZN1BIiE1aE
+# UNIQUE: OBJECT  UNIQUE DEFAULT [[#]] _ZN1BIiE1aE
+
+#--- weak.s
+## Clang
+	.type	_ZN1BIiE1aE,@object
+	.section	.bss._ZN1BIiE1aE,"aGwR",@nobits,_ZN1BIiE1aE,comdat
+	.weak	_ZN1BIiE1aE
+_ZN1BIiE1aE:
+	.zero	4
+
+	.type	_ZGVN1BIiE1aE,@object
+	.section	.bss._ZGVN1BIiE1aE,"aGw",@nobits,_ZN1BIiE1aE,comdat
+	.weak	_ZGVN1BIiE1aE
+_ZGVN1BIiE1aE:
+	.quad	0
+
+#--- unique.s
+## GCC -fgnu-unique. Note the different group signature for the second group.
+	.weak	_ZN1BIiE1aE
+	.section	.bss._ZN1BIiE1aE,"awG",@nobits,_ZN1BIiE1aE,comdat
+	.type	_ZN1BIiE1aE, @gnu_unique_object
+_ZN1BIiE1aE:
+	.zero	4
+
+	.weak	_ZGVN1BIiE1aE
+	.section	.bss._ZGVN1BIiE1aE,"awG",@nobits,_ZGVN1BIiE1aE,comdat
+	.type	_ZGVN1BIiE1aE, @gnu_unique_object
+_ZGVN1BIiE1aE:
+	.zero	8

From 1e1c5204c25914951fbda55af5593056586e6b6f Mon Sep 17 00:00:00 2001
From: Tom Stellard <tstellar@redhat.com>
Date: Mon, 24 Oct 2022 14:48:32 -0700
Subject: [PATCH 25/84] [SystemZ] Relase notes for LLVM 15

Unfortunately these notes were compiled until now, but these are the release notes for SystemZ.

(Did not find anything under clang)

@tstellar Should I push this patch onto release/15.x once approved, or will you apply it?

Differential Revision: https://reviews.llvm.org/D134430
---
 llvm/docs/ReleaseNotes.rst | 14 ++++++++++++++
 1 file changed, 14 insertions(+)

diff --git a/llvm/docs/ReleaseNotes.rst b/llvm/docs/ReleaseNotes.rst
index 9324d26cbdd819..0660bc134652b5 100644
--- a/llvm/docs/ReleaseNotes.rst
+++ b/llvm/docs/ReleaseNotes.rst
@@ -227,6 +227,20 @@ Changes to the WebAssembly Backend
 
 * ...
 
+Changes to the SystemZ Backend
+------------------------------
+
+* Support z16 processor name.
+* Machine scheduler description for z16.
+* Add support for inline assembly address operands ("p") as well as for SystemZ
+  specific address operands ("ZQ", "ZR", "ZS" and "ZT").
+* Efficient handling of small memcpy/memset operations up to 32 bytes.
+* Tuning of the inliner.
+* Fixing emission of library calls so that narrow integer arguments are sign or
+  zero extended per the SystemZ ABI.
+* Support added for libunwind.
+* Various minor improvements and bugfixes.
+
 Changes to the X86 Backend
 --------------------------
 

From 2d5c43ad484482cd23794b8b056a9b13ee920369 Mon Sep 17 00:00:00 2001
From: Jonas Devlieghere <jonas@devlieghere.com>
Date: Tue, 16 Aug 2022 17:53:34 -0700
Subject: [PATCH 26/84] [lldb]  Automatically unwrap parameter packs in
 template argument accessors

When looking at template arguments in LLDB, we usually care about what
the user passed in his code, not whether some of those arguments where
passed as a variadic parameter pack.

This patch extends all the C++ APIs to look at template parameters to
take an additional 'expand_pack' boolean that automatically unwraps the
potential argument packs. The equivalent SBAPI calls have been changed
to pass true for this parameter.

A byproduct of the patch is to also fix the support for template type
that have only a parameter pack as argument (like the OnlyPack type in
the test). Those were not recognized as template instanciations before.

The added test verifies that the SBAPI is able to iterate over the
arguments of a variadic template.

The original patch was written by Fred Riss almost 4 years ago.

Differential revision: https://reviews.llvm.org/D51387

(cherry picked from commit b706f56133a77f9d7c55270ac24ff59e6fce3fa4)
---
 lldb/include/lldb/API/SBType.h                |  2 +
 lldb/include/lldb/Symbol/CompilerType.h       | 24 ++++--
 lldb/include/lldb/Symbol/TypeSystem.h         | 14 ++--
 lldb/source/API/SBType.cpp                    | 12 ++-
 .../TypeSystem/Clang/TypeSystemClang.cpp      | 81 ++++++++++++++-----
 .../TypeSystem/Clang/TypeSystemClang.h        | 19 ++---
 lldb/source/Symbol/CompilerType.cpp           | 18 +++--
 lldb/source/Symbol/TypeSystem.cpp             | 12 +--
 .../TestTemplatePackArgs.py                   | 38 +++++++++
 .../class-template-parameter-pack/main.cpp    |  8 +-
 lldb/unittests/Symbol/TestTypeSystemClang.cpp | 30 ++++---
 11 files changed, 190 insertions(+), 68 deletions(-)
 create mode 100644 lldb/test/API/lang/cpp/class-template-parameter-pack/TestTemplatePackArgs.py

diff --git a/lldb/include/lldb/API/SBType.h b/lldb/include/lldb/API/SBType.h
index 244d328b51f43a..aa45aeeec476dd 100644
--- a/lldb/include/lldb/API/SBType.h
+++ b/lldb/include/lldb/API/SBType.h
@@ -182,6 +182,8 @@ class SBType {
 
   lldb::SBType GetTemplateArgumentType(uint32_t idx);
 
+  /// Return the TemplateArgumentKind of the template argument at index idx.
+  /// Variadic argument packs are automatically expanded.
   lldb::TemplateArgumentKind GetTemplateArgumentKind(uint32_t idx);
 
   lldb::SBType GetFunctionReturnType();
diff --git a/lldb/include/lldb/Symbol/CompilerType.h b/lldb/include/lldb/Symbol/CompilerType.h
index 0ad05a27570e9a..aefd19d0a85952 100644
--- a/lldb/include/lldb/Symbol/CompilerType.h
+++ b/lldb/include/lldb/Symbol/CompilerType.h
@@ -338,14 +338,28 @@ class CompilerType {
   GetIndexOfChildMemberWithName(const char *name, bool omit_empty_base_classes,
                                 std::vector<uint32_t> &child_indexes) const;
 
-  size_t GetNumTemplateArguments() const;
-
-  lldb::TemplateArgumentKind GetTemplateArgumentKind(size_t idx) const;
-  CompilerType GetTypeTemplateArgument(size_t idx) const;
+  /// Return the number of template arguments the type has.
+  /// If expand_pack is true, then variadic argument packs are automatically
+  /// expanded to their supplied arguments. If it is false an argument pack
+  /// will only count as 1 argument.
+  size_t GetNumTemplateArguments(bool expand_pack = false) const;
+
+  // Return the TemplateArgumentKind of the template argument at index idx.
+  // If expand_pack is true, then variadic argument packs are automatically
+  // expanded to their supplied arguments. With expand_pack set to false, an
+  // arguement pack will count as 1 argument and return a type of Pack.
+  lldb::TemplateArgumentKind
+  GetTemplateArgumentKind(size_t idx, bool expand_pack = false) const;
+  CompilerType GetTypeTemplateArgument(size_t idx,
+                                       bool expand_pack = false) const;
 
   /// Returns the value of the template argument and its type.
+  /// If expand_pack is true, then variadic argument packs are automatically
+  /// expanded to their supplied arguments. With expand_pack set to false, an
+  /// arguement pack will count as 1 argument and it is invalid to call this
+  /// method on the pack argument.
   llvm::Optional<IntegralTemplateArgument>
-  GetIntegralTemplateArgument(size_t idx) const;
+  GetIntegralTemplateArgument(size_t idx, bool expand_pack = false) const;
 
   CompilerType GetTypeForFormatters() const;
 
diff --git a/lldb/include/lldb/Symbol/TypeSystem.h b/lldb/include/lldb/Symbol/TypeSystem.h
index be578359689745..769449a4933b26 100644
--- a/lldb/include/lldb/Symbol/TypeSystem.h
+++ b/lldb/include/lldb/Symbol/TypeSystem.h
@@ -346,14 +346,18 @@ class TypeSystem : public PluginInterface {
                                 const char *name, bool omit_empty_base_classes,
                                 std::vector<uint32_t> &child_indexes) = 0;
 
-  virtual size_t GetNumTemplateArguments(lldb::opaque_compiler_type_t type);
+  virtual size_t GetNumTemplateArguments(lldb::opaque_compiler_type_t type,
+                                         bool expand_pack);
 
   virtual lldb::TemplateArgumentKind
-  GetTemplateArgumentKind(lldb::opaque_compiler_type_t type, size_t idx);
-  virtual CompilerType GetTypeTemplateArgument(lldb::opaque_compiler_type_t type,
-                                           size_t idx);
+  GetTemplateArgumentKind(lldb::opaque_compiler_type_t type, size_t idx,
+                          bool expand_pack);
+  virtual CompilerType
+  GetTypeTemplateArgument(lldb::opaque_compiler_type_t type, size_t idx,
+                          bool expand_pack);
   virtual llvm::Optional<CompilerType::IntegralTemplateArgument>
-  GetIntegralTemplateArgument(lldb::opaque_compiler_type_t type, size_t idx);
+  GetIntegralTemplateArgument(lldb::opaque_compiler_type_t type, size_t idx,
+                              bool expand_pack);
 
   // Dumping types
 
diff --git a/lldb/source/API/SBType.cpp b/lldb/source/API/SBType.cpp
index 533930c0544bdb..adc60a084367de 100644
--- a/lldb/source/API/SBType.cpp
+++ b/lldb/source/API/SBType.cpp
@@ -542,7 +542,8 @@ uint32_t SBType::GetNumberOfTemplateArguments() {
   LLDB_INSTRUMENT_VA(this);
 
   if (IsValid())
-    return m_opaque_sp->GetCompilerType(false).GetNumTemplateArguments();
+    return m_opaque_sp->GetCompilerType(false).GetNumTemplateArguments(
+        /*expand_pack=*/true);
   return 0;
 }
 
@@ -553,13 +554,15 @@ lldb::SBType SBType::GetTemplateArgumentType(uint32_t idx) {
     return SBType();
 
   CompilerType type;
+  const bool expand_pack = true;
   switch(GetTemplateArgumentKind(idx)) {
     case eTemplateArgumentKindType:
-      type = m_opaque_sp->GetCompilerType(false).GetTypeTemplateArgument(idx);
+      type = m_opaque_sp->GetCompilerType(false).GetTypeTemplateArgument(
+          idx, expand_pack);
       break;
     case eTemplateArgumentKindIntegral:
       type = m_opaque_sp->GetCompilerType(false)
-                 .GetIntegralTemplateArgument(idx)
+                 .GetIntegralTemplateArgument(idx, expand_pack)
                  ->type;
       break;
     default:
@@ -574,7 +577,8 @@ lldb::TemplateArgumentKind SBType::GetTemplateArgumentKind(uint32_t idx) {
   LLDB_INSTRUMENT_VA(this, idx);
 
   if (IsValid())
-    return m_opaque_sp->GetCompilerType(false).GetTemplateArgumentKind(idx);
+    return m_opaque_sp->GetCompilerType(false).GetTemplateArgumentKind(
+        idx, /*expand_pack=*/true);
   return eTemplateArgumentKindNull;
 }
 
diff --git a/lldb/source/Plugins/TypeSystem/Clang/TypeSystemClang.cpp b/lldb/source/Plugins/TypeSystem/Clang/TypeSystemClang.cpp
index c6eb693bba6b85..a1ebe5830bb951 100644
--- a/lldb/source/Plugins/TypeSystem/Clang/TypeSystemClang.cpp
+++ b/lldb/source/Plugins/TypeSystem/Clang/TypeSystemClang.cpp
@@ -7096,7 +7096,8 @@ TypeSystemClang::GetIndexOfChildWithName(lldb::opaque_compiler_type_t type,
 }
 
 size_t
-TypeSystemClang::GetNumTemplateArguments(lldb::opaque_compiler_type_t type) {
+TypeSystemClang::GetNumTemplateArguments(lldb::opaque_compiler_type_t type,
+                                         bool expand_pack) {
   if (!type)
     return 0;
 
@@ -7111,8 +7112,17 @@ TypeSystemClang::GetNumTemplateArguments(lldb::opaque_compiler_type_t type) {
         const clang::ClassTemplateSpecializationDecl *template_decl =
             llvm::dyn_cast<clang::ClassTemplateSpecializationDecl>(
                 cxx_record_decl);
-        if (template_decl)
-          return template_decl->getTemplateArgs().size();
+        if (template_decl) {
+          const auto &template_arg_list = template_decl->getTemplateArgs();
+          size_t num_args = template_arg_list.size();
+          assert(num_args && "template specialization without any args");
+          if (expand_pack && num_args) {
+            const auto &pack = template_arg_list[num_args - 1];
+            if (pack.getKind() == clang::TemplateArgument::Pack)
+              num_args += pack.pack_size() - 1;
+          }
+          return num_args;
+        }
       }
     }
     break;
@@ -7149,15 +7159,51 @@ TypeSystemClang::GetAsTemplateSpecialization(
   }
 }
 
+const TemplateArgument *
+GetNthTemplateArgument(const clang::ClassTemplateSpecializationDecl *decl,
+                       size_t idx, bool expand_pack) {
+  const auto &args = decl->getTemplateArgs();
+  const size_t args_size = args.size();
+
+  assert(args_size && "template specialization without any args");
+  if (!args_size)
+    return nullptr;
+
+  const size_t last_idx = args_size - 1;
+
+  // We're asked for a template argument that can't be a parameter pack, so
+  // return it without worrying about 'expand_pack'.
+  if (idx < last_idx)
+    return &args[idx];
+
+  // We're asked for the last template argument but we don't want/need to
+  // expand it.
+  if (!expand_pack || args[last_idx].getKind() != clang::TemplateArgument::Pack)
+    return idx >= args.size() ? nullptr : &args[idx];
+
+  // Index into the expanded pack.
+  // Note that 'idx' counts from the beginning of all template arguments
+  // (including the ones preceding the parameter pack).
+  const auto &pack = args[last_idx];
+  const size_t pack_idx = idx - last_idx;
+  const size_t pack_size = pack.pack_size();
+  assert(pack_idx < pack_size && "parameter pack index out-of-bounds");
+  return &pack.pack_elements()[pack_idx];
+}
+
 lldb::TemplateArgumentKind
 TypeSystemClang::GetTemplateArgumentKind(lldb::opaque_compiler_type_t type,
-                                         size_t arg_idx) {
+                                         size_t arg_idx, bool expand_pack) {
   const clang::ClassTemplateSpecializationDecl *template_decl =
       GetAsTemplateSpecialization(type);
-  if (! template_decl || arg_idx >= template_decl->getTemplateArgs().size())
+  if (!template_decl)
+    return eTemplateArgumentKindNull;
+
+  const auto *arg = GetNthTemplateArgument(template_decl, arg_idx, expand_pack);
+  if (!arg)
     return eTemplateArgumentKindNull;
 
-  switch (template_decl->getTemplateArgs()[arg_idx].getKind()) {
+  switch (arg->getKind()) {
   case clang::TemplateArgument::Null:
     return eTemplateArgumentKindNull;
 
@@ -7190,35 +7236,32 @@ TypeSystemClang::GetTemplateArgumentKind(lldb::opaque_compiler_type_t type,
 
 CompilerType
 TypeSystemClang::GetTypeTemplateArgument(lldb::opaque_compiler_type_t type,
-                                         size_t idx) {
+                                         size_t idx, bool expand_pack) {
   const clang::ClassTemplateSpecializationDecl *template_decl =
       GetAsTemplateSpecialization(type);
-  if (!template_decl || idx >= template_decl->getTemplateArgs().size())
+  if (!template_decl)
     return CompilerType();
 
-  const clang::TemplateArgument &template_arg =
-      template_decl->getTemplateArgs()[idx];
-  if (template_arg.getKind() != clang::TemplateArgument::Type)
+  const auto *arg = GetNthTemplateArgument(template_decl, idx, expand_pack);
+  if (!arg || arg->getKind() != clang::TemplateArgument::Type)
     return CompilerType();
 
-  return GetType(template_arg.getAsType());
+  return GetType(arg->getAsType());
 }
 
 Optional<CompilerType::IntegralTemplateArgument>
 TypeSystemClang::GetIntegralTemplateArgument(lldb::opaque_compiler_type_t type,
-                                             size_t idx) {
+                                             size_t idx, bool expand_pack) {
   const clang::ClassTemplateSpecializationDecl *template_decl =
       GetAsTemplateSpecialization(type);
-  if (! template_decl || idx >= template_decl->getTemplateArgs().size())
+  if (!template_decl)
     return llvm::None;
 
-  const clang::TemplateArgument &template_arg =
-      template_decl->getTemplateArgs()[idx];
-  if (template_arg.getKind() != clang::TemplateArgument::Integral)
+  const auto *arg = GetNthTemplateArgument(template_decl, idx, expand_pack);
+  if (!arg || arg->getKind() != clang::TemplateArgument::Integral)
     return llvm::None;
 
-  return {
-      {template_arg.getAsIntegral(), GetType(template_arg.getIntegralType())}};
+  return {{arg->getAsIntegral(), GetType(arg->getIntegralType())}};
 }
 
 CompilerType TypeSystemClang::GetTypeForFormatters(void *type) {
diff --git a/lldb/source/Plugins/TypeSystem/Clang/TypeSystemClang.h b/lldb/source/Plugins/TypeSystem/Clang/TypeSystemClang.h
index 24dbb71c8f4d13..7f25a6df548fb3 100644
--- a/lldb/source/Plugins/TypeSystem/Clang/TypeSystemClang.h
+++ b/lldb/source/Plugins/TypeSystem/Clang/TypeSystemClang.h
@@ -91,7 +91,7 @@ class TypePayloadClang {
   void SetOwningModule(OptionalClangModuleID id);
   /// \}
 };
-  
+
 /// A TypeSystem implementation based on Clang.
 ///
 /// This class uses a single clang::ASTContext as the backend for storing
@@ -334,7 +334,7 @@ class TypeSystemClang : public TypeSystem {
 
     llvm::SmallVector<const char *, 2> names;
     llvm::SmallVector<clang::TemplateArgument, 2> args;
-    
+
     const char * pack_name = nullptr;
     std::unique_ptr<TemplateParameterInfos> packed_args;
   };
@@ -537,7 +537,7 @@ class TypeSystemClang : public TypeSystem {
 #ifndef NDEBUG
   bool Verify(lldb::opaque_compiler_type_t type) override;
 #endif
-  
+
   bool IsArrayType(lldb::opaque_compiler_type_t type,
                    CompilerType *element_type, uint64_t *size,
                    bool *is_incomplete) override;
@@ -810,16 +810,17 @@ class TypeSystemClang : public TypeSystem {
                                 const char *name, bool omit_empty_base_classes,
                                 std::vector<uint32_t> &child_indexes) override;
 
-  size_t GetNumTemplateArguments(lldb::opaque_compiler_type_t type) override;
+  size_t GetNumTemplateArguments(lldb::opaque_compiler_type_t type,
+                                 bool expand_pack) override;
 
   lldb::TemplateArgumentKind
-  GetTemplateArgumentKind(lldb::opaque_compiler_type_t type,
-                          size_t idx) override;
+  GetTemplateArgumentKind(lldb::opaque_compiler_type_t type, size_t idx,
+                          bool expand_pack) override;
   CompilerType GetTypeTemplateArgument(lldb::opaque_compiler_type_t type,
-                                       size_t idx) override;
+                                       size_t idx, bool expand_pack) override;
   llvm::Optional<CompilerType::IntegralTemplateArgument>
-  GetIntegralTemplateArgument(lldb::opaque_compiler_type_t type,
-                              size_t idx) override;
+  GetIntegralTemplateArgument(lldb::opaque_compiler_type_t type, size_t idx,
+                              bool expand_pack) override;
 
   CompilerType GetTypeForFormatters(void *type) override;
 
diff --git a/lldb/source/Symbol/CompilerType.cpp b/lldb/source/Symbol/CompilerType.cpp
index ac98352c235ebf..bef456583687ce 100644
--- a/lldb/source/Symbol/CompilerType.cpp
+++ b/lldb/source/Symbol/CompilerType.cpp
@@ -659,30 +659,32 @@ size_t CompilerType::GetIndexOfChildMemberWithName(
   return 0;
 }
 
-size_t CompilerType::GetNumTemplateArguments() const {
+size_t CompilerType::GetNumTemplateArguments(bool expand_pack) const {
   if (IsValid()) {
-    return m_type_system->GetNumTemplateArguments(m_type);
+    return m_type_system->GetNumTemplateArguments(m_type, expand_pack);
   }
   return 0;
 }
 
-TemplateArgumentKind CompilerType::GetTemplateArgumentKind(size_t idx) const {
+TemplateArgumentKind
+CompilerType::GetTemplateArgumentKind(size_t idx, bool expand_pack) const {
   if (IsValid())
-    return m_type_system->GetTemplateArgumentKind(m_type, idx);
+    return m_type_system->GetTemplateArgumentKind(m_type, idx, expand_pack);
   return eTemplateArgumentKindNull;
 }
 
-CompilerType CompilerType::GetTypeTemplateArgument(size_t idx) const {
+CompilerType CompilerType::GetTypeTemplateArgument(size_t idx,
+                                                   bool expand_pack) const {
   if (IsValid()) {
-    return m_type_system->GetTypeTemplateArgument(m_type, idx);
+    return m_type_system->GetTypeTemplateArgument(m_type, idx, expand_pack);
   }
   return CompilerType();
 }
 
 llvm::Optional<CompilerType::IntegralTemplateArgument>
-CompilerType::GetIntegralTemplateArgument(size_t idx) const {
+CompilerType::GetIntegralTemplateArgument(size_t idx, bool expand_pack) const {
   if (IsValid())
-    return m_type_system->GetIntegralTemplateArgument(m_type, idx);
+    return m_type_system->GetIntegralTemplateArgument(m_type, idx, expand_pack);
   return llvm::None;
 }
 
diff --git a/lldb/source/Symbol/TypeSystem.cpp b/lldb/source/Symbol/TypeSystem.cpp
index 3092dc0bf0a4fa..412373533aabac 100644
--- a/lldb/source/Symbol/TypeSystem.cpp
+++ b/lldb/source/Symbol/TypeSystem.cpp
@@ -118,23 +118,25 @@ CompilerType TypeSystem::GetTypeForFormatters(void *type) {
   return CompilerType(this, type);
 }
 
-size_t TypeSystem::GetNumTemplateArguments(lldb::opaque_compiler_type_t type) {
+size_t TypeSystem::GetNumTemplateArguments(lldb::opaque_compiler_type_t type,
+                                           bool expand_pack) {
   return 0;
 }
 
 TemplateArgumentKind
-TypeSystem::GetTemplateArgumentKind(opaque_compiler_type_t type, size_t idx) {
+TypeSystem::GetTemplateArgumentKind(opaque_compiler_type_t type, size_t idx,
+                                    bool expand_pack) {
   return eTemplateArgumentKindNull;
 }
 
 CompilerType TypeSystem::GetTypeTemplateArgument(opaque_compiler_type_t type,
-                                                 size_t idx) {
+                                                 size_t idx, bool expand_pack) {
   return CompilerType();
 }
 
 llvm::Optional<CompilerType::IntegralTemplateArgument>
-TypeSystem::GetIntegralTemplateArgument(opaque_compiler_type_t type,
-                                        size_t idx) {
+TypeSystem::GetIntegralTemplateArgument(opaque_compiler_type_t type, size_t idx,
+                                        bool expand_pack) {
   return llvm::None;
 }
 
diff --git a/lldb/test/API/lang/cpp/class-template-parameter-pack/TestTemplatePackArgs.py b/lldb/test/API/lang/cpp/class-template-parameter-pack/TestTemplatePackArgs.py
new file mode 100644
index 00000000000000..180d3f503c4f29
--- /dev/null
+++ b/lldb/test/API/lang/cpp/class-template-parameter-pack/TestTemplatePackArgs.py
@@ -0,0 +1,38 @@
+"""
+Test that the type of arguments to C++ template classes that have variadic
+parameters can be enumerated.
+"""
+import lldb
+from lldbsuite.test.decorators import *
+from lldbsuite.test.lldbtest import *
+from lldbsuite.test import lldbutil
+
+
+class TemplatePackArgsTestCase(TestBase):
+
+    mydir = TestBase.compute_mydir(__file__)
+
+    def test_template_argument_pack(self):
+        self.build()
+        (_, _, thread, _) = lldbutil.run_to_source_breakpoint(self,
+          'breakpoint here', lldb.SBFileSpec('main.cpp'), exe_name = 'a.out')
+        frame = thread.GetSelectedFrame()
+
+        empty_pack = frame.FindVariable('emptyPack')
+        self.assertTrue(empty_pack.IsValid(),
+                        'make sure we find the emptyPack variable')
+
+        only_pack = frame.FindVariable('onlyPack')
+        self.assertTrue(only_pack.IsValid(),
+                        'make sure we find the onlyPack variable')
+        self.assertEqual(only_pack.GetType().GetNumberOfTemplateArguments(), 4)
+        self.assertEqual(only_pack.GetType().GetTemplateArgumentType(0).GetName(), 'int')
+        self.assertEqual(only_pack.GetType().GetTemplateArgumentType(1).GetName(), 'char')
+        self.assertEqual(only_pack.GetType().GetTemplateArgumentType(2).GetName(), 'double')
+        # Access the C<double, 42> template parameter.
+        nested_template = only_pack.GetType().GetTemplateArgumentType(3)
+        self.assertEqual(nested_template.GetName(), 'D<int, int, bool>')
+        self.assertEqual(nested_template.GetNumberOfTemplateArguments(), 3)
+        self.assertEqual(nested_template.GetTemplateArgumentType(0).GetName(), 'int')
+        self.assertEqual(nested_template.GetTemplateArgumentType(1).GetName(), 'int')
+        self.assertEqual(nested_template.GetTemplateArgumentType(2).GetName(), 'bool')
diff --git a/lldb/test/API/lang/cpp/class-template-parameter-pack/main.cpp b/lldb/test/API/lang/cpp/class-template-parameter-pack/main.cpp
index 8bb0a42b58a3af..26f8eab545c86a 100644
--- a/lldb/test/API/lang/cpp/class-template-parameter-pack/main.cpp
+++ b/lldb/test/API/lang/cpp/class-template-parameter-pack/main.cpp
@@ -26,7 +26,13 @@ template <> struct D<int, int, bool> : D<int, int> {
   bool argsAre_Int_bool() { return true; }
 };
 
+template <typename... Args> struct OnlyPack {};
+template <typename T, typename... Args> struct EmptyPack {};
+
 int main(int argc, char const *argv[]) {
+  EmptyPack<int> emptyPack;
+  OnlyPack<int, char, double, D<int, int, bool>> onlyPack;
+
   C<int, 16, 32> myC;
   C<int, 16> myLesserC;
   myC.member = 64;
@@ -34,7 +40,7 @@ int main(int argc, char const *argv[]) {
   (void)C<int, 16>().argsAre_16_32();
   (void)(myC.member != 64);
   D<int, int, bool> myD;
-  D<int, int> myLesserD;
+  D<int, int> myLesserD; // breakpoint here
   myD.member = 64;
   (void)D<int, int, bool>().argsAre_Int_bool();
   (void)D<int, int>().argsAre_Int_bool();
diff --git a/lldb/unittests/Symbol/TestTypeSystemClang.cpp b/lldb/unittests/Symbol/TestTypeSystemClang.cpp
index e78a084f59f081..4da17cf3610cd1 100644
--- a/lldb/unittests/Symbol/TestTypeSystemClang.cpp
+++ b/lldb/unittests/Symbol/TestTypeSystemClang.cpp
@@ -500,18 +500,24 @@ TEST_F(TestTypeSystemClang, TemplateArguments) {
   for (CompilerType t : {type, typedef_type, auto_type}) {
     SCOPED_TRACE(t.GetTypeName().AsCString());
 
-    EXPECT_EQ(m_ast->GetTemplateArgumentKind(t.GetOpaqueQualType(), 0),
-              eTemplateArgumentKindType);
-    EXPECT_EQ(m_ast->GetTypeTemplateArgument(t.GetOpaqueQualType(), 0),
-              int_type);
-    EXPECT_EQ(llvm::None,
-              m_ast->GetIntegralTemplateArgument(t.GetOpaqueQualType(), 0));
-
-    EXPECT_EQ(m_ast->GetTemplateArgumentKind(t.GetOpaqueQualType(), 1),
-              eTemplateArgumentKindIntegral);
-    EXPECT_EQ(m_ast->GetTypeTemplateArgument(t.GetOpaqueQualType(), 1),
-              CompilerType());
-    auto result = m_ast->GetIntegralTemplateArgument(t.GetOpaqueQualType(), 1);
+    const bool expand_pack = false;
+    EXPECT_EQ(
+        m_ast->GetTemplateArgumentKind(t.GetOpaqueQualType(), 0, expand_pack),
+        eTemplateArgumentKindType);
+    EXPECT_EQ(
+        m_ast->GetTypeTemplateArgument(t.GetOpaqueQualType(), 0, expand_pack),
+        int_type);
+    EXPECT_EQ(llvm::None, m_ast->GetIntegralTemplateArgument(
+                              t.GetOpaqueQualType(), 0, expand_pack));
+
+    EXPECT_EQ(
+        m_ast->GetTemplateArgumentKind(t.GetOpaqueQualType(), 1, expand_pack),
+        eTemplateArgumentKindIntegral);
+    EXPECT_EQ(
+        m_ast->GetTypeTemplateArgument(t.GetOpaqueQualType(), 1, expand_pack),
+        CompilerType());
+    auto result = m_ast->GetIntegralTemplateArgument(t.GetOpaqueQualType(), 1,
+                                                     expand_pack);
     ASSERT_NE(llvm::None, result);
     EXPECT_EQ(arg, result->value);
     EXPECT_EQ(int_type, result->type);

From db68723804fd30d5e7da1fb2ad2aab409ef58d29 Mon Sep 17 00:00:00 2001
From: Tom Praschan <13141438+tom-anders@users.noreply.github.com>
Date: Sun, 18 Sep 2022 18:48:11 +0200
Subject: [PATCH 27/84] [clangd] Return earlier when snippet is empty

Fixes github.com/clangd/clangd/issues/1216

If the Snippet string is empty, Snippet.front() would trigger a crash.
Move the Snippet->empty() check up a few lines to avoid this. Should not
break any existing behavior.

Differential Revision: https://reviews.llvm.org/D134137

(cherry picked from commit 60528c690a4c334d2a3a2c22eb97af9e67d7a91d)
---
 clang-tools-extra/clangd/CodeComplete.cpp       |  5 +++--
 .../clangd/unittests/CodeCompleteTests.cpp      | 17 +++++++++++++++++
 2 files changed, 20 insertions(+), 2 deletions(-)

diff --git a/clang-tools-extra/clangd/CodeComplete.cpp b/clang-tools-extra/clangd/CodeComplete.cpp
index edbb1722ae38e6..55982f41250f5e 100644
--- a/clang-tools-extra/clangd/CodeComplete.cpp
+++ b/clang-tools-extra/clangd/CodeComplete.cpp
@@ -486,6 +486,9 @@ struct CodeCompletionBuilder {
       // we need to complete 'forward<$1>($0)'.
       return "($0)";
 
+    if (Snippet->empty())
+      return "";
+
     bool MayHaveArgList = Completion.Kind == CompletionItemKind::Function ||
                           Completion.Kind == CompletionItemKind::Method ||
                           Completion.Kind == CompletionItemKind::Constructor ||
@@ -524,8 +527,6 @@ struct CodeCompletionBuilder {
       return *Snippet;
 
     // Replace argument snippets with a simplified pattern.
-    if (Snippet->empty())
-      return "";
     if (MayHaveArgList) {
       // Functions snippets can be of 2 types:
       // - containing only function arguments, e.g.
diff --git a/clang-tools-extra/clangd/unittests/CodeCompleteTests.cpp b/clang-tools-extra/clangd/unittests/CodeCompleteTests.cpp
index 5050ab203b8dbf..079a4ec70623c2 100644
--- a/clang-tools-extra/clangd/unittests/CodeCompleteTests.cpp
+++ b/clang-tools-extra/clangd/unittests/CodeCompleteTests.cpp
@@ -1014,6 +1014,23 @@ TEST(CodeCompleteTest, NoColonColonAtTheEnd) {
   EXPECT_THAT(Results.Completions, Not(Contains(labeled("clang::"))));
 }
 
+TEST(CompletionTests, EmptySnippetDoesNotCrash) {
+    // See https://github.com/clangd/clangd/issues/1216
+    auto Results = completions(R"cpp(
+        int main() {
+          auto w = [&](auto &&f) { return f(f); };
+          auto f = w([&](auto &&f) {
+            return [&](auto &&n) {
+              if (n == 0) {
+                return 1;
+              }
+              return n * ^(f)(n - 1);
+            };
+          })(10);
+        }
+    )cpp");
+}
+
 TEST(CompletionTest, BacktrackCrashes) {
   // Sema calls code completion callbacks twice in these cases.
   auto Results = completions(R"cpp(

From 3010b7e000006f680b6bf3141be988291fa1da41 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Timm=20B=C3=A4der?= <tbaeder@redhat.com>
Date: Fri, 21 Oct 2022 11:36:37 +0200
Subject: [PATCH 28/84] [clang][driver] Remove dynamic gcc-toolset/devtoolset
 logic

This breaks when the newest available devtoolset directory is not a
complete toolset: https://github.com/llvm/llvm-project/issues/57843

Remove this again in favor or just adding the two new directories for
devtoolset/gcc-toolset 12.

This reverts commit 35aaf548237a4f213ba9d95de53b33c5ce1eadce.
This reverts commit 9f97720268911abae2ad9d90e270358db234a1c1.

Fixes https://github.com/llvm/llvm-project/issues/57843

Differential Revision: https://reviews.llvm.org/D136435
---
 clang/lib/Driver/ToolChains/Gnu.cpp      | 40 ++++-------
 clang/unittests/Driver/ToolChainTest.cpp | 92 ------------------------
 2 files changed, 15 insertions(+), 117 deletions(-)

diff --git a/clang/lib/Driver/ToolChains/Gnu.cpp b/clang/lib/Driver/ToolChains/Gnu.cpp
index f203cae1d329ff..665cdc3132fb8f 100644
--- a/clang/lib/Driver/ToolChains/Gnu.cpp
+++ b/clang/lib/Driver/ToolChains/Gnu.cpp
@@ -2139,31 +2139,21 @@ void Generic_GCC::GCCInstallationDetector::AddDefaultGCCPrefixes(
   // and gcc-toolsets.
   if (SysRoot.empty() && TargetTriple.getOS() == llvm::Triple::Linux &&
       D.getVFS().exists("/opt/rh")) {
-    // Find the directory in /opt/rh/ starting with gcc-toolset-* or
-    // devtoolset-* with the highest version number and add that
-    // one to our prefixes.
-    std::string ChosenToolsetDir;
-    unsigned ChosenToolsetVersion = 0;
-    std::error_code EC;
-    for (llvm::vfs::directory_iterator LI = D.getVFS().dir_begin("/opt/rh", EC),
-                                       LE;
-         !EC && LI != LE; LI = LI.increment(EC)) {
-      StringRef ToolsetDir = llvm::sys::path::filename(LI->path());
-      unsigned ToolsetVersion;
-      if ((!ToolsetDir.startswith("gcc-toolset-") &&
-           !ToolsetDir.startswith("devtoolset-")) ||
-          ToolsetDir.substr(ToolsetDir.rfind('-') + 1)
-              .getAsInteger(10, ToolsetVersion))
-        continue;
-
-      if (ToolsetVersion > ChosenToolsetVersion) {
-        ChosenToolsetVersion = ToolsetVersion;
-        ChosenToolsetDir = "/opt/rh/" + ToolsetDir.str();
-      }
-    }
-
-    if (ChosenToolsetVersion > 0)
-      Prefixes.push_back(ChosenToolsetDir + "/root/usr");
+    // TODO: We may want to remove this, since the functionality
+    //   can be achieved using config files.
+    Prefixes.push_back("/opt/rh/gcc-toolset-12/root/usr");
+    Prefixes.push_back("/opt/rh/gcc-toolset-11/root/usr");
+    Prefixes.push_back("/opt/rh/gcc-toolset-10/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-12/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-11/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-10/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-9/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-8/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-7/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-6/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-4/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-3/root/usr");
+    Prefixes.push_back("/opt/rh/devtoolset-2/root/usr");
   }
 
   // Fall back to /usr which is used by most non-Solaris systems.
diff --git a/clang/unittests/Driver/ToolChainTest.cpp b/clang/unittests/Driver/ToolChainTest.cpp
index 64bc616523f059..c434dfcb3e86c4 100644
--- a/clang/unittests/Driver/ToolChainTest.cpp
+++ b/clang/unittests/Driver/ToolChainTest.cpp
@@ -18,7 +18,6 @@
 #include "clang/Driver/Driver.h"
 #include "llvm/ADT/ArrayRef.h"
 #include "llvm/MC/TargetRegistry.h"
-#include "llvm/Support/Host.h"
 #include "llvm/Support/TargetSelect.h"
 #include "llvm/Support/VirtualFileSystem.h"
 #include "llvm/Support/raw_ostream.h"
@@ -570,95 +569,4 @@ TEST(DxcModeTest, ValidatorVersionValidation) {
   Diags.Clear();
   DiagConsumer->clear();
 }
-
-TEST(ToolChainTest, Toolsets) {
-  // Ignore this test on Windows hosts.
-  llvm::Triple Host(llvm::sys::getProcessTriple());
-  if (Host.isOSWindows())
-    GTEST_SKIP();
-
-  IntrusiveRefCntPtr<DiagnosticOptions> DiagOpts = new DiagnosticOptions();
-  IntrusiveRefCntPtr<DiagnosticIDs> DiagID(new DiagnosticIDs());
-
-  // Check (newer) GCC toolset installation.
-  {
-    IntrusiveRefCntPtr<llvm::vfs::InMemoryFileSystem> InMemoryFileSystem(
-        new llvm::vfs::InMemoryFileSystem);
-
-    // These should be ignored.
-    InMemoryFileSystem->addFile("/opt/rh/gcc-toolset-2", 0,
-                                llvm::MemoryBuffer::getMemBuffer("\n"));
-    InMemoryFileSystem->addFile("/opt/rh/gcc-toolset-", 0,
-                                llvm::MemoryBuffer::getMemBuffer("\n"));
-    InMemoryFileSystem->addFile("/opt/rh/gcc-toolset--", 0,
-                                llvm::MemoryBuffer::getMemBuffer("\n"));
-    InMemoryFileSystem->addFile("/opt/rh/gcc-toolset--1", 0,
-                                llvm::MemoryBuffer::getMemBuffer("\n"));
-
-    // File needed for GCC installation detection.
-    InMemoryFileSystem->addFile("/opt/rh/gcc-toolset-12/root/usr/lib/gcc/"
-                                "x86_64-redhat-linux/11/crtbegin.o",
-                                0, llvm::MemoryBuffer::getMemBuffer("\n"));
-
-    DiagnosticsEngine Diags(DiagID, &*DiagOpts, new SimpleDiagnosticConsumer);
-    Driver TheDriver("/bin/clang", "x86_64-redhat-linux", Diags,
-                     "clang LLVM compiler", InMemoryFileSystem);
-    std::unique_ptr<Compilation> C(
-        TheDriver.BuildCompilation({"clang", "--gcc-toolchain="}));
-    ASSERT_TRUE(C);
-    std::string S;
-    {
-      llvm::raw_string_ostream OS(S);
-      C->getDefaultToolChain().printVerboseInfo(OS);
-    }
-    EXPECT_EQ("Found candidate GCC installation: "
-              "/opt/rh/gcc-toolset-12/root/usr/lib/gcc/x86_64-redhat-linux/11\n"
-              "Selected GCC installation: "
-              "/opt/rh/gcc-toolset-12/root/usr/lib/gcc/x86_64-redhat-linux/11\n"
-              "Candidate multilib: .;@m64\n"
-              "Selected multilib: .;@m64\n",
-              S);
-  }
-
-  // And older devtoolset.
-  {
-    IntrusiveRefCntPtr<llvm::vfs::InMemoryFileSystem> InMemoryFileSystem(
-        new llvm::vfs::InMemoryFileSystem);
-
-    // These should be ignored.
-    InMemoryFileSystem->addFile("/opt/rh/devtoolset-2", 0,
-                                llvm::MemoryBuffer::getMemBuffer("\n"));
-    InMemoryFileSystem->addFile("/opt/rh/devtoolset-", 0,
-                                llvm::MemoryBuffer::getMemBuffer("\n"));
-    InMemoryFileSystem->addFile("/opt/rh/devtoolset--", 0,
-                                llvm::MemoryBuffer::getMemBuffer("\n"));
-    InMemoryFileSystem->addFile("/opt/rh/devtoolset--1", 0,
-                                llvm::MemoryBuffer::getMemBuffer("\n"));
-
-    // File needed for GCC installation detection.
-    InMemoryFileSystem->addFile("/opt/rh/devtoolset-12/root/usr/lib/gcc/"
-                                "x86_64-redhat-linux/11/crtbegin.o",
-                                0, llvm::MemoryBuffer::getMemBuffer("\n"));
-
-    DiagnosticsEngine Diags(DiagID, &*DiagOpts, new SimpleDiagnosticConsumer);
-    Driver TheDriver("/bin/clang", "x86_64-redhat-linux", Diags,
-                     "clang LLVM compiler", InMemoryFileSystem);
-    std::unique_ptr<Compilation> C(
-        TheDriver.BuildCompilation({"clang", "--gcc-toolchain="}));
-    ASSERT_TRUE(C);
-    std::string S;
-    {
-      llvm::raw_string_ostream OS(S);
-      C->getDefaultToolChain().printVerboseInfo(OS);
-    }
-    EXPECT_EQ("Found candidate GCC installation: "
-              "/opt/rh/devtoolset-12/root/usr/lib/gcc/x86_64-redhat-linux/11\n"
-              "Selected GCC installation: "
-              "/opt/rh/devtoolset-12/root/usr/lib/gcc/x86_64-redhat-linux/11\n"
-              "Candidate multilib: .;@m64\n"
-              "Selected multilib: .;@m64\n",
-              S);
-  }
-}
-
 } // end anonymous namespace.

From dd711a9391226189476f23f793fb98e244d52a4b Mon Sep 17 00:00:00 2001
From: Jez Ng <jezng@fb.com>
Date: Tue, 11 Oct 2022 23:50:46 -0400
Subject: [PATCH 29/84] [lld-macho] Canonicalize personality pointers in EH
 frames

We already do this for personality pointers referenced from compact
unwind entries; this patch extends that behavior to personalities
referenced via EH frames as well.

This reduces the number of distinct personalities we need in the final
binary, and helps us avoid hitting the "too many personalities" error.

I renamed `UnwindInfoSection::prepareRelocations()` to simply `prepare`
since we now do some non-reloc-specific stuff within.

Fixes #58277.

Reviewed By: #lld-macho, oontvoo

Differential Revision: https://reviews.llvm.org/D135728

(cherry picked from commit 7b45dfc6811a52ff4e9a6054dc276d70d77fddaf)
---
 lld/MachO/UnwindInfoSection.cpp             | 35 ++++++++++++++---
 lld/MachO/UnwindInfoSection.h               |  2 +-
 lld/MachO/Writer.cpp                        |  2 +-
 lld/test/MachO/eh-frame-personality-dedup.s | 43 +++++++++++++++++++++
 4 files changed, 75 insertions(+), 7 deletions(-)
 create mode 100644 lld/test/MachO/eh-frame-personality-dedup.s

diff --git a/lld/MachO/UnwindInfoSection.cpp b/lld/MachO/UnwindInfoSection.cpp
index ca6cbdfbb8bb41..8f267251b7c0f0 100644
--- a/lld/MachO/UnwindInfoSection.cpp
+++ b/lld/MachO/UnwindInfoSection.cpp
@@ -158,7 +158,7 @@ class UnwindInfoSectionImpl final : public UnwindInfoSection {
 public:
   UnwindInfoSectionImpl() : cuOffsets(target->wordSize) {}
   uint64_t getSize() const override { return unwindInfoSize; }
-  void prepareRelocations() override;
+  void prepare() override;
   void finalize() override;
   void writeTo(uint8_t *buf) const override;
 
@@ -166,6 +166,7 @@ class UnwindInfoSectionImpl final : public UnwindInfoSection {
   void prepareRelocations(ConcatInputSection *);
   void relocateCompactUnwind(std::vector<CompactUnwindEntry> &);
   void encodePersonalities();
+  Symbol *canonicalizePersonality(Symbol *);
 
   uint64_t unwindInfoSize = 0;
   std::vector<decltype(symbols)::value_type> symbolsVec;
@@ -218,14 +219,24 @@ void UnwindInfoSection::addSymbol(const Defined *d) {
   }
 }
 
-void UnwindInfoSectionImpl::prepareRelocations() {
+void UnwindInfoSectionImpl::prepare() {
   // This iteration needs to be deterministic, since prepareRelocations may add
   // entries to the GOT. Hence the use of a MapVector for
   // UnwindInfoSection::symbols.
   for (const Defined *d : make_second_range(symbols))
-    if (d->unwindEntry &&
-        d->unwindEntry->getName() == section_names::compactUnwind)
-      prepareRelocations(d->unwindEntry);
+    if (d->unwindEntry) {
+      if (d->unwindEntry->getName() == section_names::compactUnwind) {
+        prepareRelocations(d->unwindEntry);
+      } else {
+        // We don't have to add entries to the GOT here because FDEs have
+        // explicit GOT relocations, so Writer::scanRelocations() will add those
+        // GOT entries. However, we still need to canonicalize the personality
+        // pointers (like prepareRelocations() does for CU entries) in order
+        // to avoid overflowing the 3-personality limit.
+        FDE &fde = cast<ObjFile>(d->getFile())->fdes[d->unwindEntry];
+        fde.personality = canonicalizePersonality(fde.personality);
+      }
+    }
 }
 
 // Compact unwind relocations have different semantics, so we handle them in a
@@ -279,6 +290,7 @@ void UnwindInfoSectionImpl::prepareRelocations(ConcatInputSection *isec) {
           continue;
       }
 
+      // Similar to canonicalizePersonality(), but we also register a GOT entry.
       if (auto *defined = dyn_cast<Defined>(s)) {
         // Check if we have created a synthetic symbol at the same address.
         Symbol *&personality =
@@ -291,6 +303,7 @@ void UnwindInfoSectionImpl::prepareRelocations(ConcatInputSection *isec) {
         }
         continue;
       }
+
       assert(isa<DylibSymbol>(s));
       in.got->addEntry(s);
       continue;
@@ -320,6 +333,18 @@ void UnwindInfoSectionImpl::prepareRelocations(ConcatInputSection *isec) {
   }
 }
 
+Symbol *UnwindInfoSectionImpl::canonicalizePersonality(Symbol *personality) {
+  if (auto *defined = dyn_cast_or_null<Defined>(personality)) {
+    // Check if we have created a synthetic symbol at the same address.
+    Symbol *&synth = personalityTable[{defined->isec, defined->value}];
+    if (synth == nullptr)
+      synth = defined;
+    else if (synth != defined)
+      return synth;
+  }
+  return personality;
+}
+
 // We need to apply the relocations to the pre-link compact unwind section
 // before converting it to post-link form. There should only be absolute
 // relocations here: since we are not emitting the pre-link CU section, there
diff --git a/lld/MachO/UnwindInfoSection.h b/lld/MachO/UnwindInfoSection.h
index c6b334731c75b0..f2bc3213a12757 100644
--- a/lld/MachO/UnwindInfoSection.h
+++ b/lld/MachO/UnwindInfoSection.h
@@ -24,7 +24,7 @@ class UnwindInfoSection : public SyntheticSection {
   // section entirely.
   bool isNeeded() const override { return !allEntriesAreOmitted; }
   void addSymbol(const Defined *);
-  virtual void prepareRelocations() = 0;
+  virtual void prepare() = 0;
 
 protected:
   UnwindInfoSection();
diff --git a/lld/MachO/Writer.cpp b/lld/MachO/Writer.cpp
index 3c44a60f4be262..ce9672dd0b4f67 100644
--- a/lld/MachO/Writer.cpp
+++ b/lld/MachO/Writer.cpp
@@ -675,7 +675,7 @@ void Writer::scanRelocations() {
     }
   }
 
-  in.unwindInfo->prepareRelocations();
+  in.unwindInfo->prepare();
 }
 
 void Writer::scanSymbols() {
diff --git a/lld/test/MachO/eh-frame-personality-dedup.s b/lld/test/MachO/eh-frame-personality-dedup.s
new file mode 100644
index 00000000000000..b14ddb23465def
--- /dev/null
+++ b/lld/test/MachO/eh-frame-personality-dedup.s
@@ -0,0 +1,43 @@
+# REQUIRES: x86
+# RUN: rm -rf %t; split-file %s %t
+# RUN: llvm-mc -filetype=obj -triple=x86_64-apple-darwin19.0.0 %t/eh-frame.s -o %t/eh-frame.o
+# RUN: llvm-mc -filetype=obj -triple=x86_64-apple-darwin19.0.0 %t/cu.s -o %t/cu.o
+# RUN: %lld -dylib %t/cu.o %t/eh-frame.o -o %t/out
+
+## Sanity check: we want our input to contain a section (and not symbol)
+## relocation for the personality reference.
+# RUN: llvm-readobj --relocations %t/cu.o | FileCheck %s --check-prefix=SECT-RELOC
+# SECT-RELOC:      Section __compact_unwind {
+# SECT-RELOC-NEXT:   __text
+# SECT-RELOC-NEXT:   __text
+# SECT-RELOC-NEXT: }
+
+## Verify that the personality referenced via a symbol reloc in eh-frame.s gets
+## dedup'ed with the personality referenced via a section reloc in cu.s.
+# RUN: llvm-objdump --macho --unwind-info %t/out | FileCheck %s
+# CHECK: Personality functions: (count = 1)
+
+#--- eh-frame.s
+_fun:
+  .cfi_startproc
+  .cfi_personality 155, _my_personality
+  ## cfi_escape cannot be encoded in compact unwind
+  .cfi_escape 0
+  ret
+  .cfi_endproc
+
+.subsections_via_symbols
+
+#--- cu.s
+.globl _my_personality
+_fun:
+  .cfi_startproc
+  .cfi_personality 155, _my_personality
+  .cfi_def_cfa_offset 16
+  ret
+  .cfi_endproc
+
+_my_personality:
+  nop
+
+.subsections_via_symbols

From 9d46557baa84ab4342707c119cf9c77c9148230e Mon Sep 17 00:00:00 2001
From: Guillaume Chatelet <gchatelet@google.com>
Date: Wed, 26 Oct 2022 09:34:34 +0000
Subject: [PATCH 30/84] Take memset_inline into account in
 analyzeLoadFromClobberingMemInst

This appeared in https://reviews.llvm.org/D126903#3884061

Differential Revision: https://reviews.llvm.org/D136752

(cherry picked from commit 1a726cfa83667585dd87a9955ed5e331cad45d18)
---
 llvm/lib/Transforms/Utils/VNCoercion.cpp | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/llvm/lib/Transforms/Utils/VNCoercion.cpp b/llvm/lib/Transforms/Utils/VNCoercion.cpp
index 42be67f3cfc058..264da2187754ad 100644
--- a/llvm/lib/Transforms/Utils/VNCoercion.cpp
+++ b/llvm/lib/Transforms/Utils/VNCoercion.cpp
@@ -356,9 +356,9 @@ int analyzeLoadFromClobberingMemInst(Type *LoadTy, Value *LoadPtr,
 
   // If this is memset, we just need to see if the offset is valid in the size
   // of the memset..
-  if (MI->getIntrinsicID() == Intrinsic::memset) {
+  if (const auto *memset_inst = dyn_cast<MemSetInst>(MI)) {
     if (DL.isNonIntegralPointerType(LoadTy->getScalarType())) {
-      auto *CI = dyn_cast<ConstantInt>(cast<MemSetInst>(MI)->getValue());
+      auto *CI = dyn_cast<ConstantInt>(memset_inst->getValue());
       if (!CI || !CI->isZero())
         return -1;
     }

From 08bd84e8a6358eb412fcef279f8875e2d69a3374 Mon Sep 17 00:00:00 2001
From: Koakuma <koachan@protonmail.com>
Date: Tue, 18 Oct 2022 00:01:55 +0000
Subject: [PATCH 31/84] [SPARC] Make calls to function with big return values
 work

Implement CanLowerReturn and associated CallingConv changes for SPARC/SPARC64.

In particular, for SPARC64 there's new `RetCC_Sparc64_*` functions that handles the return case of the calling convention.
It uses the same analysis as `CC_Sparc64_*` family of funtions, but fails if the return value doesn't fit into the return registers.

This makes calls to functions with big return values converted to an sret function as expected, instead of crashing LLVM.

Reviewed By: MaskRay

Differential Revision: https://reviews.llvm.org/D132465

(cherry picked from commit d3fcbee10d893b9e01e563c3840414ba89283484)
---
 .../SelectionDAG/SelectionDAGBuilder.cpp      |   1 +
 llvm/lib/Target/Sparc/SparcCallingConv.td     |  10 +-
 llvm/lib/Target/Sparc/SparcISelLowering.cpp   |  61 ++++-
 llvm/lib/Target/Sparc/SparcISelLowering.h     |   5 +
 llvm/test/CodeGen/SPARC/64abi.ll              |  27 --
 llvm/test/CodeGen/SPARC/bigreturn.ll          | 254 ++++++++++++++++++
 6 files changed, 322 insertions(+), 36 deletions(-)
 create mode 100644 llvm/test/CodeGen/SPARC/bigreturn.ll

diff --git a/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp b/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp
index 35650b9bd00e44..ecdaef0442dabf 100644
--- a/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp
+++ b/llvm/lib/CodeGen/SelectionDAG/SelectionDAGBuilder.cpp
@@ -9693,6 +9693,7 @@ TargetLowering::LowerCallTo(TargetLowering::CallLoweringInfo &CLI) const {
     Entry.Alignment = Alignment;
     CLI.getArgs().insert(CLI.getArgs().begin(), Entry);
     CLI.NumFixedArgs += 1;
+    CLI.getArgs()[0].IndirectType = CLI.RetTy;
     CLI.RetTy = Type::getVoidTy(CLI.RetTy->getContext());
 
     // sret demotion isn't compatible with tail-calls, since the sret argument
diff --git a/llvm/lib/Target/Sparc/SparcCallingConv.td b/llvm/lib/Target/Sparc/SparcCallingConv.td
index e6d23f741ea5f8..8afd0a7fc09ad2 100644
--- a/llvm/lib/Target/Sparc/SparcCallingConv.td
+++ b/llvm/lib/Target/Sparc/SparcCallingConv.td
@@ -125,10 +125,14 @@ def CC_Sparc64 : CallingConv<[
 def RetCC_Sparc64 : CallingConv<[
   // A single f32 return value always goes in %f0. The ABI doesn't specify what
   // happens to multiple f32 return values outside a struct.
-  CCIfType<[f32], CCCustom<"CC_Sparc64_Half">>,
+  CCIfType<[f32], CCCustom<"RetCC_Sparc64_Half">>,
 
-  // Otherwise, return values are passed exactly like arguments.
-  CCDelegateTo<CC_Sparc64>
+  // Otherwise, return values are passed exactly like arguments, except that
+  // returns that are too big to fit into the registers is passed as an sret
+  // instead.
+  CCIfInReg<CCIfType<[i32, f32], CCCustom<"RetCC_Sparc64_Half">>>,
+  CCIfType<[i32], CCPromoteToType<i64>>,
+  CCCustom<"RetCC_Sparc64_Full">
 ]>;
 
 // Callee-saved registers are handled by the register window mechanism.
diff --git a/llvm/lib/Target/Sparc/SparcISelLowering.cpp b/llvm/lib/Target/Sparc/SparcISelLowering.cpp
index 2cb74e7709c7b6..f5567508910284 100644
--- a/llvm/lib/Target/Sparc/SparcISelLowering.cpp
+++ b/llvm/lib/Target/Sparc/SparcISelLowering.cpp
@@ -101,9 +101,9 @@ static bool CC_Sparc_Assign_Ret_Split_64(unsigned &ValNo, MVT &ValVT,
 }
 
 // Allocate a full-sized argument for the 64-bit ABI.
-static bool CC_Sparc64_Full(unsigned &ValNo, MVT &ValVT,
-                            MVT &LocVT, CCValAssign::LocInfo &LocInfo,
-                            ISD::ArgFlagsTy &ArgFlags, CCState &State) {
+static bool Analyze_CC_Sparc64_Full(bool IsReturn, unsigned &ValNo, MVT &ValVT,
+                                    MVT &LocVT, CCValAssign::LocInfo &LocInfo,
+                                    ISD::ArgFlagsTy &ArgFlags, CCState &State) {
   assert((LocVT == MVT::f32 || LocVT == MVT::f128
           || LocVT.getSizeInBits() == 64) &&
          "Can't handle non-64 bits locations");
@@ -133,6 +133,11 @@ static bool CC_Sparc64_Full(unsigned &ValNo, MVT &ValVT,
     return true;
   }
 
+  // Bail out if this is a return CC and we run out of registers to place
+  // values into.
+  if (IsReturn)
+    return false;
+
   // This argument goes on the stack in an 8-byte slot.
   // When passing floats, LocVT is smaller than 8 bytes. Adjust the offset to
   // the right-aligned float. The first 4 bytes of the stack slot are undefined.
@@ -146,9 +151,9 @@ static bool CC_Sparc64_Full(unsigned &ValNo, MVT &ValVT,
 // Allocate a half-sized argument for the 64-bit ABI.
 //
 // This is used when passing { float, int } structs by value in registers.
-static bool CC_Sparc64_Half(unsigned &ValNo, MVT &ValVT,
-                            MVT &LocVT, CCValAssign::LocInfo &LocInfo,
-                            ISD::ArgFlagsTy &ArgFlags, CCState &State) {
+static bool Analyze_CC_Sparc64_Half(bool IsReturn, unsigned &ValNo, MVT &ValVT,
+                                    MVT &LocVT, CCValAssign::LocInfo &LocInfo,
+                                    ISD::ArgFlagsTy &ArgFlags, CCState &State) {
   assert(LocVT.getSizeInBits() == 32 && "Can't handle non-32 bits locations");
   unsigned Offset = State.AllocateStack(4, Align(4));
 
@@ -174,10 +179,43 @@ static bool CC_Sparc64_Half(unsigned &ValNo, MVT &ValVT,
     return true;
   }
 
+  // Bail out if this is a return CC and we run out of registers to place
+  // values into.
+  if (IsReturn)
+    return false;
+
   State.addLoc(CCValAssign::getMem(ValNo, ValVT, Offset, LocVT, LocInfo));
   return true;
 }
 
+static bool CC_Sparc64_Full(unsigned &ValNo, MVT &ValVT, MVT &LocVT,
+                            CCValAssign::LocInfo &LocInfo,
+                            ISD::ArgFlagsTy &ArgFlags, CCState &State) {
+  return Analyze_CC_Sparc64_Full(false, ValNo, ValVT, LocVT, LocInfo, ArgFlags,
+                                 State);
+}
+
+static bool CC_Sparc64_Half(unsigned &ValNo, MVT &ValVT, MVT &LocVT,
+                            CCValAssign::LocInfo &LocInfo,
+                            ISD::ArgFlagsTy &ArgFlags, CCState &State) {
+  return Analyze_CC_Sparc64_Half(false, ValNo, ValVT, LocVT, LocInfo, ArgFlags,
+                                 State);
+}
+
+static bool RetCC_Sparc64_Full(unsigned &ValNo, MVT &ValVT, MVT &LocVT,
+                               CCValAssign::LocInfo &LocInfo,
+                               ISD::ArgFlagsTy &ArgFlags, CCState &State) {
+  return Analyze_CC_Sparc64_Full(true, ValNo, ValVT, LocVT, LocInfo, ArgFlags,
+                                 State);
+}
+
+static bool RetCC_Sparc64_Half(unsigned &ValNo, MVT &ValVT, MVT &LocVT,
+                               CCValAssign::LocInfo &LocInfo,
+                               ISD::ArgFlagsTy &ArgFlags, CCState &State) {
+  return Analyze_CC_Sparc64_Half(true, ValNo, ValVT, LocVT, LocInfo, ArgFlags,
+                                 State);
+}
+
 #include "SparcGenCallingConv.inc"
 
 // The calling conventions in SparcCallingConv.td are described in terms of the
@@ -191,6 +229,15 @@ static unsigned toCallerWindow(unsigned Reg) {
   return Reg;
 }
 
+bool SparcTargetLowering::CanLowerReturn(
+    CallingConv::ID CallConv, MachineFunction &MF, bool isVarArg,
+    const SmallVectorImpl<ISD::OutputArg> &Outs, LLVMContext &Context) const {
+  SmallVector<CCValAssign, 16> RVLocs;
+  CCState CCInfo(CallConv, isVarArg, MF, RVLocs, Context);
+  return CCInfo.CheckReturn(Outs, Subtarget->is64Bit() ? RetCC_Sparc64
+                                                       : RetCC_Sparc32);
+}
+
 SDValue
 SparcTargetLowering::LowerReturn(SDValue Chain, CallingConv::ID CallConv,
                                  bool IsVarArg,
@@ -1031,6 +1078,7 @@ SparcTargetLowering::LowerCall_32(TargetLowering::CallLoweringInfo &CLI,
 
   // Copy all of the result registers out of their specified physreg.
   for (unsigned i = 0; i != RVLocs.size(); ++i) {
+    assert(RVLocs[i].isRegLoc() && "Can only return in registers!");
     if (RVLocs[i].getLocVT() == MVT::v2i32) {
       SDValue Vec = DAG.getNode(ISD::UNDEF, dl, MVT::v2i32);
       SDValue Lo = DAG.getCopyFromReg(
@@ -1346,6 +1394,7 @@ SparcTargetLowering::LowerCall_64(TargetLowering::CallLoweringInfo &CLI,
   // Copy all of the result registers out of their specified physreg.
   for (unsigned i = 0; i != RVLocs.size(); ++i) {
     CCValAssign &VA = RVLocs[i];
+    assert(VA.isRegLoc() && "Can only return in registers!");
     unsigned Reg = toCallerWindow(VA.getLocReg());
 
     // When returning 'inreg {i32, i32 }', two consecutive i32 arguments can
diff --git a/llvm/lib/Target/Sparc/SparcISelLowering.h b/llvm/lib/Target/Sparc/SparcISelLowering.h
index 2768bb20566a5c..16e4f26870548a 100644
--- a/llvm/lib/Target/Sparc/SparcISelLowering.h
+++ b/llvm/lib/Target/Sparc/SparcISelLowering.h
@@ -144,6 +144,11 @@ namespace llvm {
     SDValue LowerCall_64(TargetLowering::CallLoweringInfo &CLI,
                          SmallVectorImpl<SDValue> &InVals) const;
 
+    bool CanLowerReturn(CallingConv::ID CallConv, MachineFunction &MF,
+                        bool isVarArg,
+                        const SmallVectorImpl<ISD::OutputArg> &Outs,
+                        LLVMContext &Context) const override;
+
     SDValue LowerReturn(SDValue Chain, CallingConv::ID CallConv, bool isVarArg,
                         const SmallVectorImpl<ISD::OutputArg> &Outs,
                         const SmallVectorImpl<SDValue> &OutVals,
diff --git a/llvm/test/CodeGen/SPARC/64abi.ll b/llvm/test/CodeGen/SPARC/64abi.ll
index 6b181d8b343291..27865f718151ec 100644
--- a/llvm/test/CodeGen/SPARC/64abi.ll
+++ b/llvm/test/CodeGen/SPARC/64abi.ll
@@ -293,33 +293,6 @@ define void @call_inreg_ii(i32* %p, i32 %i1, i32 %i2) {
   ret void
 }
 
-; Structs up to 32 bytes in size can be returned in registers.
-; CHECK-LABEL: ret_i64_pair:
-; CHECK: ldx [%i2], %i0
-; CHECK: ldx [%i3], %i1
-define { i64, i64 } @ret_i64_pair(i32 %a0, i32 %a1, i64* %p, i64* %q) {
-  %r1 = load i64, i64* %p
-  %rv1 = insertvalue { i64, i64 } undef, i64 %r1, 0
-  store i64 0, i64* %p
-  %r2 = load i64, i64* %q
-  %rv2 = insertvalue { i64, i64 } %rv1, i64 %r2, 1
-  ret { i64, i64 } %rv2
-}
-
-; CHECK-LABEL: call_ret_i64_pair:
-; CHECK: call ret_i64_pair
-; CHECK: stx %o0, [%i0]
-; CHECK: stx %o1, [%i0]
-define void @call_ret_i64_pair(i64* %i0) {
-  %rv = call { i64, i64 } @ret_i64_pair(i32 undef, i32 undef,
-                                        i64* undef, i64* undef)
-  %e0 = extractvalue { i64, i64 } %rv, 0
-  store volatile i64 %e0, i64* %i0
-  %e1 = extractvalue { i64, i64 } %rv, 1
-  store i64 %e1, i64* %i0
-  ret void
-}
-
 ; This is not a C struct, the i32 member uses 8 bytes, but the float only 4.
 ; CHECK-LABEL: ret_i32_float_pair:
 ; CHECK: ld [%i2], %i0
diff --git a/llvm/test/CodeGen/SPARC/bigreturn.ll b/llvm/test/CodeGen/SPARC/bigreturn.ll
new file mode 100644
index 00000000000000..25b4eeecadc0f7
--- /dev/null
+++ b/llvm/test/CodeGen/SPARC/bigreturn.ll
@@ -0,0 +1,254 @@
+; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
+; RUN: llc < %s -mtriple=sparc -disable-sparc-delay-filler -disable-sparc-leaf-proc | FileCheck --check-prefix=SPARC %s
+; RUN: llc < %s -mtriple=sparc64 -disable-sparc-delay-filler -disable-sparc-leaf-proc | FileCheck --check-prefix=SPARC64 %s
+
+;; Structs up to six registers in size can be returned in registers.
+;; Note that the maximum return size and member placement is NOT
+;; compatible with the C ABI - see SparcCallingConv.td.
+define { i32, i32 } @ret_i32_pair(i32 %a0, i32 %a1, i32* %p, i32* %q) {
+; SPARC-LABEL: ret_i32_pair:
+; SPARC:         .cfi_startproc
+; SPARC-NEXT:  ! %bb.0:
+; SPARC-NEXT:    save %sp, -96, %sp
+; SPARC-NEXT:    .cfi_def_cfa_register %fp
+; SPARC-NEXT:    .cfi_window_save
+; SPARC-NEXT:    .cfi_register %o7, %i7
+; SPARC-NEXT:    ld [%i2], %i0
+; SPARC-NEXT:    st %g0, [%i2]
+; SPARC-NEXT:    ld [%i3], %i1
+; SPARC-NEXT:    restore
+; SPARC-NEXT:    retl
+; SPARC-NEXT:    nop
+;
+; SPARC64-LABEL: ret_i32_pair:
+; SPARC64:         .cfi_startproc
+; SPARC64-NEXT:  ! %bb.0:
+; SPARC64-NEXT:    save %sp, -128, %sp
+; SPARC64-NEXT:    .cfi_def_cfa_register %fp
+; SPARC64-NEXT:    .cfi_window_save
+; SPARC64-NEXT:    .cfi_register %o7, %i7
+; SPARC64-NEXT:    ld [%i2], %i0
+; SPARC64-NEXT:    st %g0, [%i2]
+; SPARC64-NEXT:    ld [%i3], %i1
+; SPARC64-NEXT:    restore
+; SPARC64-NEXT:    retl
+; SPARC64-NEXT:    nop
+  %r1 = load i32, i32* %p
+  %rv1 = insertvalue { i32, i32 } undef, i32 %r1, 0
+  store i32 0, i32* %p
+  %r2 = load i32, i32* %q
+  %rv2 = insertvalue { i32, i32 } %rv1, i32 %r2, 1
+  ret { i32, i32 } %rv2
+}
+
+define void @call_ret_i32_pair(i32* %i0) {
+; SPARC-LABEL: call_ret_i32_pair:
+; SPARC:         .cfi_startproc
+; SPARC-NEXT:  ! %bb.0:
+; SPARC-NEXT:    save %sp, -96, %sp
+; SPARC-NEXT:    .cfi_def_cfa_register %fp
+; SPARC-NEXT:    .cfi_window_save
+; SPARC-NEXT:    .cfi_register %o7, %i7
+; SPARC-NEXT:    call ret_i32_pair
+; SPARC-NEXT:    nop
+; SPARC-NEXT:    st %o0, [%i0]
+; SPARC-NEXT:    st %o1, [%i0]
+; SPARC-NEXT:    restore
+; SPARC-NEXT:    retl
+; SPARC-NEXT:    nop
+;
+; SPARC64-LABEL: call_ret_i32_pair:
+; SPARC64:         .cfi_startproc
+; SPARC64-NEXT:  ! %bb.0:
+; SPARC64-NEXT:    save %sp, -176, %sp
+; SPARC64-NEXT:    .cfi_def_cfa_register %fp
+; SPARC64-NEXT:    .cfi_window_save
+; SPARC64-NEXT:    .cfi_register %o7, %i7
+; SPARC64-NEXT:    call ret_i32_pair
+; SPARC64-NEXT:    nop
+; SPARC64-NEXT:    st %o0, [%i0]
+; SPARC64-NEXT:    st %o1, [%i0]
+; SPARC64-NEXT:    restore
+; SPARC64-NEXT:    retl
+; SPARC64-NEXT:    nop
+  %rv = call { i32, i32 } @ret_i32_pair(i32 undef, i32 undef,
+                                        i32* undef, i32* undef)
+  %e0 = extractvalue { i32, i32 } %rv, 0
+  store volatile i32 %e0, i32* %i0
+  %e1 = extractvalue { i32, i32 } %rv, 1
+  store i32 %e1, i32* %i0
+  ret void
+}
+
+;; Functions returning structs more than six registers' worth of space
+;; should be automatically treated as an sret function.
+declare { [16 x i32] } @ret_i32_arr(i32 %input)
+
+define i32 @call_ret_i32_arr(i32 %0) {
+; SPARC-LABEL: call_ret_i32_arr:
+; SPARC:         .cfi_startproc
+; SPARC-NEXT:  ! %bb.0:
+; SPARC-NEXT:    save %sp, -160, %sp
+; SPARC-NEXT:    .cfi_def_cfa_register %fp
+; SPARC-NEXT:    .cfi_window_save
+; SPARC-NEXT:    .cfi_register %o7, %i7
+; SPARC-NEXT:    add %fp, -64, %i1
+; SPARC-NEXT:    st %i1, [%sp+64]
+; SPARC-NEXT:    mov %i0, %o0
+; SPARC-NEXT:    call ret_i32_arr
+; SPARC-NEXT:    nop
+; SPARC-NEXT:    unimp 64
+; SPARC-NEXT:    ld [%fp+-4], %i0
+; SPARC-NEXT:    restore
+; SPARC-NEXT:    retl
+; SPARC-NEXT:    nop
+;
+; SPARC64-LABEL: call_ret_i32_arr:
+; SPARC64:         .cfi_startproc
+; SPARC64-NEXT:  ! %bb.0:
+; SPARC64-NEXT:    save %sp, -240, %sp
+; SPARC64-NEXT:    .cfi_def_cfa_register %fp
+; SPARC64-NEXT:    .cfi_window_save
+; SPARC64-NEXT:    .cfi_register %o7, %i7
+; SPARC64-NEXT:    add %fp, 1983, %o0
+; SPARC64-NEXT:    mov %i0, %o1
+; SPARC64-NEXT:    call ret_i32_arr
+; SPARC64-NEXT:    nop
+; SPARC64-NEXT:    ld [%fp+2043], %i0
+; SPARC64-NEXT:    restore
+; SPARC64-NEXT:    retl
+; SPARC64-NEXT:    nop
+  %2 = call { [16 x i32] } @ret_i32_arr(i32 %0)
+  %3 = extractvalue { [16 x i32] } %2, 0
+  %4 = extractvalue [16 x i32] %3, 15
+  ret i32 %4
+}
+
+;; Structs up to six registers in size can be returned in registers.
+;; Note that the maximum return size and member placement is NOT
+;; compatible with the C ABI - see SparcCallingConv.td.
+define { i64, i64 } @ret_i64_pair(i32 %a0, i32 %a1, i64* %p, i64* %q) {
+; SPARC-LABEL: ret_i64_pair:
+; SPARC:         .cfi_startproc
+; SPARC-NEXT:  ! %bb.0:
+; SPARC-NEXT:    save %sp, -96, %sp
+; SPARC-NEXT:    .cfi_def_cfa_register %fp
+; SPARC-NEXT:    .cfi_window_save
+; SPARC-NEXT:    .cfi_register %o7, %i7
+; SPARC-NEXT:    mov %g0, %i4
+; SPARC-NEXT:    ldd [%i2], %i0
+; SPARC-NEXT:    mov %i4, %i5
+; SPARC-NEXT:    std %i4, [%i2]
+; SPARC-NEXT:    ldd [%i3], %i2
+; SPARC-NEXT:    restore
+; SPARC-NEXT:    retl
+; SPARC-NEXT:    nop
+;
+; SPARC64-LABEL: ret_i64_pair:
+; SPARC64:         .cfi_startproc
+; SPARC64-NEXT:  ! %bb.0:
+; SPARC64-NEXT:    save %sp, -128, %sp
+; SPARC64-NEXT:    .cfi_def_cfa_register %fp
+; SPARC64-NEXT:    .cfi_window_save
+; SPARC64-NEXT:    .cfi_register %o7, %i7
+; SPARC64-NEXT:    ldx [%i2], %i0
+; SPARC64-NEXT:    stx %g0, [%i2]
+; SPARC64-NEXT:    ldx [%i3], %i1
+; SPARC64-NEXT:    restore
+; SPARC64-NEXT:    retl
+; SPARC64-NEXT:    nop
+  %r1 = load i64, i64* %p
+  %rv1 = insertvalue { i64, i64 } undef, i64 %r1, 0
+  store i64 0, i64* %p
+  %r2 = load i64, i64* %q
+  %rv2 = insertvalue { i64, i64 } %rv1, i64 %r2, 1
+  ret { i64, i64 } %rv2
+}
+
+define void @call_ret_i64_pair(i64* %i0) {
+; SPARC-LABEL: call_ret_i64_pair:
+; SPARC:         .cfi_startproc
+; SPARC-NEXT:  ! %bb.0:
+; SPARC-NEXT:    save %sp, -96, %sp
+; SPARC-NEXT:    .cfi_def_cfa_register %fp
+; SPARC-NEXT:    .cfi_window_save
+; SPARC-NEXT:    .cfi_register %o7, %i7
+; SPARC-NEXT:    call ret_i64_pair
+; SPARC-NEXT:    nop
+; SPARC-NEXT:    ! kill: def $o0 killed $o0 killed $o0_o1 def $o0_o1
+; SPARC-NEXT:    ! kill: def $o2 killed $o2 killed $o2_o3 def $o2_o3
+; SPARC-NEXT:    ! kill: def $o1 killed $o1 killed $o0_o1 def $o0_o1
+; SPARC-NEXT:    std %o0, [%i0]
+; SPARC-NEXT:    ! kill: def $o3 killed $o3 killed $o2_o3 def $o2_o3
+; SPARC-NEXT:    std %o2, [%i0]
+; SPARC-NEXT:    restore
+; SPARC-NEXT:    retl
+; SPARC-NEXT:    nop
+;
+; SPARC64-LABEL: call_ret_i64_pair:
+; SPARC64:         .cfi_startproc
+; SPARC64-NEXT:  ! %bb.0:
+; SPARC64-NEXT:    save %sp, -176, %sp
+; SPARC64-NEXT:    .cfi_def_cfa_register %fp
+; SPARC64-NEXT:    .cfi_window_save
+; SPARC64-NEXT:    .cfi_register %o7, %i7
+; SPARC64-NEXT:    call ret_i64_pair
+; SPARC64-NEXT:    nop
+; SPARC64-NEXT:    stx %o0, [%i0]
+; SPARC64-NEXT:    stx %o1, [%i0]
+; SPARC64-NEXT:    restore
+; SPARC64-NEXT:    retl
+; SPARC64-NEXT:    nop
+  %rv = call { i64, i64 } @ret_i64_pair(i32 undef, i32 undef,
+                                        i64* undef, i64* undef)
+  %e0 = extractvalue { i64, i64 } %rv, 0
+  store volatile i64 %e0, i64* %i0
+  %e1 = extractvalue { i64, i64 } %rv, 1
+  store i64 %e1, i64* %i0
+  ret void
+}
+
+;; Functions returning structs more than six registers' worth of space
+;; should be automatically treated as an sret function.
+declare { [16 x i64] } @ret_i64_arr(i64 %input)
+
+define i64 @call_ret_i64_arr(i64 %0) {
+; SPARC-LABEL: call_ret_i64_arr:
+; SPARC:         .cfi_startproc
+; SPARC-NEXT:  ! %bb.0:
+; SPARC-NEXT:    save %sp, -224, %sp
+; SPARC-NEXT:    .cfi_def_cfa_register %fp
+; SPARC-NEXT:    .cfi_window_save
+; SPARC-NEXT:    .cfi_register %o7, %i7
+; SPARC-NEXT:    add %fp, -128, %i2
+; SPARC-NEXT:    st %i2, [%sp+64]
+; SPARC-NEXT:    mov %i0, %o0
+; SPARC-NEXT:    mov %i1, %o1
+; SPARC-NEXT:    call ret_i64_arr
+; SPARC-NEXT:    nop
+; SPARC-NEXT:    unimp 128
+; SPARC-NEXT:    ldd [%fp+-8], %i0
+; SPARC-NEXT:    restore
+; SPARC-NEXT:    retl
+; SPARC-NEXT:    nop
+;
+; SPARC64-LABEL: call_ret_i64_arr:
+; SPARC64:         .cfi_startproc
+; SPARC64-NEXT:  ! %bb.0:
+; SPARC64-NEXT:    save %sp, -304, %sp
+; SPARC64-NEXT:    .cfi_def_cfa_register %fp
+; SPARC64-NEXT:    .cfi_window_save
+; SPARC64-NEXT:    .cfi_register %o7, %i7
+; SPARC64-NEXT:    add %fp, 1919, %o0
+; SPARC64-NEXT:    mov %i0, %o1
+; SPARC64-NEXT:    call ret_i64_arr
+; SPARC64-NEXT:    nop
+; SPARC64-NEXT:    ldx [%fp+2039], %i0
+; SPARC64-NEXT:    restore
+; SPARC64-NEXT:    retl
+; SPARC64-NEXT:    nop
+  %2 = call { [16 x i64] } @ret_i64_arr(i64 %0)
+  %3 = extractvalue { [16 x i64] } %2, 0
+  %4 = extractvalue [16 x i64] %3, 15
+  ret i64 %4
+}

From 80a9fc840b1b0c5bdd6509578283af3b02782d48 Mon Sep 17 00:00:00 2001
From: Yonghong Song <yhs@fb.com>
Date: Wed, 26 Oct 2022 16:15:02 -0700
Subject: [PATCH 32/84] [clang][Sema] Fix a clang crash with btf_type_tag

For the following program,
  $ cat t.c
  struct t {
   int (__attribute__((btf_type_tag("rcu"))) *f)();
   int a;
  };
  int foo(struct t *arg) {
    return arg->a;
  }
Compiling with 'clang -g -O2 -S t.c' will cause a failure like below:
  clang: /home/yhs/work/llvm-project/clang/lib/Sema/SemaType.cpp:6391: void {anonymous}::DeclaratorLocFiller::VisitParenTypeLoc(clang::ParenTypeLoc):
         Assertion `Chunk.Kind == DeclaratorChunk::Paren' failed.
  PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace, preprocessed source, and associated run script.
  Stack dump:
  ......
  #5 0x00007f89e4280ea5 abort (/lib64/libc.so.6+0x21ea5)
  #6 0x00007f89e4280d79 _nl_load_domain.cold.0 (/lib64/libc.so.6+0x21d79)
  #7 0x00007f89e42a6456 (/lib64/libc.so.6+0x47456)
  #8 0x00000000045c2596 GetTypeSourceInfoForDeclarator((anonymous namespace)::TypeProcessingState&, clang::QualType, clang::TypeSourceInfo*) SemaType.cpp:0:0
  #9 0x00000000045ccfa5 GetFullTypeForDeclarator((anonymous namespace)::TypeProcessingState&, clang::QualType, clang::TypeSourceInfo*) SemaType.cpp:0:0
  ......

The reason of the failure is due to the mismatch of TypeLoc and D.getTypeObject().Kind. For example,
the TypeLoc is
  BTFTagAttributedType 0x88614e0 'int  btf_type_tag(rcu)()' sugar
  |-ParenType 0x8861480 'int ()' sugar
  | `-FunctionNoProtoType 0x8861450 'int ()' cdecl
  |   `-BuiltinType 0x87fd500 'int'
while corresponding D.getTypeObject().Kind points to DeclaratorChunk::Paren, and
this will cause later assertion.

To fix the issue, similar to AttributedTypeLoc, let us skip BTFTagAttributedTypeLoc in
GetTypeSourceInfoForDeclarator().

Differential Revision: https://reviews.llvm.org/D136807
---
 clang/docs/ReleaseNotes.rst                     |  2 ++
 clang/lib/Sema/SemaType.cpp                     |  3 +++
 clang/test/CodeGen/attr-btf_type_tag-func-ptr.c | 15 +++++++++++++++
 3 files changed, 20 insertions(+)
 create mode 100644 clang/test/CodeGen/attr-btf_type_tag-func-ptr.c

diff --git a/clang/docs/ReleaseNotes.rst b/clang/docs/ReleaseNotes.rst
index a17b033f5eb3ce..a1ee8f0459aedb 100644
--- a/clang/docs/ReleaseNotes.rst
+++ b/clang/docs/ReleaseNotes.rst
@@ -225,6 +225,8 @@ Bug Fixes
 - Fix a crash when generating code coverage information for an
   ``if consteval`` statement. This fixes
   `Issue 57377 <https://github.com/llvm/llvm-project/issues/57377>`_.
+- Fix a crash when a ``btf_type_tag`` attribute is applied to the pointee of
+  a function pointer.
 
 Improvements to Clang's diagnostics
 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
diff --git a/clang/lib/Sema/SemaType.cpp b/clang/lib/Sema/SemaType.cpp
index 3ab5d26a9a7506..edcac4d2ee9a26 100644
--- a/clang/lib/Sema/SemaType.cpp
+++ b/clang/lib/Sema/SemaType.cpp
@@ -6443,6 +6443,9 @@ GetTypeSourceInfoForDeclarator(TypeProcessingState &State,
       CurrTL = TL.getNextTypeLoc().getUnqualifiedLoc();
     }
 
+    while (BTFTagAttributedTypeLoc TL = CurrTL.getAs<BTFTagAttributedTypeLoc>())
+      CurrTL = TL.getNextTypeLoc().getUnqualifiedLoc();
+
     while (DependentAddressSpaceTypeLoc TL =
                CurrTL.getAs<DependentAddressSpaceTypeLoc>()) {
       fillDependentAddressSpaceTypeLoc(TL, D.getTypeObject(i).getAttrs());
diff --git a/clang/test/CodeGen/attr-btf_type_tag-func-ptr.c b/clang/test/CodeGen/attr-btf_type_tag-func-ptr.c
new file mode 100644
index 00000000000000..29ca5f58e4b812
--- /dev/null
+++ b/clang/test/CodeGen/attr-btf_type_tag-func-ptr.c
@@ -0,0 +1,15 @@
+// RUN: %clang_cc1 -triple %itanium_abi_triple -debug-info-kind=limited -S -emit-llvm -o - %s | FileCheck %s
+
+struct t {
+ int (__attribute__((btf_type_tag("rcu"))) *f)();
+ int a;
+};
+int foo(struct t *arg) {
+  return arg->a;
+}
+
+// CHECK:      !DIDerivedType(tag: DW_TAG_member, name: "f"
+// CHECK-SAME: baseType: ![[L18:[0-9]+]]
+// CHECK:      ![[L18]] = !DIDerivedType(tag: DW_TAG_pointer_type, baseType: ![[#]], size: [[#]], annotations: ![[L21:[0-9]+]])
+// CHECK:      ![[L21]] = !{![[L22:[0-9]+]]}
+// CHECK:      ![[L22]] = !{!"btf_type_tag", !"rcu"}

From 5c68a1cb123161b54b72ce90e7975d95a8eaf2a4 Mon Sep 17 00:00:00 2001
From: Matt Arsenault <Matthew.Arsenault@amd.com>
Date: Mon, 26 Sep 2022 23:07:49 -0400
Subject: [PATCH 33/84] AMDGPU: Make various vector undefs legal

Surprisingly these were getting legalized to something
zero initialized.

This fixes an infinite loop when combining some vector types.
Also fixes zero initializing some undef values.

SimplifyDemandedVectorElts / SimplifyDemandedBits are not checking
for the legality of the output undefs they are replacing unused
operations with. This resulted in turning vectors into undefs
that were later re-legalized back into zero vectors.

(cherry picked from commit 7a84624079a2656c684bed6100708544500c5a32)
---
 llvm/lib/Target/AMDGPU/SIISelLowering.cpp     |   2 +
 llvm/test/CodeGen/AMDGPU/commute-shifts.ll    |  16 --
 .../AMDGPU/cross-block-use-is-not-abi-copy.ll |   4 +-
 .../CodeGen/AMDGPU/dagcombine-fma-fmad.ll     |  10 +-
 .../CodeGen/AMDGPU/extract-subvector-16bit.ll |  78 +------
 llvm/test/CodeGen/AMDGPU/insert_vector_elt.ll |  14 +-
 llvm/test/CodeGen/AMDGPU/select-undef.ll      | 219 +++++++++++++++++-
 llvm/test/CodeGen/AMDGPU/skip-if-dead.ll      | 113 ++-------
 llvm/test/CodeGen/AMDGPU/v1024.ll             |   2 +
 .../CodeGen/AMDGPU/vgpr-tuple-allocation.ll   | 144 ++----------
 llvm/test/CodeGen/AMDGPU/wqm.ll               | 162 ++-----------
 11 files changed, 306 insertions(+), 458 deletions(-)

diff --git a/llvm/lib/Target/AMDGPU/SIISelLowering.cpp b/llvm/lib/Target/AMDGPU/SIISelLowering.cpp
index f7d139adc63bac..f6b7d1ffc6d27c 100644
--- a/llvm/lib/Target/AMDGPU/SIISelLowering.cpp
+++ b/llvm/lib/Target/AMDGPU/SIISelLowering.cpp
@@ -249,6 +249,7 @@ SITargetLowering::SITargetLowering(const TargetMachine &TM,
       case ISD::STORE:
       case ISD::BUILD_VECTOR:
       case ISD::BITCAST:
+      case ISD::UNDEF:
       case ISD::EXTRACT_VECTOR_ELT:
       case ISD::INSERT_VECTOR_ELT:
       case ISD::EXTRACT_SUBVECTOR:
@@ -516,6 +517,7 @@ SITargetLowering::SITargetLowering(const TargetMachine &TM,
         case ISD::STORE:
         case ISD::BUILD_VECTOR:
         case ISD::BITCAST:
+        case ISD::UNDEF:
         case ISD::EXTRACT_VECTOR_ELT:
         case ISD::INSERT_VECTOR_ELT:
         case ISD::INSERT_SUBVECTOR:
diff --git a/llvm/test/CodeGen/AMDGPU/commute-shifts.ll b/llvm/test/CodeGen/AMDGPU/commute-shifts.ll
index 8df85ba872bfbf..3697946cb5c398 100644
--- a/llvm/test/CodeGen/AMDGPU/commute-shifts.ll
+++ b/llvm/test/CodeGen/AMDGPU/commute-shifts.ll
@@ -5,14 +5,6 @@
 define amdgpu_ps float @main(float %arg0, float %arg1) #0 {
 ; SI-LABEL: main:
 ; SI:       ; %bb.0: ; %bb
-; SI-NEXT:    s_mov_b32 s0, 0
-; SI-NEXT:    s_mov_b32 s1, s0
-; SI-NEXT:    s_mov_b32 s2, s0
-; SI-NEXT:    s_mov_b32 s3, s0
-; SI-NEXT:    s_mov_b32 s4, s0
-; SI-NEXT:    s_mov_b32 s5, s0
-; SI-NEXT:    s_mov_b32 s6, s0
-; SI-NEXT:    s_mov_b32 s7, s0
 ; SI-NEXT:    image_load v2, v0, s[0:7] dmask:0x1 unorm
 ; SI-NEXT:    v_cvt_i32_f32_e32 v0, v0
 ; SI-NEXT:    v_and_b32_e32 v0, 7, v0
@@ -26,14 +18,6 @@ define amdgpu_ps float @main(float %arg0, float %arg1) #0 {
 ;
 ; VI-LABEL: main:
 ; VI:       ; %bb.0: ; %bb
-; VI-NEXT:    s_mov_b32 s0, 0
-; VI-NEXT:    s_mov_b32 s1, s0
-; VI-NEXT:    s_mov_b32 s2, s0
-; VI-NEXT:    s_mov_b32 s3, s0
-; VI-NEXT:    s_mov_b32 s4, s0
-; VI-NEXT:    s_mov_b32 s5, s0
-; VI-NEXT:    s_mov_b32 s6, s0
-; VI-NEXT:    s_mov_b32 s7, s0
 ; VI-NEXT:    image_load v2, v0, s[0:7] dmask:0x1 unorm
 ; VI-NEXT:    v_cvt_i32_f32_e32 v0, v0
 ; VI-NEXT:    v_and_b32_e32 v0, 7, v0
diff --git a/llvm/test/CodeGen/AMDGPU/cross-block-use-is-not-abi-copy.ll b/llvm/test/CodeGen/AMDGPU/cross-block-use-is-not-abi-copy.ll
index 29fc098899ee5c..5d985850446cc3 100644
--- a/llvm/test/CodeGen/AMDGPU/cross-block-use-is-not-abi-copy.ll
+++ b/llvm/test/CodeGen/AMDGPU/cross-block-use-is-not-abi-copy.ll
@@ -213,7 +213,7 @@ if.else:                                          ; preds = %entry
   br label %if.end
 
 if.end:                                           ; preds = %if.else, %if.then
-  %call6.sink = phi <3 x i16> [ %call6, %if.else ], [ undef, %if.then ]
+  %call6.sink = phi <3 x i16> [ %call6, %if.else ], [ zeroinitializer, %if.then ]
   store <3 x i16> %call6.sink, <3 x i16> addrspace(1)* undef
   ret void
 }
@@ -266,7 +266,7 @@ if.else:                                          ; preds = %entry
   br label %if.end
 
 if.end:                                           ; preds = %if.else, %if.then
-  %call6.sink = phi <3 x half> [ %call6, %if.else ], [ undef, %if.then ]
+  %call6.sink = phi <3 x half> [ %call6, %if.else ], [ zeroinitializer, %if.then ]
   store <3 x half> %call6.sink, <3 x half> addrspace(1)* undef
   ret void
 }
diff --git a/llvm/test/CodeGen/AMDGPU/dagcombine-fma-fmad.ll b/llvm/test/CodeGen/AMDGPU/dagcombine-fma-fmad.ll
index 8af7575f03d06d..0b629efffbb30e 100644
--- a/llvm/test/CodeGen/AMDGPU/dagcombine-fma-fmad.ll
+++ b/llvm/test/CodeGen/AMDGPU/dagcombine-fma-fmad.ll
@@ -4,16 +4,8 @@
 define amdgpu_ps float @_amdgpu_ps_main() #0 {
 ; GCN-LABEL: _amdgpu_ps_main:
 ; GCN:       ; %bb.0: ; %.entry
-; GCN-NEXT:    s_mov_b32 s0, 0
-; GCN-NEXT:    v_mov_b32_e32 v4, 0
-; GCN-NEXT:    s_mov_b32 s1, s0
-; GCN-NEXT:    s_mov_b32 s2, s0
-; GCN-NEXT:    s_mov_b32 s3, s0
-; GCN-NEXT:    s_mov_b32 s4, s0
-; GCN-NEXT:    s_mov_b32 s5, s0
-; GCN-NEXT:    s_mov_b32 s6, s0
-; GCN-NEXT:    s_mov_b32 s7, s0
 ; GCN-NEXT:    image_sample v[0:1], v[0:1], s[0:7], s[0:3] dmask:0x3 dim:SQ_RSRC_IMG_2D
+; GCN-NEXT:    v_mov_b32_e32 v4, 0
 ; GCN-NEXT:    s_waitcnt vmcnt(0)
 ; GCN-NEXT:    s_clause 0x1
 ; GCN-NEXT:    image_sample v2, v[0:1], s[0:7], s[0:3] dmask:0x4 dim:SQ_RSRC_IMG_2D
diff --git a/llvm/test/CodeGen/AMDGPU/extract-subvector-16bit.ll b/llvm/test/CodeGen/AMDGPU/extract-subvector-16bit.ll
index 6456c87a31fbfc..cbfd8ec5cb16e6 100644
--- a/llvm/test/CodeGen/AMDGPU/extract-subvector-16bit.ll
+++ b/llvm/test/CodeGen/AMDGPU/extract-subvector-16bit.ll
@@ -100,14 +100,7 @@ define <4 x i16> @vec_8xi16_extract_4xi16(<8 x i16> addrspace(1) * %p0, <8 x i16
 ; GFX9-NEXT:    s_cbranch_execz .LBB0_3
 ; GFX9-NEXT:    s_branch .LBB0_4
 ; GFX9-NEXT:  .LBB0_2:
-; GFX9-NEXT:    s_mov_b32 s8, 0
-; GFX9-NEXT:    s_mov_b32 s9, s8
-; GFX9-NEXT:    s_mov_b32 s10, s8
-; GFX9-NEXT:    s_mov_b32 s11, s8
-; GFX9-NEXT:    v_mov_b32_e32 v2, s8
-; GFX9-NEXT:    v_mov_b32_e32 v3, s9
-; GFX9-NEXT:    v_mov_b32_e32 v4, s10
-; GFX9-NEXT:    v_mov_b32_e32 v5, s11
+; GFX9-NEXT:    ; implicit-def: $vgpr2_vgpr3_vgpr4_vgpr5
 ; GFX9-NEXT:  .LBB0_3: ; %T
 ; GFX9-NEXT:    global_load_dwordx4 v[2:5], v[0:1], off glc
 ; GFX9-NEXT:    s_waitcnt vmcnt(0)
@@ -244,14 +237,7 @@ define <4 x i16> @vec_8xi16_extract_4xi16_2(<8 x i16> addrspace(1) * %p0, <8 x i
 ; GFX9-NEXT:    s_cbranch_execz .LBB1_3
 ; GFX9-NEXT:    s_branch .LBB1_4
 ; GFX9-NEXT:  .LBB1_2:
-; GFX9-NEXT:    s_mov_b32 s8, 0
-; GFX9-NEXT:    s_mov_b32 s9, s8
-; GFX9-NEXT:    s_mov_b32 s10, s8
-; GFX9-NEXT:    s_mov_b32 s11, s8
-; GFX9-NEXT:    v_mov_b32_e32 v2, s8
-; GFX9-NEXT:    v_mov_b32_e32 v3, s9
-; GFX9-NEXT:    v_mov_b32_e32 v4, s10
-; GFX9-NEXT:    v_mov_b32_e32 v5, s11
+; GFX9-NEXT:    ; implicit-def: $vgpr2_vgpr3_vgpr4_vgpr5
 ; GFX9-NEXT:  .LBB1_3: ; %T
 ; GFX9-NEXT:    global_load_dwordx4 v[2:5], v[0:1], off glc
 ; GFX9-NEXT:    s_waitcnt vmcnt(0)
@@ -386,14 +372,7 @@ define <4 x half> @vec_8xf16_extract_4xf16(<8 x half> addrspace(1) * %p0, <8 x h
 ; GFX9-NEXT:    s_cbranch_execz .LBB2_3
 ; GFX9-NEXT:    s_branch .LBB2_4
 ; GFX9-NEXT:  .LBB2_2:
-; GFX9-NEXT:    s_mov_b32 s8, 0
-; GFX9-NEXT:    s_mov_b32 s9, s8
-; GFX9-NEXT:    s_mov_b32 s10, s8
-; GFX9-NEXT:    s_mov_b32 s11, s8
-; GFX9-NEXT:    v_mov_b32_e32 v2, s8
-; GFX9-NEXT:    v_mov_b32_e32 v3, s9
-; GFX9-NEXT:    v_mov_b32_e32 v4, s10
-; GFX9-NEXT:    v_mov_b32_e32 v5, s11
+; GFX9-NEXT:    ; implicit-def: $vgpr2_vgpr3_vgpr4_vgpr5
 ; GFX9-NEXT:  .LBB2_3: ; %T
 ; GFX9-NEXT:    global_load_dwordx4 v[2:5], v[0:1], off glc
 ; GFX9-NEXT:    s_waitcnt vmcnt(0)
@@ -567,22 +546,7 @@ define <4 x i16> @vec_16xi16_extract_4xi16(<16 x i16> addrspace(1) * %p0, <16 x
 ; GFX9-NEXT:    s_cbranch_execz .LBB3_3
 ; GFX9-NEXT:    s_branch .LBB3_4
 ; GFX9-NEXT:  .LBB3_2:
-; GFX9-NEXT:    s_mov_b32 s8, 0
-; GFX9-NEXT:    s_mov_b32 s9, s8
-; GFX9-NEXT:    s_mov_b32 s10, s8
-; GFX9-NEXT:    s_mov_b32 s11, s8
-; GFX9-NEXT:    s_mov_b32 s12, s8
-; GFX9-NEXT:    s_mov_b32 s13, s8
-; GFX9-NEXT:    s_mov_b32 s14, s8
-; GFX9-NEXT:    s_mov_b32 s15, s8
-; GFX9-NEXT:    v_mov_b32_e32 v4, s8
-; GFX9-NEXT:    v_mov_b32_e32 v5, s9
-; GFX9-NEXT:    v_mov_b32_e32 v6, s10
-; GFX9-NEXT:    v_mov_b32_e32 v7, s11
-; GFX9-NEXT:    v_mov_b32_e32 v8, s12
-; GFX9-NEXT:    v_mov_b32_e32 v9, s13
-; GFX9-NEXT:    v_mov_b32_e32 v10, s14
-; GFX9-NEXT:    v_mov_b32_e32 v11, s15
+; GFX9-NEXT:    ; implicit-def: $vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11
 ; GFX9-NEXT:  .LBB3_3: ; %T
 ; GFX9-NEXT:    s_waitcnt vmcnt(0)
 ; GFX9-NEXT:    global_load_dwordx4 v[2:5], v[0:1], off offset:16 glc
@@ -759,22 +723,7 @@ define <4 x i16> @vec_16xi16_extract_4xi16_2(<16 x i16> addrspace(1) * %p0, <16
 ; GFX9-NEXT:    s_cbranch_execz .LBB4_3
 ; GFX9-NEXT:    s_branch .LBB4_4
 ; GFX9-NEXT:  .LBB4_2:
-; GFX9-NEXT:    s_mov_b32 s8, 0
-; GFX9-NEXT:    s_mov_b32 s9, s8
-; GFX9-NEXT:    s_mov_b32 s10, s8
-; GFX9-NEXT:    s_mov_b32 s11, s8
-; GFX9-NEXT:    s_mov_b32 s12, s8
-; GFX9-NEXT:    s_mov_b32 s13, s8
-; GFX9-NEXT:    s_mov_b32 s14, s8
-; GFX9-NEXT:    s_mov_b32 s15, s8
-; GFX9-NEXT:    v_mov_b32_e32 v4, s8
-; GFX9-NEXT:    v_mov_b32_e32 v5, s9
-; GFX9-NEXT:    v_mov_b32_e32 v6, s10
-; GFX9-NEXT:    v_mov_b32_e32 v7, s11
-; GFX9-NEXT:    v_mov_b32_e32 v8, s12
-; GFX9-NEXT:    v_mov_b32_e32 v9, s13
-; GFX9-NEXT:    v_mov_b32_e32 v10, s14
-; GFX9-NEXT:    v_mov_b32_e32 v11, s15
+; GFX9-NEXT:    ; implicit-def: $vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11
 ; GFX9-NEXT:  .LBB4_3: ; %T
 ; GFX9-NEXT:    s_waitcnt vmcnt(0)
 ; GFX9-NEXT:    global_load_dwordx4 v[2:5], v[0:1], off offset:16 glc
@@ -949,22 +898,7 @@ define <4 x half> @vec_16xf16_extract_4xf16(<16 x half> addrspace(1) * %p0, <16
 ; GFX9-NEXT:    s_cbranch_execz .LBB5_3
 ; GFX9-NEXT:    s_branch .LBB5_4
 ; GFX9-NEXT:  .LBB5_2:
-; GFX9-NEXT:    s_mov_b32 s8, 0
-; GFX9-NEXT:    s_mov_b32 s9, s8
-; GFX9-NEXT:    s_mov_b32 s10, s8
-; GFX9-NEXT:    s_mov_b32 s11, s8
-; GFX9-NEXT:    s_mov_b32 s12, s8
-; GFX9-NEXT:    s_mov_b32 s13, s8
-; GFX9-NEXT:    s_mov_b32 s14, s8
-; GFX9-NEXT:    s_mov_b32 s15, s8
-; GFX9-NEXT:    v_mov_b32_e32 v4, s8
-; GFX9-NEXT:    v_mov_b32_e32 v5, s9
-; GFX9-NEXT:    v_mov_b32_e32 v6, s10
-; GFX9-NEXT:    v_mov_b32_e32 v7, s11
-; GFX9-NEXT:    v_mov_b32_e32 v8, s12
-; GFX9-NEXT:    v_mov_b32_e32 v9, s13
-; GFX9-NEXT:    v_mov_b32_e32 v10, s14
-; GFX9-NEXT:    v_mov_b32_e32 v11, s15
+; GFX9-NEXT:    ; implicit-def: $vgpr4_vgpr5_vgpr6_vgpr7_vgpr8_vgpr9_vgpr10_vgpr11
 ; GFX9-NEXT:  .LBB5_3: ; %T
 ; GFX9-NEXT:    s_waitcnt vmcnt(0)
 ; GFX9-NEXT:    global_load_dwordx4 v[2:5], v[0:1], off offset:16 glc
diff --git a/llvm/test/CodeGen/AMDGPU/insert_vector_elt.ll b/llvm/test/CodeGen/AMDGPU/insert_vector_elt.ll
index cc4ece6c7059f7..f742d2c0bda4d5 100644
--- a/llvm/test/CodeGen/AMDGPU/insert_vector_elt.ll
+++ b/llvm/test/CodeGen/AMDGPU/insert_vector_elt.ll
@@ -374,18 +374,10 @@ define <4 x float> @insertelement_to_sgpr() nounwind {
 ; GCN-LABEL: insertelement_to_sgpr:
 ; GCN:       ; %bb.0:
 ; GCN-NEXT:    s_waitcnt vmcnt(0) expcnt(0) lgkmcnt(0)
-; GCN-NEXT:    s_load_dwordx4 s[12:15], s[4:5], 0x0
+; GCN-NEXT:    s_load_dwordx4 s[4:7], s[4:5], 0x0
 ; GCN-NEXT:    s_waitcnt lgkmcnt(0)
-; GCN-NEXT:    s_mov_b32 s12, 0
-; GCN-NEXT:    s_mov_b32 s4, s12
-; GCN-NEXT:    s_mov_b32 s5, s12
-; GCN-NEXT:    s_mov_b32 s6, s12
-; GCN-NEXT:    s_mov_b32 s7, s12
-; GCN-NEXT:    s_mov_b32 s8, s12
-; GCN-NEXT:    s_mov_b32 s9, s12
-; GCN-NEXT:    s_mov_b32 s10, s12
-; GCN-NEXT:    s_mov_b32 s11, s12
-; GCN-NEXT:    image_gather4_lz v[0:3], v[0:1], s[4:11], s[12:15] dmask:0x1
+; GCN-NEXT:    s_mov_b32 s4, 0
+; GCN-NEXT:    image_gather4_lz v[0:3], v[0:1], s[4:11], s[4:7] dmask:0x1
 ; GCN-NEXT:    s_waitcnt vmcnt(0)
 ; GCN-NEXT:    s_setpc_b64 s[30:31]
   %tmp = load <4 x i32>, <4 x i32> addrspace(4)* undef
diff --git a/llvm/test/CodeGen/AMDGPU/select-undef.ll b/llvm/test/CodeGen/AMDGPU/select-undef.ll
index 6597d6784e0c23..f02cd3fc5e4e65 100644
--- a/llvm/test/CodeGen/AMDGPU/select-undef.ll
+++ b/llvm/test/CodeGen/AMDGPU/select-undef.ll
@@ -1,4 +1,4 @@
-; RUN: llc -mtriple=amdgcn-amd-amdhsa < %s | FileCheck -check-prefix=GCN %s
+; RUN: llc -mtriple=amdgcn-amd-amdhsa -mcpu=gfx900 < %s | FileCheck -check-prefix=GCN %s
 
 ; GCN-LABEL: {{^}}select_undef_lhs:
 ; GCN: s_waitcnt
@@ -43,3 +43,220 @@ define void @select_undef_n2(float addrspace(1)* %a, i32 %c) {
 }
 
 declare float @llvm.amdgcn.rcp.f32(float)
+
+
+; Make sure the vector undef isn't lowered into 0s.
+; GCN-LABEL: {{^}}undef_v6f32:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v6f32(<6 x float> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <6 x float> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <6 x float>, <6 x float> addrspace(3)* undef
+  %add = fadd <6 x float> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <6 x float> %add, <6 x float> addrspace(3)* undef
+  ret void
+}
+
+; GCN-LABEL: {{^}}undef_v6i32:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v6i32(<6 x i32> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <6 x i32> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <6 x i32>, <6 x i32> addrspace(3)* undef
+  %add = add <6 x i32> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <6 x i32> %add, <6 x i32> addrspace(3)* undef
+  ret void
+}
+
+; Make sure the vector undef isn't lowered into 0s.
+; GCN-LABEL: {{^}}undef_v5f32:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v5f32(<5 x float> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <5 x float> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <5 x float>, <5 x float> addrspace(3)* undef
+  %add = fadd <5 x float> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <5 x float> %add, <5 x float> addrspace(3)* undef
+  ret void
+}
+
+; GCN-LABEL: {{^}}undef_v5i32:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v5i32(<5 x i32> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <5 x i32> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <5 x i32>, <5 x i32> addrspace(3)* undef
+  %add = add <5 x i32> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <5 x i32> %add, <5 x i32> addrspace(3)* undef
+  ret void
+}
+
+; Make sure the vector undef isn't lowered into 0s.
+; GCN-LABEL: {{^}}undef_v3f64:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v3f64(<3 x double> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <3 x double> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <3 x double>, <3 x double> addrspace(3)* %ptr
+  %add = fadd <3 x double> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <3 x double> %add, <3 x double> addrspace(3)* %ptr
+  ret void
+}
+
+; GCN-LABEL: {{^}}undef_v3i64:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v3i64(<3 x i64> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <3 x i64> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <3 x i64>, <3 x i64> addrspace(3)* %ptr
+  %add = add <3 x i64> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <3 x i64> %add, <3 x i64> addrspace(3)* %ptr
+  ret void
+}
+
+; Make sure the vector undef isn't lowered into 0s.
+; GCN-LABEL: {{^}}undef_v4f16:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v4f16(<4 x half> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <4 x half> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <4 x half>, <4 x half> addrspace(3)* %ptr
+  %add = fadd <4 x half> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <4 x half> %add, <4 x half> addrspace(3)* %ptr
+  ret void
+}
+
+; GCN-LABEL: {{^}}undef_v4i16:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v4i16(<4 x i16> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <4 x i16> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <4 x i16>, <4 x i16> addrspace(3)* %ptr
+  %add = add <4 x i16> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <4 x i16> %add, <4 x i16> addrspace(3)* %ptr
+  ret void
+}
+
+; Make sure the vector undef isn't lowered into 0s.
+; GCN-LABEL: {{^}}undef_v2f16:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v2f16(<2 x half> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <2 x half> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <2 x half>, <2 x half> addrspace(3)* %ptr
+  %add = fadd <2 x half> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <2 x half> %add, <2 x half> addrspace(3)* %ptr
+  ret void
+}
+
+; GCN-LABEL: {{^}}undef_v2i16:
+; GCN-NOT: v_mov_b32_e32 v{{[0-9]+}}, 0
+; GCN-NOT: s_mov_b32 s{{[0-9]+}}, 0
+; GCN: s_cbranch_vccnz
+define amdgpu_kernel void @undef_v2i16(<2 x i16> addrspace(3)* %ptr, i1 %cond) {
+entry:
+  br label %loop
+
+loop:
+  %phi = phi <2 x i16> [ undef, %entry ], [ %add, %loop ]
+  %load = load volatile <2 x i16>, <2 x i16> addrspace(3)* %ptr
+  %add = add <2 x i16> %load, %phi
+  br i1 %cond, label %loop, label %ret
+
+ret:
+  store volatile <2 x i16> %add, <2 x i16> addrspace(3)* %ptr
+  ret void
+}
+
+; We were expanding undef vectors into zero vectors. Optimizations
+; would then see we used no elements of the vector, and reform the
+; undef vector resulting in a combiner loop.
+; GCN-LABEL: {{^}}inf_loop_undef_vector:
+; GCN: s_waitcnt
+; GCN-NEXT: v_mad_u64_u32
+; GCN-NEXT: v_mul_lo_u32
+; GCN-NEXT: v_mul_lo_u32
+; GCN-NEXT: v_add3_u32
+; GCN-NEXT: global_store_dwordx2
+define void @inf_loop_undef_vector(<6 x float> %arg, float %arg1, i64 %arg2) {
+  %i = insertelement <6 x float> %arg, float %arg1, i64 2
+  %i3 = bitcast <6 x float> %i to <3 x i64>
+  %i4 = extractelement <3 x i64> %i3, i64 0
+  %i5 = extractelement <3 x i64> %i3, i64 1
+  %i6 = mul i64 %i5, %arg2
+  %i7 = add i64 %i6, %i4
+  store volatile i64 %i7, i64 addrspace(1)* undef, align 4
+  ret void
+}
diff --git a/llvm/test/CodeGen/AMDGPU/skip-if-dead.ll b/llvm/test/CodeGen/AMDGPU/skip-if-dead.ll
index ada6c1da04e2ca..7080c84f7b50a2 100644
--- a/llvm/test/CodeGen/AMDGPU/skip-if-dead.ll
+++ b/llvm/test/CodeGen/AMDGPU/skip-if-dead.ll
@@ -1397,28 +1397,20 @@ bb7:                                              ; preds = %bb4
 define amdgpu_ps void @if_after_kill_block(float %arg, float %arg1, float %arg2, float %arg3) #0 {
 ; SI-LABEL: if_after_kill_block:
 ; SI:       ; %bb.0: ; %bb
-; SI-NEXT:    s_mov_b64 s[2:3], exec
+; SI-NEXT:    s_mov_b64 s[0:1], exec
 ; SI-NEXT:    s_wqm_b64 exec, exec
-; SI-NEXT:    s_mov_b32 s0, 0
 ; SI-NEXT:    v_cmp_nle_f32_e32 vcc, 0, v1
-; SI-NEXT:    s_and_saveexec_b64 s[4:5], vcc
-; SI-NEXT:    s_xor_b64 s[4:5], exec, s[4:5]
+; SI-NEXT:    s_and_saveexec_b64 s[2:3], vcc
+; SI-NEXT:    s_xor_b64 s[2:3], exec, s[2:3]
 ; SI-NEXT:    s_cbranch_execz .LBB13_3
 ; SI-NEXT:  ; %bb.1: ; %bb3
 ; SI-NEXT:    v_cmp_ngt_f32_e32 vcc, 0, v0
-; SI-NEXT:    s_andn2_b64 s[2:3], s[2:3], vcc
+; SI-NEXT:    s_andn2_b64 s[0:1], s[0:1], vcc
 ; SI-NEXT:    s_cbranch_scc0 .LBB13_6
 ; SI-NEXT:  ; %bb.2: ; %bb3
 ; SI-NEXT:    s_andn2_b64 exec, exec, vcc
 ; SI-NEXT:  .LBB13_3: ; %bb4
-; SI-NEXT:    s_or_b64 exec, exec, s[4:5]
-; SI-NEXT:    s_mov_b32 s1, s0
-; SI-NEXT:    s_mov_b32 s2, s0
-; SI-NEXT:    s_mov_b32 s3, s0
-; SI-NEXT:    s_mov_b32 s4, s0
-; SI-NEXT:    s_mov_b32 s5, s0
-; SI-NEXT:    s_mov_b32 s6, s0
-; SI-NEXT:    s_mov_b32 s7, s0
+; SI-NEXT:    s_or_b64 exec, exec, s[2:3]
 ; SI-NEXT:    image_sample_c v0, v[2:3], s[0:7], s[0:3] dmask:0x10
 ; SI-NEXT:    s_waitcnt vmcnt(0)
 ; SI-NEXT:    v_cmp_neq_f32_e32 vcc, 0, v0
@@ -1439,28 +1431,20 @@ define amdgpu_ps void @if_after_kill_block(float %arg, float %arg1, float %arg2,
 ;
 ; GFX10-WAVE64-LABEL: if_after_kill_block:
 ; GFX10-WAVE64:       ; %bb.0: ; %bb
-; GFX10-WAVE64-NEXT:    s_mov_b64 s[2:3], exec
+; GFX10-WAVE64-NEXT:    s_mov_b64 s[0:1], exec
 ; GFX10-WAVE64-NEXT:    s_wqm_b64 exec, exec
 ; GFX10-WAVE64-NEXT:    v_cmp_nle_f32_e32 vcc, 0, v1
-; GFX10-WAVE64-NEXT:    s_mov_b32 s0, 0
-; GFX10-WAVE64-NEXT:    s_and_saveexec_b64 s[4:5], vcc
-; GFX10-WAVE64-NEXT:    s_xor_b64 s[4:5], exec, s[4:5]
+; GFX10-WAVE64-NEXT:    s_and_saveexec_b64 s[2:3], vcc
+; GFX10-WAVE64-NEXT:    s_xor_b64 s[2:3], exec, s[2:3]
 ; GFX10-WAVE64-NEXT:    s_cbranch_execz .LBB13_3
 ; GFX10-WAVE64-NEXT:  ; %bb.1: ; %bb3
 ; GFX10-WAVE64-NEXT:    v_cmp_ngt_f32_e32 vcc, 0, v0
-; GFX10-WAVE64-NEXT:    s_andn2_b64 s[2:3], s[2:3], vcc
+; GFX10-WAVE64-NEXT:    s_andn2_b64 s[0:1], s[0:1], vcc
 ; GFX10-WAVE64-NEXT:    s_cbranch_scc0 .LBB13_6
 ; GFX10-WAVE64-NEXT:  ; %bb.2: ; %bb3
 ; GFX10-WAVE64-NEXT:    s_andn2_b64 exec, exec, vcc
 ; GFX10-WAVE64-NEXT:  .LBB13_3: ; %bb4
-; GFX10-WAVE64-NEXT:    s_or_b64 exec, exec, s[4:5]
-; GFX10-WAVE64-NEXT:    s_mov_b32 s1, s0
-; GFX10-WAVE64-NEXT:    s_mov_b32 s2, s0
-; GFX10-WAVE64-NEXT:    s_mov_b32 s3, s0
-; GFX10-WAVE64-NEXT:    s_mov_b32 s4, s0
-; GFX10-WAVE64-NEXT:    s_mov_b32 s5, s0
-; GFX10-WAVE64-NEXT:    s_mov_b32 s6, s0
-; GFX10-WAVE64-NEXT:    s_mov_b32 s7, s0
+; GFX10-WAVE64-NEXT:    s_or_b64 exec, exec, s[2:3]
 ; GFX10-WAVE64-NEXT:    image_sample_c v0, v[2:3], s[0:7], s[0:3] dmask:0x10 dim:SQ_RSRC_IMG_1D
 ; GFX10-WAVE64-NEXT:    s_waitcnt vmcnt(0)
 ; GFX10-WAVE64-NEXT:    v_cmp_neq_f32_e32 vcc, 0, v0
@@ -1479,28 +1463,20 @@ define amdgpu_ps void @if_after_kill_block(float %arg, float %arg1, float %arg2,
 ;
 ; GFX10-WAVE32-LABEL: if_after_kill_block:
 ; GFX10-WAVE32:       ; %bb.0: ; %bb
-; GFX10-WAVE32-NEXT:    s_mov_b32 s1, exec_lo
+; GFX10-WAVE32-NEXT:    s_mov_b32 s0, exec_lo
 ; GFX10-WAVE32-NEXT:    s_wqm_b32 exec_lo, exec_lo
 ; GFX10-WAVE32-NEXT:    v_cmp_nle_f32_e32 vcc_lo, 0, v1
-; GFX10-WAVE32-NEXT:    s_mov_b32 s0, 0
-; GFX10-WAVE32-NEXT:    s_and_saveexec_b32 s2, vcc_lo
-; GFX10-WAVE32-NEXT:    s_xor_b32 s2, exec_lo, s2
+; GFX10-WAVE32-NEXT:    s_and_saveexec_b32 s1, vcc_lo
+; GFX10-WAVE32-NEXT:    s_xor_b32 s1, exec_lo, s1
 ; GFX10-WAVE32-NEXT:    s_cbranch_execz .LBB13_3
 ; GFX10-WAVE32-NEXT:  ; %bb.1: ; %bb3
 ; GFX10-WAVE32-NEXT:    v_cmp_ngt_f32_e32 vcc_lo, 0, v0
-; GFX10-WAVE32-NEXT:    s_andn2_b32 s1, s1, vcc_lo
+; GFX10-WAVE32-NEXT:    s_andn2_b32 s0, s0, vcc_lo
 ; GFX10-WAVE32-NEXT:    s_cbranch_scc0 .LBB13_6
 ; GFX10-WAVE32-NEXT:  ; %bb.2: ; %bb3
 ; GFX10-WAVE32-NEXT:    s_andn2_b32 exec_lo, exec_lo, vcc_lo
 ; GFX10-WAVE32-NEXT:  .LBB13_3: ; %bb4
-; GFX10-WAVE32-NEXT:    s_or_b32 exec_lo, exec_lo, s2
-; GFX10-WAVE32-NEXT:    s_mov_b32 s1, s0
-; GFX10-WAVE32-NEXT:    s_mov_b32 s2, s0
-; GFX10-WAVE32-NEXT:    s_mov_b32 s3, s0
-; GFX10-WAVE32-NEXT:    s_mov_b32 s4, s0
-; GFX10-WAVE32-NEXT:    s_mov_b32 s5, s0
-; GFX10-WAVE32-NEXT:    s_mov_b32 s6, s0
-; GFX10-WAVE32-NEXT:    s_mov_b32 s7, s0
+; GFX10-WAVE32-NEXT:    s_or_b32 exec_lo, exec_lo, s1
 ; GFX10-WAVE32-NEXT:    image_sample_c v0, v[2:3], s[0:7], s[0:3] dmask:0x10 dim:SQ_RSRC_IMG_1D
 ; GFX10-WAVE32-NEXT:    s_waitcnt vmcnt(0)
 ; GFX10-WAVE32-NEXT:    v_cmp_neq_f32_e32 vcc_lo, 0, v0
@@ -1519,29 +1495,22 @@ define amdgpu_ps void @if_after_kill_block(float %arg, float %arg1, float %arg2,
 ;
 ; GFX11-LABEL: if_after_kill_block:
 ; GFX11:       ; %bb.0: ; %bb
-; GFX11-NEXT:    s_mov_b64 s[2:3], exec
+; GFX11-NEXT:    s_mov_b64 s[0:1], exec
 ; GFX11-NEXT:    s_wqm_b64 exec, exec
-; GFX11-NEXT:    s_mov_b32 s0, 0
-; GFX11-NEXT:    s_mov_b64 s[4:5], exec
+; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
+; GFX11-NEXT:    s_mov_b64 s[2:3], exec
 ; GFX11-NEXT:    v_cmpx_nle_f32_e32 0, v1
-; GFX11-NEXT:    s_xor_b64 s[4:5], exec, s[4:5]
+; GFX11-NEXT:    s_xor_b64 s[2:3], exec, s[2:3]
 ; GFX11-NEXT:    s_cbranch_execz .LBB13_3
 ; GFX11-NEXT:  ; %bb.1: ; %bb3
 ; GFX11-NEXT:    v_cmp_ngt_f32_e32 vcc, 0, v0
-; GFX11-NEXT:    s_and_not1_b64 s[2:3], s[2:3], vcc
+; GFX11-NEXT:    s_and_not1_b64 s[0:1], s[0:1], vcc
 ; GFX11-NEXT:    s_cbranch_scc0 .LBB13_6
 ; GFX11-NEXT:  ; %bb.2: ; %bb3
 ; GFX11-NEXT:    s_and_not1_b64 exec, exec, vcc
 ; GFX11-NEXT:  .LBB13_3: ; %bb4
 ; GFX11-NEXT:    s_delay_alu instid0(SALU_CYCLE_1)
-; GFX11-NEXT:    s_or_b64 exec, exec, s[4:5]
-; GFX11-NEXT:    s_mov_b32 s1, s0
-; GFX11-NEXT:    s_mov_b32 s2, s0
-; GFX11-NEXT:    s_mov_b32 s3, s0
-; GFX11-NEXT:    s_mov_b32 s4, s0
-; GFX11-NEXT:    s_mov_b32 s5, s0
-; GFX11-NEXT:    s_mov_b32 s6, s0
-; GFX11-NEXT:    s_mov_b32 s7, s0
+; GFX11-NEXT:    s_or_b64 exec, exec, s[2:3]
 ; GFX11-NEXT:    image_sample_c v0, v[2:3], s[0:7], s[0:3] dmask:0x10 dim:SQ_RSRC_IMG_1D
 ; GFX11-NEXT:    s_mov_b64 s[0:1], exec
 ; GFX11-NEXT:    s_waitcnt vmcnt(0)
@@ -1584,19 +1553,11 @@ bb9:                                              ; preds = %bb4
 define amdgpu_ps void @cbranch_kill(i32 inreg %0, float %val0, float %val1) {
 ; SI-LABEL: cbranch_kill:
 ; SI:       ; %bb.0: ; %.entry
-; SI-NEXT:    s_mov_b32 s4, 0
 ; SI-NEXT:    s_mov_b64 s[0:1], exec
 ; SI-NEXT:    v_mov_b32_e32 v4, 0
 ; SI-NEXT:    v_mov_b32_e32 v2, v1
 ; SI-NEXT:    v_mov_b32_e32 v3, v1
-; SI-NEXT:    s_mov_b32 s5, s4
-; SI-NEXT:    s_mov_b32 s6, s4
-; SI-NEXT:    s_mov_b32 s7, s4
-; SI-NEXT:    s_mov_b32 s8, s4
-; SI-NEXT:    s_mov_b32 s9, s4
-; SI-NEXT:    s_mov_b32 s10, s4
-; SI-NEXT:    s_mov_b32 s11, s4
-; SI-NEXT:    image_sample_l v1, v[1:4], s[4:11], s[0:3] dmask:0x1 da
+; SI-NEXT:    image_sample_l v1, v[1:4], s[0:7], s[0:3] dmask:0x1 da
 ; SI-NEXT:    s_waitcnt vmcnt(0)
 ; SI-NEXT:    v_cmp_ge_f32_e32 vcc, 0, v1
 ; SI-NEXT:    s_and_saveexec_b64 s[2:3], vcc
@@ -1627,16 +1588,8 @@ define amdgpu_ps void @cbranch_kill(i32 inreg %0, float %val0, float %val1) {
 ; GFX10-WAVE64-LABEL: cbranch_kill:
 ; GFX10-WAVE64:       ; %bb.0: ; %.entry
 ; GFX10-WAVE64-NEXT:    v_mov_b32_e32 v2, 0
-; GFX10-WAVE64-NEXT:    s_mov_b32 s4, 0
 ; GFX10-WAVE64-NEXT:    s_mov_b64 s[0:1], exec
-; GFX10-WAVE64-NEXT:    s_mov_b32 s5, s4
-; GFX10-WAVE64-NEXT:    s_mov_b32 s6, s4
-; GFX10-WAVE64-NEXT:    s_mov_b32 s7, s4
-; GFX10-WAVE64-NEXT:    s_mov_b32 s8, s4
-; GFX10-WAVE64-NEXT:    s_mov_b32 s9, s4
-; GFX10-WAVE64-NEXT:    s_mov_b32 s10, s4
-; GFX10-WAVE64-NEXT:    s_mov_b32 s11, s4
-; GFX10-WAVE64-NEXT:    image_sample_l v1, [v1, v1, v1, v2], s[4:11], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D_ARRAY
+; GFX10-WAVE64-NEXT:    image_sample_l v1, [v1, v1, v1, v2], s[0:7], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D_ARRAY
 ; GFX10-WAVE64-NEXT:    s_waitcnt vmcnt(0)
 ; GFX10-WAVE64-NEXT:    v_cmp_ge_f32_e32 vcc, 0, v1
 ; GFX10-WAVE64-NEXT:    s_and_saveexec_b64 s[2:3], vcc
@@ -1667,16 +1620,8 @@ define amdgpu_ps void @cbranch_kill(i32 inreg %0, float %val0, float %val1) {
 ; GFX10-WAVE32-LABEL: cbranch_kill:
 ; GFX10-WAVE32:       ; %bb.0: ; %.entry
 ; GFX10-WAVE32-NEXT:    v_mov_b32_e32 v2, 0
-; GFX10-WAVE32-NEXT:    s_mov_b32 s4, 0
 ; GFX10-WAVE32-NEXT:    s_mov_b32 s0, exec_lo
-; GFX10-WAVE32-NEXT:    s_mov_b32 s5, s4
-; GFX10-WAVE32-NEXT:    s_mov_b32 s6, s4
-; GFX10-WAVE32-NEXT:    s_mov_b32 s7, s4
-; GFX10-WAVE32-NEXT:    s_mov_b32 s8, s4
-; GFX10-WAVE32-NEXT:    s_mov_b32 s9, s4
-; GFX10-WAVE32-NEXT:    s_mov_b32 s10, s4
-; GFX10-WAVE32-NEXT:    s_mov_b32 s11, s4
-; GFX10-WAVE32-NEXT:    image_sample_l v1, [v1, v1, v1, v2], s[4:11], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D_ARRAY
+; GFX10-WAVE32-NEXT:    image_sample_l v1, [v1, v1, v1, v2], s[0:7], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D_ARRAY
 ; GFX10-WAVE32-NEXT:    s_waitcnt vmcnt(0)
 ; GFX10-WAVE32-NEXT:    v_cmp_ge_f32_e32 vcc_lo, 0, v1
 ; GFX10-WAVE32-NEXT:    s_and_saveexec_b32 s1, vcc_lo
@@ -1707,16 +1652,8 @@ define amdgpu_ps void @cbranch_kill(i32 inreg %0, float %val0, float %val1) {
 ; GFX11-LABEL: cbranch_kill:
 ; GFX11:       ; %bb.0: ; %.entry
 ; GFX11-NEXT:    v_mov_b32_e32 v2, 0
-; GFX11-NEXT:    s_mov_b32 s4, 0
 ; GFX11-NEXT:    s_mov_b64 s[0:1], exec
-; GFX11-NEXT:    s_mov_b32 s5, s4
-; GFX11-NEXT:    s_mov_b32 s6, s4
-; GFX11-NEXT:    s_mov_b32 s7, s4
-; GFX11-NEXT:    s_mov_b32 s8, s4
-; GFX11-NEXT:    s_mov_b32 s9, s4
-; GFX11-NEXT:    s_mov_b32 s10, s4
-; GFX11-NEXT:    s_mov_b32 s11, s4
-; GFX11-NEXT:    image_sample_l v1, [v1, v1, v1, v2], s[4:11], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D_ARRAY
+; GFX11-NEXT:    image_sample_l v1, [v1, v1, v1, v2], s[0:7], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D_ARRAY
 ; GFX11-NEXT:    s_mov_b64 s[2:3], exec
 ; GFX11-NEXT:    s_waitcnt vmcnt(0)
 ; GFX11-NEXT:    v_cmpx_ge_f32_e32 0, v1
diff --git a/llvm/test/CodeGen/AMDGPU/v1024.ll b/llvm/test/CodeGen/AMDGPU/v1024.ll
index a5e0454a36344e..1326ba437f94ff 100644
--- a/llvm/test/CodeGen/AMDGPU/v1024.ll
+++ b/llvm/test/CodeGen/AMDGPU/v1024.ll
@@ -10,6 +10,7 @@ define amdgpu_kernel void @test_v1024() {
 entry:
   %alloca = alloca <32 x i32>, align 16, addrspace(5)
   %cast = bitcast <32 x i32> addrspace(5)* %alloca to i8 addrspace(5)*
+  call void @llvm.memset.p5i8.i32(i8 addrspace(5)* %cast, i8 0, i32 128, i1 false)
   br i1 undef, label %if.then.i.i, label %if.else.i
 
 if.then.i.i:                                      ; preds = %entry
@@ -24,6 +25,7 @@ if.then.i62.i:                                    ; preds = %if.else.i, %if.then
   ret void
 }
 
+declare void @llvm.memset.p5i8.i32(i8 addrspace(5)* nocapture readonly, i8, i32, i1 immarg)
 declare void @llvm.memcpy.p5i8.p5i8.i64(i8 addrspace(5)* nocapture writeonly, i8 addrspace(5)* nocapture readonly, i64, i1 immarg)
 
 declare void @llvm.memcpy.p1i8.p5i8.i64(i8 addrspace(1)* nocapture writeonly, i8 addrspace(5)* nocapture readonly, i64, i1 immarg)
diff --git a/llvm/test/CodeGen/AMDGPU/vgpr-tuple-allocation.ll b/llvm/test/CodeGen/AMDGPU/vgpr-tuple-allocation.ll
index 5164b072a6ddc7..ed0de729dafdfa 100644
--- a/llvm/test/CodeGen/AMDGPU/vgpr-tuple-allocation.ll
+++ b/llvm/test/CodeGen/AMDGPU/vgpr-tuple-allocation.ll
@@ -14,7 +14,6 @@ define <4 x float> @non_preserved_vgpr_tuple8(<8 x i32> %rsrc, <4 x i32> %samp,
 ; GFX9-NEXT:    s_or_saveexec_b64 s[4:5], -1
 ; GFX9-NEXT:    buffer_store_dword v40, off, s[0:3], s32 offset:16 ; 4-byte Folded Spill
 ; GFX9-NEXT:    s_mov_b64 exec, s[4:5]
-; GFX9-NEXT:    s_mov_b32 s4, 0
 ; GFX9-NEXT:    v_writelane_b32 v40, s33, 2
 ; GFX9-NEXT:    s_mov_b32 s33, s32
 ; GFX9-NEXT:    v_mov_b32_e32 v36, v16
@@ -22,13 +21,6 @@ define <4 x float> @non_preserved_vgpr_tuple8(<8 x i32> %rsrc, <4 x i32> %samp,
 ; GFX9-NEXT:    v_mov_b32_e32 v34, v14
 ; GFX9-NEXT:    v_mov_b32_e32 v33, v13
 ; GFX9-NEXT:    v_mov_b32_e32 v32, v12
-; GFX9-NEXT:    s_mov_b32 s5, s4
-; GFX9-NEXT:    s_mov_b32 s6, s4
-; GFX9-NEXT:    s_mov_b32 s7, s4
-; GFX9-NEXT:    s_mov_b32 s8, s4
-; GFX9-NEXT:    s_mov_b32 s9, s4
-; GFX9-NEXT:    s_mov_b32 s10, s4
-; GFX9-NEXT:    s_mov_b32 s11, s4
 ; GFX9-NEXT:    buffer_store_dword v41, off, s[0:3], s33 offset:12 ; 4-byte Folded Spill
 ; GFX9-NEXT:    buffer_store_dword v42, off, s[0:3], s33 offset:8 ; 4-byte Folded Spill
 ; GFX9-NEXT:    buffer_store_dword v43, off, s[0:3], s33 offset:4 ; 4-byte Folded Spill
@@ -82,16 +74,8 @@ define <4 x float> @non_preserved_vgpr_tuple8(<8 x i32> %rsrc, <4 x i32> %samp,
 ; GFX10-NEXT:    v_mov_b32_e32 v34, v14
 ; GFX10-NEXT:    v_mov_b32_e32 v33, v13
 ; GFX10-NEXT:    v_mov_b32_e32 v32, v12
-; GFX10-NEXT:    s_mov_b32 s4, 0
 ; GFX10-NEXT:    v_writelane_b32 v40, s33, 2
 ; GFX10-NEXT:    s_mov_b32 s33, s32
-; GFX10-NEXT:    s_mov_b32 s5, s4
-; GFX10-NEXT:    s_mov_b32 s6, s4
-; GFX10-NEXT:    s_mov_b32 s7, s4
-; GFX10-NEXT:    s_mov_b32 s8, s4
-; GFX10-NEXT:    s_mov_b32 s9, s4
-; GFX10-NEXT:    s_mov_b32 s10, s4
-; GFX10-NEXT:    s_mov_b32 s11, s4
 ; GFX10-NEXT:    buffer_store_dword v41, off, s[0:3], s33 offset:12 ; 4-byte Folded Spill
 ; GFX10-NEXT:    buffer_store_dword v42, off, s[0:3], s33 offset:8 ; 4-byte Folded Spill
 ; GFX10-NEXT:    buffer_store_dword v43, off, s[0:3], s33 offset:4 ; 4-byte Folded Spill
@@ -145,16 +129,8 @@ define <4 x float> @non_preserved_vgpr_tuple8(<8 x i32> %rsrc, <4 x i32> %samp,
 ; GFX11-NEXT:    v_dual_mov_b32 v36, v16 :: v_dual_mov_b32 v35, v15
 ; GFX11-NEXT:    v_dual_mov_b32 v34, v14 :: v_dual_mov_b32 v33, v13
 ; GFX11-NEXT:    v_mov_b32_e32 v32, v12
-; GFX11-NEXT:    s_mov_b32 s0, 0
 ; GFX11-NEXT:    v_writelane_b32 v40, s33, 2
 ; GFX11-NEXT:    s_mov_b32 s33, s32
-; GFX11-NEXT:    s_mov_b32 s1, s0
-; GFX11-NEXT:    s_mov_b32 s2, s0
-; GFX11-NEXT:    s_mov_b32 s3, s0
-; GFX11-NEXT:    s_mov_b32 s4, s0
-; GFX11-NEXT:    s_mov_b32 s5, s0
-; GFX11-NEXT:    s_mov_b32 s6, s0
-; GFX11-NEXT:    s_mov_b32 s7, s0
 ; GFX11-NEXT:    s_clause 0x3
 ; GFX11-NEXT:    scratch_store_b32 off, v41, s33 offset:12
 ; GFX11-NEXT:    scratch_store_b32 off, v42, s33 offset:8
@@ -225,65 +201,41 @@ define <4 x float> @call_preserved_vgpr_tuple8(<8 x i32> %rsrc, <4 x i32> %samp,
 ; GFX9-NEXT:    s_or_saveexec_b64 s[4:5], -1
 ; GFX9-NEXT:    buffer_store_dword v40, off, s[0:3], s32 offset:20 ; 4-byte Folded Spill
 ; GFX9-NEXT:    s_mov_b64 exec, s[4:5]
-; GFX9-NEXT:    v_writelane_b32 v40, s33, 10
-; GFX9-NEXT:    v_writelane_b32 v40, s30, 0
-; GFX9-NEXT:    v_writelane_b32 v40, s31, 1
-; GFX9-NEXT:    v_writelane_b32 v40, s36, 2
-; GFX9-NEXT:    v_writelane_b32 v40, s37, 3
-; GFX9-NEXT:    v_writelane_b32 v40, s38, 4
-; GFX9-NEXT:    v_writelane_b32 v40, s39, 5
-; GFX9-NEXT:    v_writelane_b32 v40, s40, 6
-; GFX9-NEXT:    v_writelane_b32 v40, s41, 7
+; GFX9-NEXT:    v_writelane_b32 v40, s33, 2
 ; GFX9-NEXT:    s_mov_b32 s33, s32
-; GFX9-NEXT:    v_writelane_b32 v40, s42, 8
-; GFX9-NEXT:    s_mov_b32 s36, 0
 ; GFX9-NEXT:    buffer_store_dword v41, off, s[0:3], s33 offset:16 ; 4-byte Folded Spill
 ; GFX9-NEXT:    buffer_store_dword v42, off, s[0:3], s33 offset:12 ; 4-byte Folded Spill
 ; GFX9-NEXT:    buffer_store_dword v43, off, s[0:3], s33 offset:8 ; 4-byte Folded Spill
 ; GFX9-NEXT:    buffer_store_dword v44, off, s[0:3], s33 offset:4 ; 4-byte Folded Spill
 ; GFX9-NEXT:    buffer_store_dword v45, off, s[0:3], s33 ; 4-byte Folded Spill
-; GFX9-NEXT:    v_writelane_b32 v40, s43, 9
 ; GFX9-NEXT:    v_mov_b32_e32 v45, v16
 ; GFX9-NEXT:    v_mov_b32_e32 v44, v15
 ; GFX9-NEXT:    v_mov_b32_e32 v43, v14
 ; GFX9-NEXT:    v_mov_b32_e32 v42, v13
 ; GFX9-NEXT:    v_mov_b32_e32 v41, v12
-; GFX9-NEXT:    s_mov_b32 s37, s36
-; GFX9-NEXT:    s_mov_b32 s38, s36
-; GFX9-NEXT:    s_mov_b32 s39, s36
-; GFX9-NEXT:    s_mov_b32 s40, s36
-; GFX9-NEXT:    s_mov_b32 s41, s36
-; GFX9-NEXT:    s_mov_b32 s42, s36
-; GFX9-NEXT:    s_mov_b32 s43, s36
-; GFX9-NEXT:    image_gather4_c_b_cl v[0:3], v[41:45], s[36:43], s[4:7] dmask:0x1
+; GFX9-NEXT:    image_gather4_c_b_cl v[0:3], v[41:45], s[4:11], s[4:7] dmask:0x1
 ; GFX9-NEXT:    s_addk_i32 s32, 0x800
 ; GFX9-NEXT:    s_getpc_b64 s[4:5]
 ; GFX9-NEXT:    s_add_u32 s4, s4, extern_func@gotpcrel32@lo+4
 ; GFX9-NEXT:    s_addc_u32 s5, s5, extern_func@gotpcrel32@hi+12
 ; GFX9-NEXT:    s_load_dwordx2 s[4:5], s[4:5], 0x0
+; GFX9-NEXT:    v_writelane_b32 v40, s30, 0
+; GFX9-NEXT:    v_writelane_b32 v40, s31, 1
 ; GFX9-NEXT:    s_waitcnt vmcnt(0)
 ; GFX9-NEXT:    global_store_dwordx4 v[0:1], v[0:3], off
 ; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
 ; GFX9-NEXT:    s_swappc_b64 s[30:31], s[4:5]
-; GFX9-NEXT:    image_gather4_c_b_cl v[0:3], v[41:45], s[36:43], s[4:7] dmask:0x1
+; GFX9-NEXT:    image_gather4_c_b_cl v[0:3], v[41:45], s[4:11], s[4:7] dmask:0x1
 ; GFX9-NEXT:    s_nop 0
 ; GFX9-NEXT:    buffer_load_dword v45, off, s[0:3], s33 ; 4-byte Folded Reload
 ; GFX9-NEXT:    buffer_load_dword v44, off, s[0:3], s33 offset:4 ; 4-byte Folded Reload
 ; GFX9-NEXT:    buffer_load_dword v43, off, s[0:3], s33 offset:8 ; 4-byte Folded Reload
 ; GFX9-NEXT:    buffer_load_dword v42, off, s[0:3], s33 offset:12 ; 4-byte Folded Reload
 ; GFX9-NEXT:    buffer_load_dword v41, off, s[0:3], s33 offset:16 ; 4-byte Folded Reload
-; GFX9-NEXT:    v_readlane_b32 s43, v40, 9
-; GFX9-NEXT:    v_readlane_b32 s42, v40, 8
-; GFX9-NEXT:    v_readlane_b32 s41, v40, 7
-; GFX9-NEXT:    v_readlane_b32 s40, v40, 6
-; GFX9-NEXT:    v_readlane_b32 s39, v40, 5
-; GFX9-NEXT:    v_readlane_b32 s38, v40, 4
-; GFX9-NEXT:    v_readlane_b32 s37, v40, 3
-; GFX9-NEXT:    v_readlane_b32 s36, v40, 2
 ; GFX9-NEXT:    v_readlane_b32 s31, v40, 1
 ; GFX9-NEXT:    v_readlane_b32 s30, v40, 0
 ; GFX9-NEXT:    s_addk_i32 s32, 0xf800
-; GFX9-NEXT:    v_readlane_b32 s33, v40, 10
+; GFX9-NEXT:    v_readlane_b32 s33, v40, 2
 ; GFX9-NEXT:    s_or_saveexec_b64 s[4:5], -1
 ; GFX9-NEXT:    buffer_load_dword v40, off, s[0:3], s32 offset:20 ; 4-byte Folded Reload
 ; GFX9-NEXT:    s_mov_b64 exec, s[4:5]
@@ -298,66 +250,42 @@ define <4 x float> @call_preserved_vgpr_tuple8(<8 x i32> %rsrc, <4 x i32> %samp,
 ; GFX10-NEXT:    buffer_store_dword v40, off, s[0:3], s32 offset:20 ; 4-byte Folded Spill
 ; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
 ; GFX10-NEXT:    s_mov_b32 exec_lo, s4
-; GFX10-NEXT:    v_writelane_b32 v40, s33, 10
+; GFX10-NEXT:    v_writelane_b32 v40, s33, 2
 ; GFX10-NEXT:    s_mov_b32 s33, s32
 ; GFX10-NEXT:    buffer_store_dword v41, off, s[0:3], s33 offset:16 ; 4-byte Folded Spill
 ; GFX10-NEXT:    buffer_store_dword v42, off, s[0:3], s33 offset:12 ; 4-byte Folded Spill
 ; GFX10-NEXT:    buffer_store_dword v43, off, s[0:3], s33 offset:8 ; 4-byte Folded Spill
 ; GFX10-NEXT:    buffer_store_dword v44, off, s[0:3], s33 offset:4 ; 4-byte Folded Spill
 ; GFX10-NEXT:    buffer_store_dword v45, off, s[0:3], s33 ; 4-byte Folded Spill
+; GFX10-NEXT:    image_gather4_c_b_cl v[0:3], v[12:16], s[4:11], s[4:7] dmask:0x1 dim:SQ_RSRC_IMG_2D
 ; GFX10-NEXT:    s_addk_i32 s32, 0x400
+; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
+; GFX10-NEXT:    s_getpc_b64 s[4:5]
+; GFX10-NEXT:    s_add_u32 s4, s4, extern_func@gotpcrel32@lo+4
+; GFX10-NEXT:    s_addc_u32 s5, s5, extern_func@gotpcrel32@hi+12
 ; GFX10-NEXT:    v_writelane_b32 v40, s30, 0
+; GFX10-NEXT:    s_load_dwordx2 s[4:5], s[4:5], 0x0
 ; GFX10-NEXT:    v_mov_b32_e32 v41, v16
 ; GFX10-NEXT:    v_mov_b32_e32 v42, v15
 ; GFX10-NEXT:    v_mov_b32_e32 v43, v14
-; GFX10-NEXT:    v_mov_b32_e32 v44, v13
 ; GFX10-NEXT:    v_writelane_b32 v40, s31, 1
+; GFX10-NEXT:    v_mov_b32_e32 v44, v13
 ; GFX10-NEXT:    v_mov_b32_e32 v45, v12
-; GFX10-NEXT:    v_writelane_b32 v40, s36, 2
-; GFX10-NEXT:    s_mov_b32 s36, 0
-; GFX10-NEXT:    v_writelane_b32 v40, s37, 3
-; GFX10-NEXT:    s_mov_b32 s37, s36
-; GFX10-NEXT:    v_writelane_b32 v40, s38, 4
-; GFX10-NEXT:    s_mov_b32 s38, s36
-; GFX10-NEXT:    v_writelane_b32 v40, s39, 5
-; GFX10-NEXT:    s_mov_b32 s39, s36
-; GFX10-NEXT:    v_writelane_b32 v40, s40, 6
-; GFX10-NEXT:    s_mov_b32 s40, s36
-; GFX10-NEXT:    v_writelane_b32 v40, s41, 7
-; GFX10-NEXT:    s_mov_b32 s41, s36
-; GFX10-NEXT:    v_writelane_b32 v40, s42, 8
-; GFX10-NEXT:    s_mov_b32 s42, s36
-; GFX10-NEXT:    v_writelane_b32 v40, s43, 9
-; GFX10-NEXT:    s_mov_b32 s43, s36
-; GFX10-NEXT:    image_gather4_c_b_cl v[0:3], v[12:16], s[36:43], s[4:7] dmask:0x1 dim:SQ_RSRC_IMG_2D
-; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
-; GFX10-NEXT:    s_getpc_b64 s[4:5]
-; GFX10-NEXT:    s_add_u32 s4, s4, extern_func@gotpcrel32@lo+4
-; GFX10-NEXT:    s_addc_u32 s5, s5, extern_func@gotpcrel32@hi+12
-; GFX10-NEXT:    s_load_dwordx2 s[4:5], s[4:5], 0x0
 ; GFX10-NEXT:    s_waitcnt vmcnt(0)
 ; GFX10-NEXT:    global_store_dwordx4 v[0:1], v[0:3], off
 ; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
 ; GFX10-NEXT:    s_swappc_b64 s[30:31], s[4:5]
-; GFX10-NEXT:    image_gather4_c_b_cl v[0:3], [v45, v44, v43, v42, v41], s[36:43], s[4:7] dmask:0x1 dim:SQ_RSRC_IMG_2D
+; GFX10-NEXT:    image_gather4_c_b_cl v[0:3], [v45, v44, v43, v42, v41], s[4:11], s[4:7] dmask:0x1 dim:SQ_RSRC_IMG_2D
 ; GFX10-NEXT:    s_clause 0x4
 ; GFX10-NEXT:    buffer_load_dword v45, off, s[0:3], s33
 ; GFX10-NEXT:    buffer_load_dword v44, off, s[0:3], s33 offset:4
 ; GFX10-NEXT:    buffer_load_dword v43, off, s[0:3], s33 offset:8
 ; GFX10-NEXT:    buffer_load_dword v42, off, s[0:3], s33 offset:12
 ; GFX10-NEXT:    buffer_load_dword v41, off, s[0:3], s33 offset:16
-; GFX10-NEXT:    v_readlane_b32 s43, v40, 9
-; GFX10-NEXT:    v_readlane_b32 s42, v40, 8
-; GFX10-NEXT:    v_readlane_b32 s41, v40, 7
-; GFX10-NEXT:    v_readlane_b32 s40, v40, 6
-; GFX10-NEXT:    v_readlane_b32 s39, v40, 5
-; GFX10-NEXT:    v_readlane_b32 s38, v40, 4
-; GFX10-NEXT:    v_readlane_b32 s37, v40, 3
-; GFX10-NEXT:    v_readlane_b32 s36, v40, 2
 ; GFX10-NEXT:    v_readlane_b32 s31, v40, 1
 ; GFX10-NEXT:    v_readlane_b32 s30, v40, 0
 ; GFX10-NEXT:    s_addk_i32 s32, 0xfc00
-; GFX10-NEXT:    v_readlane_b32 s33, v40, 10
+; GFX10-NEXT:    v_readlane_b32 s33, v40, 2
 ; GFX10-NEXT:    s_or_saveexec_b32 s4, -1
 ; GFX10-NEXT:    buffer_load_dword v40, off, s[0:3], s32 offset:20 ; 4-byte Folded Reload
 ; GFX10-NEXT:    s_waitcnt_depctr 0xffe3
@@ -372,7 +300,7 @@ define <4 x float> @call_preserved_vgpr_tuple8(<8 x i32> %rsrc, <4 x i32> %samp,
 ; GFX11-NEXT:    s_or_saveexec_b32 s0, -1
 ; GFX11-NEXT:    scratch_store_b32 off, v40, s32 offset:20 ; 4-byte Folded Spill
 ; GFX11-NEXT:    s_mov_b32 exec_lo, s0
-; GFX11-NEXT:    v_writelane_b32 v40, s33, 10
+; GFX11-NEXT:    v_writelane_b32 v40, s33, 2
 ; GFX11-NEXT:    s_mov_b32 s33, s32
 ; GFX11-NEXT:    s_clause 0x4
 ; GFX11-NEXT:    scratch_store_b32 off, v41, s33 offset:16
@@ -380,56 +308,32 @@ define <4 x float> @call_preserved_vgpr_tuple8(<8 x i32> %rsrc, <4 x i32> %samp,
 ; GFX11-NEXT:    scratch_store_b32 off, v43, s33 offset:8
 ; GFX11-NEXT:    scratch_store_b32 off, v44, s33 offset:4
 ; GFX11-NEXT:    scratch_store_b32 off, v45, s33
+; GFX11-NEXT:    image_gather4_c_b_cl v[0:3], v[12:16], s[0:7], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D
 ; GFX11-NEXT:    s_add_i32 s32, s32, 32
+; GFX11-NEXT:    s_getpc_b64 s[0:1]
+; GFX11-NEXT:    s_add_u32 s0, s0, extern_func@gotpcrel32@lo+4
+; GFX11-NEXT:    s_addc_u32 s1, s1, extern_func@gotpcrel32@hi+12
 ; GFX11-NEXT:    v_writelane_b32 v40, s30, 0
+; GFX11-NEXT:    s_load_b64 s[0:1], s[0:1], 0x0
 ; GFX11-NEXT:    v_dual_mov_b32 v41, v16 :: v_dual_mov_b32 v42, v15
 ; GFX11-NEXT:    v_dual_mov_b32 v43, v14 :: v_dual_mov_b32 v44, v13
 ; GFX11-NEXT:    v_writelane_b32 v40, s31, 1
 ; GFX11-NEXT:    v_mov_b32_e32 v45, v12
-; GFX11-NEXT:    v_writelane_b32 v40, s36, 2
-; GFX11-NEXT:    s_mov_b32 s36, 0
-; GFX11-NEXT:    v_writelane_b32 v40, s37, 3
-; GFX11-NEXT:    s_mov_b32 s37, s36
-; GFX11-NEXT:    v_writelane_b32 v40, s38, 4
-; GFX11-NEXT:    s_mov_b32 s38, s36
-; GFX11-NEXT:    v_writelane_b32 v40, s39, 5
-; GFX11-NEXT:    s_mov_b32 s39, s36
-; GFX11-NEXT:    v_writelane_b32 v40, s40, 6
-; GFX11-NEXT:    s_mov_b32 s40, s36
-; GFX11-NEXT:    v_writelane_b32 v40, s41, 7
-; GFX11-NEXT:    s_mov_b32 s41, s36
-; GFX11-NEXT:    v_writelane_b32 v40, s42, 8
-; GFX11-NEXT:    s_mov_b32 s42, s36
-; GFX11-NEXT:    v_writelane_b32 v40, s43, 9
-; GFX11-NEXT:    s_mov_b32 s43, s36
-; GFX11-NEXT:    image_gather4_c_b_cl v[0:3], v[12:16], s[36:43], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D
-; GFX11-NEXT:    s_getpc_b64 s[0:1]
-; GFX11-NEXT:    s_add_u32 s0, s0, extern_func@gotpcrel32@lo+4
-; GFX11-NEXT:    s_addc_u32 s1, s1, extern_func@gotpcrel32@hi+12
-; GFX11-NEXT:    s_load_b64 s[0:1], s[0:1], 0x0
 ; GFX11-NEXT:    s_waitcnt vmcnt(0)
 ; GFX11-NEXT:    global_store_b128 v[0:1], v[0:3], off
 ; GFX11-NEXT:    s_waitcnt lgkmcnt(0)
 ; GFX11-NEXT:    s_swappc_b64 s[30:31], s[0:1]
-; GFX11-NEXT:    image_gather4_c_b_cl v[0:3], [v45, v44, v43, v42, v41], s[36:43], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D
+; GFX11-NEXT:    image_gather4_c_b_cl v[0:3], [v45, v44, v43, v42, v41], s[0:7], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_2D
 ; GFX11-NEXT:    s_clause 0x4
 ; GFX11-NEXT:    scratch_load_b32 v45, off, s33
 ; GFX11-NEXT:    scratch_load_b32 v44, off, s33 offset:4
 ; GFX11-NEXT:    scratch_load_b32 v43, off, s33 offset:8
 ; GFX11-NEXT:    scratch_load_b32 v42, off, s33 offset:12
 ; GFX11-NEXT:    scratch_load_b32 v41, off, s33 offset:16
-; GFX11-NEXT:    v_readlane_b32 s43, v40, 9
-; GFX11-NEXT:    v_readlane_b32 s42, v40, 8
-; GFX11-NEXT:    v_readlane_b32 s41, v40, 7
-; GFX11-NEXT:    v_readlane_b32 s40, v40, 6
-; GFX11-NEXT:    v_readlane_b32 s39, v40, 5
-; GFX11-NEXT:    v_readlane_b32 s38, v40, 4
-; GFX11-NEXT:    v_readlane_b32 s37, v40, 3
-; GFX11-NEXT:    v_readlane_b32 s36, v40, 2
 ; GFX11-NEXT:    v_readlane_b32 s31, v40, 1
 ; GFX11-NEXT:    v_readlane_b32 s30, v40, 0
 ; GFX11-NEXT:    s_addk_i32 s32, 0xffe0
-; GFX11-NEXT:    v_readlane_b32 s33, v40, 10
+; GFX11-NEXT:    v_readlane_b32 s33, v40, 2
 ; GFX11-NEXT:    s_or_saveexec_b32 s0, -1
 ; GFX11-NEXT:    scratch_load_b32 v40, off, s32 offset:20 ; 4-byte Folded Reload
 ; GFX11-NEXT:    s_mov_b32 exec_lo, s0
diff --git a/llvm/test/CodeGen/AMDGPU/wqm.ll b/llvm/test/CodeGen/AMDGPU/wqm.ll
index dc85462631d4a7..16c30174657a5f 100644
--- a/llvm/test/CodeGen/AMDGPU/wqm.ll
+++ b/llvm/test/CodeGen/AMDGPU/wqm.ll
@@ -1833,87 +1833,54 @@ main_body:
 define amdgpu_ps <4 x float> @test_loop_vcc(<4 x float> %in) nounwind {
 ; GFX9-W64-LABEL: test_loop_vcc:
 ; GFX9-W64:       ; %bb.0: ; %entry
-; GFX9-W64-NEXT:    s_mov_b64 s[8:9], exec
+; GFX9-W64-NEXT:    s_mov_b64 s[0:1], exec
 ; GFX9-W64-NEXT:    s_wqm_b64 exec, exec
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v7, v3
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v6, v2
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v5, v1
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v4, v0
-; GFX9-W64-NEXT:    s_and_b64 exec, exec, s[8:9]
-; GFX9-W64-NEXT:    s_mov_b32 s0, 0
-; GFX9-W64-NEXT:    s_mov_b32 s1, s0
-; GFX9-W64-NEXT:    s_mov_b32 s2, s0
-; GFX9-W64-NEXT:    s_mov_b32 s3, s0
-; GFX9-W64-NEXT:    s_mov_b32 s4, s0
-; GFX9-W64-NEXT:    s_mov_b32 s5, s0
-; GFX9-W64-NEXT:    s_mov_b32 s6, s0
-; GFX9-W64-NEXT:    s_mov_b32 s7, s0
+; GFX9-W64-NEXT:    s_and_b64 exec, exec, s[0:1]
 ; GFX9-W64-NEXT:    image_store v[4:7], v0, s[0:7] dmask:0xf unorm
 ; GFX9-W64-NEXT:    s_wqm_b64 exec, exec
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v8, 0
-; GFX9-W64-NEXT:    s_mov_b32 s10, 0x40e00000
+; GFX9-W64-NEXT:    s_mov_b32 s4, 0x40e00000
 ; GFX9-W64-NEXT:    s_branch .LBB31_2
 ; GFX9-W64-NEXT:  .LBB31_1: ; %body
 ; GFX9-W64-NEXT:    ; in Loop: Header=BB31_2 Depth=1
-; GFX9-W64-NEXT:    s_mov_b32 s1, s0
-; GFX9-W64-NEXT:    s_mov_b32 s2, s0
-; GFX9-W64-NEXT:    s_mov_b32 s3, s0
-; GFX9-W64-NEXT:    s_mov_b32 s4, s0
-; GFX9-W64-NEXT:    s_mov_b32 s5, s0
-; GFX9-W64-NEXT:    s_mov_b32 s6, s0
-; GFX9-W64-NEXT:    s_mov_b32 s7, s0
 ; GFX9-W64-NEXT:    image_sample v[4:7], v0, s[0:7], s[0:3] dmask:0xf
 ; GFX9-W64-NEXT:    v_add_f32_e32 v8, 2.0, v8
-; GFX9-W64-NEXT:    s_mov_b64 s[2:3], 0
 ; GFX9-W64-NEXT:    s_cbranch_execz .LBB31_4
 ; GFX9-W64-NEXT:  .LBB31_2: ; %loop
 ; GFX9-W64-NEXT:    ; =>This Inner Loop Header: Depth=1
 ; GFX9-W64-NEXT:    s_waitcnt vmcnt(0)
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v0, v4
-; GFX9-W64-NEXT:    v_cmp_lt_f32_e32 vcc, s10, v8
+; GFX9-W64-NEXT:    v_cmp_lt_f32_e32 vcc, s4, v8
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v1, v5
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v2, v6
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v3, v7
 ; GFX9-W64-NEXT:    s_cbranch_vccz .LBB31_1
 ; GFX9-W64-NEXT:  ; %bb.3:
-; GFX9-W64-NEXT:    s_mov_b64 s[2:3], -1
 ; GFX9-W64-NEXT:    ; implicit-def: $vgpr4_vgpr5_vgpr6_vgpr7
 ; GFX9-W64-NEXT:    ; implicit-def: $vgpr8
 ; GFX9-W64-NEXT:  .LBB31_4: ; %break
-; GFX9-W64-NEXT:    s_and_b64 exec, exec, s[8:9]
+; GFX9-W64-NEXT:    s_and_b64 exec, exec, s[0:1]
 ; GFX9-W64-NEXT:    s_waitcnt vmcnt(0)
 ; GFX9-W64-NEXT:    ; return to shader part epilog
 ;
 ; GFX10-W32-LABEL: test_loop_vcc:
 ; GFX10-W32:       ; %bb.0: ; %entry
-; GFX10-W32-NEXT:    s_mov_b32 s8, exec_lo
+; GFX10-W32-NEXT:    s_mov_b32 s0, exec_lo
 ; GFX10-W32-NEXT:    s_wqm_b32 exec_lo, exec_lo
 ; GFX10-W32-NEXT:    v_mov_b32_e32 v8, 0
-; GFX10-W32-NEXT:    s_mov_b32 s0, 0
-; GFX10-W32-NEXT:    s_mov_b32 s1, s0
-; GFX10-W32-NEXT:    s_mov_b32 s2, s0
-; GFX10-W32-NEXT:    s_mov_b32 s3, s0
-; GFX10-W32-NEXT:    s_mov_b32 s4, s0
-; GFX10-W32-NEXT:    s_mov_b32 s5, s0
-; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s8
-; GFX10-W32-NEXT:    s_mov_b32 s6, s0
-; GFX10-W32-NEXT:    s_mov_b32 s7, s0
+; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s0
 ; GFX10-W32-NEXT:    image_store v[0:3], v0, s[0:7] dmask:0xf dim:SQ_RSRC_IMG_1D unorm
 ; GFX10-W32-NEXT:    s_wqm_b32 exec_lo, exec_lo
 ; GFX10-W32-NEXT:    s_branch .LBB31_2
 ; GFX10-W32-NEXT:    .p2align 6
 ; GFX10-W32-NEXT:  .LBB31_1: ; %body
 ; GFX10-W32-NEXT:    ; in Loop: Header=BB31_2 Depth=1
-; GFX10-W32-NEXT:    s_mov_b32 s1, s0
-; GFX10-W32-NEXT:    s_mov_b32 s2, s0
-; GFX10-W32-NEXT:    s_mov_b32 s3, s0
-; GFX10-W32-NEXT:    s_mov_b32 s4, s0
-; GFX10-W32-NEXT:    s_mov_b32 s5, s0
-; GFX10-W32-NEXT:    s_mov_b32 s6, s0
-; GFX10-W32-NEXT:    s_mov_b32 s7, s0
-; GFX10-W32-NEXT:    v_add_f32_e32 v8, 2.0, v8
 ; GFX10-W32-NEXT:    image_sample v[0:3], v4, s[0:7], s[0:3] dmask:0xf dim:SQ_RSRC_IMG_1D
-; GFX10-W32-NEXT:    s_mov_b32 s1, 0
+; GFX10-W32-NEXT:    v_add_f32_e32 v8, 2.0, v8
 ; GFX10-W32-NEXT:    s_cbranch_execz .LBB31_4
 ; GFX10-W32-NEXT:  .LBB31_2: ; %loop
 ; GFX10-W32-NEXT:    ; =>This Inner Loop Header: Depth=1
@@ -1925,11 +1892,10 @@ define amdgpu_ps <4 x float> @test_loop_vcc(<4 x float> %in) nounwind {
 ; GFX10-W32-NEXT:    v_mov_b32_e32 v4, v0
 ; GFX10-W32-NEXT:    s_cbranch_vccz .LBB31_1
 ; GFX10-W32-NEXT:  ; %bb.3:
-; GFX10-W32-NEXT:    s_mov_b32 s1, -1
 ; GFX10-W32-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
 ; GFX10-W32-NEXT:    ; implicit-def: $vgpr8
 ; GFX10-W32-NEXT:  .LBB31_4: ; %break
-; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s8
+; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s0
 ; GFX10-W32-NEXT:    s_waitcnt vmcnt(0)
 ; GFX10-W32-NEXT:    v_mov_b32_e32 v0, v4
 ; GFX10-W32-NEXT:    v_mov_b32_e32 v1, v5
@@ -1999,14 +1965,6 @@ define amdgpu_ps void @test_alloca(float %data, i32 %a, i32 %idx) nounwind {
 ; GFX9-W64-NEXT:    v_lshl_add_u32 v0, v2, 2, v0
 ; GFX9-W64-NEXT:    buffer_load_dword v0, v0, s[8:11], 0 offen
 ; GFX9-W64-NEXT:    s_and_b64 exec, exec, s[0:1]
-; GFX9-W64-NEXT:    s_mov_b32 s0, 0
-; GFX9-W64-NEXT:    s_mov_b32 s1, s0
-; GFX9-W64-NEXT:    s_mov_b32 s2, s0
-; GFX9-W64-NEXT:    s_mov_b32 s3, s0
-; GFX9-W64-NEXT:    s_mov_b32 s4, s0
-; GFX9-W64-NEXT:    s_mov_b32 s5, s0
-; GFX9-W64-NEXT:    s_mov_b32 s6, s0
-; GFX9-W64-NEXT:    s_mov_b32 s7, s0
 ; GFX9-W64-NEXT:    s_waitcnt vmcnt(0)
 ; GFX9-W64-NEXT:    image_sample v[0:3], v0, s[0:7], s[0:3] dmask:0xf
 ; GFX9-W64-NEXT:    s_waitcnt vmcnt(0)
@@ -2035,14 +1993,6 @@ define amdgpu_ps void @test_alloca(float %data, i32 %a, i32 %idx) nounwind {
 ; GFX10-W32-NEXT:    s_wqm_b32 exec_lo, exec_lo
 ; GFX10-W32-NEXT:    buffer_load_dword v0, v2, s[8:11], 0 offen
 ; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s0
-; GFX10-W32-NEXT:    s_mov_b32 s0, 0
-; GFX10-W32-NEXT:    s_mov_b32 s1, s0
-; GFX10-W32-NEXT:    s_mov_b32 s2, s0
-; GFX10-W32-NEXT:    s_mov_b32 s3, s0
-; GFX10-W32-NEXT:    s_mov_b32 s4, s0
-; GFX10-W32-NEXT:    s_mov_b32 s5, s0
-; GFX10-W32-NEXT:    s_mov_b32 s6, s0
-; GFX10-W32-NEXT:    s_mov_b32 s7, s0
 ; GFX10-W32-NEXT:    s_waitcnt vmcnt(0)
 ; GFX10-W32-NEXT:    image_sample v[0:3], v0, s[0:7], s[0:3] dmask:0xf dim:SQ_RSRC_IMG_1D
 ; GFX10-W32-NEXT:    s_waitcnt vmcnt(0)
@@ -2079,18 +2029,10 @@ entry:
 define amdgpu_ps <4 x float> @test_nonvoid_return() nounwind {
 ; GFX9-W64-LABEL: test_nonvoid_return:
 ; GFX9-W64:       ; %bb.0:
-; GFX9-W64-NEXT:    s_mov_b32 s0, 0
-; GFX9-W64-NEXT:    s_mov_b64 s[8:9], exec
-; GFX9-W64-NEXT:    s_mov_b32 s1, s0
-; GFX9-W64-NEXT:    s_mov_b32 s2, s0
-; GFX9-W64-NEXT:    s_mov_b32 s3, s0
-; GFX9-W64-NEXT:    s_mov_b32 s4, s0
-; GFX9-W64-NEXT:    s_mov_b32 s5, s0
-; GFX9-W64-NEXT:    s_mov_b32 s6, s0
-; GFX9-W64-NEXT:    s_mov_b32 s7, s0
+; GFX9-W64-NEXT:    s_mov_b64 s[0:1], exec
 ; GFX9-W64-NEXT:    s_wqm_b64 exec, exec
 ; GFX9-W64-NEXT:    image_sample v0, v0, s[0:7], s[0:3] dmask:0x1
-; GFX9-W64-NEXT:    s_and_b64 exec, exec, s[8:9]
+; GFX9-W64-NEXT:    s_and_b64 exec, exec, s[0:1]
 ; GFX9-W64-NEXT:    s_waitcnt vmcnt(0)
 ; GFX9-W64-NEXT:    image_sample v[0:3], v0, s[0:7], s[0:3] dmask:0xf
 ; GFX9-W64-NEXT:    s_waitcnt vmcnt(0)
@@ -2098,18 +2040,10 @@ define amdgpu_ps <4 x float> @test_nonvoid_return() nounwind {
 ;
 ; GFX10-W32-LABEL: test_nonvoid_return:
 ; GFX10-W32:       ; %bb.0:
-; GFX10-W32-NEXT:    s_mov_b32 s0, 0
-; GFX10-W32-NEXT:    s_mov_b32 s8, exec_lo
-; GFX10-W32-NEXT:    s_mov_b32 s1, s0
-; GFX10-W32-NEXT:    s_mov_b32 s2, s0
-; GFX10-W32-NEXT:    s_mov_b32 s3, s0
-; GFX10-W32-NEXT:    s_mov_b32 s4, s0
-; GFX10-W32-NEXT:    s_mov_b32 s5, s0
-; GFX10-W32-NEXT:    s_mov_b32 s6, s0
-; GFX10-W32-NEXT:    s_mov_b32 s7, s0
+; GFX10-W32-NEXT:    s_mov_b32 s0, exec_lo
 ; GFX10-W32-NEXT:    s_wqm_b32 exec_lo, exec_lo
 ; GFX10-W32-NEXT:    image_sample v0, v0, s[0:7], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_1D
-; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s8
+; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s0
 ; GFX10-W32-NEXT:    s_waitcnt vmcnt(0)
 ; GFX10-W32-NEXT:    image_sample v[0:3], v0, s[0:7], s[0:3] dmask:0xf dim:SQ_RSRC_IMG_1D
 ; GFX10-W32-NEXT:    s_waitcnt vmcnt(0)
@@ -2128,20 +2062,11 @@ define amdgpu_ps <4 x float> @test_nonvoid_return() nounwind {
 define amdgpu_ps <4 x float> @test_nonvoid_return_unreachable(i32 inreg %c) nounwind {
 ; GFX9-W64-LABEL: test_nonvoid_return_unreachable:
 ; GFX9-W64:       ; %bb.0: ; %entry
-; GFX9-W64-NEXT:    s_mov_b32 s4, 0
-; GFX9-W64-NEXT:    s_mov_b64 s[2:3], exec
-; GFX9-W64-NEXT:    s_mov_b32 s5, s4
-; GFX9-W64-NEXT:    s_mov_b32 s6, s4
-; GFX9-W64-NEXT:    s_mov_b32 s7, s4
-; GFX9-W64-NEXT:    s_mov_b32 s8, s4
-; GFX9-W64-NEXT:    s_mov_b32 s9, s4
-; GFX9-W64-NEXT:    s_mov_b32 s10, s4
-; GFX9-W64-NEXT:    s_mov_b32 s11, s4
 ; GFX9-W64-NEXT:    s_wqm_b64 exec, exec
-; GFX9-W64-NEXT:    image_sample v0, v0, s[4:11], s[0:3] dmask:0x1
-; GFX9-W64-NEXT:    s_and_b64 exec, exec, s[2:3]
+; GFX9-W64-NEXT:    image_sample v0, v0, s[0:7], s[0:3] dmask:0x1
+; GFX9-W64-NEXT:    s_and_b64 exec, exec, exec
 ; GFX9-W64-NEXT:    s_waitcnt vmcnt(0)
-; GFX9-W64-NEXT:    image_sample v[0:3], v0, s[4:11], s[0:3] dmask:0xf
+; GFX9-W64-NEXT:    image_sample v[0:3], v0, s[0:7], s[0:3] dmask:0xf
 ; GFX9-W64-NEXT:    s_cmp_lt_i32 s0, 1
 ; GFX9-W64-NEXT:    s_cbranch_scc0 .LBB34_2
 ; GFX9-W64-NEXT:  ; %bb.1: ; %else
@@ -2155,20 +2080,11 @@ define amdgpu_ps <4 x float> @test_nonvoid_return_unreachable(i32 inreg %c) noun
 ;
 ; GFX10-W32-LABEL: test_nonvoid_return_unreachable:
 ; GFX10-W32:       ; %bb.0: ; %entry
-; GFX10-W32-NEXT:    s_mov_b32 s4, 0
-; GFX10-W32-NEXT:    s_mov_b32 s1, exec_lo
-; GFX10-W32-NEXT:    s_mov_b32 s5, s4
-; GFX10-W32-NEXT:    s_mov_b32 s6, s4
-; GFX10-W32-NEXT:    s_mov_b32 s7, s4
-; GFX10-W32-NEXT:    s_mov_b32 s8, s4
-; GFX10-W32-NEXT:    s_mov_b32 s9, s4
-; GFX10-W32-NEXT:    s_mov_b32 s10, s4
-; GFX10-W32-NEXT:    s_mov_b32 s11, s4
 ; GFX10-W32-NEXT:    s_wqm_b32 exec_lo, exec_lo
-; GFX10-W32-NEXT:    image_sample v0, v0, s[4:11], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_1D
-; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s1
+; GFX10-W32-NEXT:    image_sample v0, v0, s[0:7], s[0:3] dmask:0x1 dim:SQ_RSRC_IMG_1D
+; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, exec_lo
 ; GFX10-W32-NEXT:    s_waitcnt vmcnt(0)
-; GFX10-W32-NEXT:    image_sample v[0:3], v0, s[4:11], s[0:3] dmask:0xf dim:SQ_RSRC_IMG_1D
+; GFX10-W32-NEXT:    image_sample v[0:3], v0, s[0:7], s[0:3] dmask:0xf dim:SQ_RSRC_IMG_1D
 ; GFX10-W32-NEXT:    s_cmp_lt_i32 s0, 1
 ; GFX10-W32-NEXT:    s_cbranch_scc0 .LBB34_2
 ; GFX10-W32-NEXT:  ; %bb.1: ; %else
@@ -2215,33 +2131,17 @@ define amdgpu_ps <4 x float> @test_scc(i32 inreg %sel, i32 %idx) #1 {
 ; GFX9-W64-NEXT:    s_cmp_lt_i32 s0, 1
 ; GFX9-W64-NEXT:    s_cbranch_scc0 .LBB35_2
 ; GFX9-W64-NEXT:  ; %bb.1: ; %else
-; GFX9-W64-NEXT:    s_mov_b32 s4, 0
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v0, 0
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v1, 1
-; GFX9-W64-NEXT:    s_mov_b32 s5, s4
-; GFX9-W64-NEXT:    s_mov_b32 s6, s4
-; GFX9-W64-NEXT:    s_mov_b32 s7, s4
-; GFX9-W64-NEXT:    s_mov_b32 s8, s4
-; GFX9-W64-NEXT:    s_mov_b32 s9, s4
-; GFX9-W64-NEXT:    s_mov_b32 s10, s4
-; GFX9-W64-NEXT:    s_mov_b32 s11, s4
-; GFX9-W64-NEXT:    image_sample v[0:3], v[0:1], s[4:11], s[0:3] dmask:0xf
+; GFX9-W64-NEXT:    image_sample v[0:3], v[0:1], s[0:7], s[0:3] dmask:0xf
 ; GFX9-W64-NEXT:    s_cbranch_execz .LBB35_3
 ; GFX9-W64-NEXT:    s_branch .LBB35_4
 ; GFX9-W64-NEXT:  .LBB35_2:
 ; GFX9-W64-NEXT:    ; implicit-def: $vgpr0_vgpr1_vgpr2_vgpr3
 ; GFX9-W64-NEXT:  .LBB35_3: ; %if
-; GFX9-W64-NEXT:    s_mov_b32 s4, 0
-; GFX9-W64-NEXT:    s_mov_b32 s5, s4
-; GFX9-W64-NEXT:    s_mov_b32 s6, s4
-; GFX9-W64-NEXT:    s_mov_b32 s7, s4
-; GFX9-W64-NEXT:    s_mov_b32 s8, s4
-; GFX9-W64-NEXT:    s_mov_b32 s9, s4
-; GFX9-W64-NEXT:    s_mov_b32 s10, s4
-; GFX9-W64-NEXT:    s_mov_b32 s11, s4
 ; GFX9-W64-NEXT:    s_waitcnt vmcnt(0)
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v0, 0
-; GFX9-W64-NEXT:    image_sample v[0:3], v0, s[4:11], s[0:3] dmask:0xf
+; GFX9-W64-NEXT:    image_sample v[0:3], v0, s[0:7], s[0:3] dmask:0xf
 ; GFX9-W64-NEXT:  .LBB35_4: ; %end
 ; GFX9-W64-NEXT:    s_and_b64 exec, exec, s[2:3]
 ; GFX9-W64-NEXT:    v_mov_b32_e32 v5, 1.0
@@ -2252,21 +2152,13 @@ define amdgpu_ps <4 x float> @test_scc(i32 inreg %sel, i32 %idx) #1 {
 ; GFX10-W32-LABEL: test_scc:
 ; GFX10-W32:       ; %bb.0: ; %main_body
 ; GFX10-W32-NEXT:    v_mov_b32_e32 v4, v0
-; GFX10-W32-NEXT:    s_mov_b32 s8, exec_lo
+; GFX10-W32-NEXT:    s_mov_b32 s1, exec_lo
 ; GFX10-W32-NEXT:    s_wqm_b32 exec_lo, exec_lo
 ; GFX10-W32-NEXT:    s_cmp_lt_i32 s0, 1
 ; GFX10-W32-NEXT:    s_cbranch_scc0 .LBB35_2
 ; GFX10-W32-NEXT:  ; %bb.1: ; %else
 ; GFX10-W32-NEXT:    v_mov_b32_e32 v0, 0
 ; GFX10-W32-NEXT:    v_mov_b32_e32 v1, 1
-; GFX10-W32-NEXT:    s_mov_b32 s0, 0
-; GFX10-W32-NEXT:    s_mov_b32 s1, s0
-; GFX10-W32-NEXT:    s_mov_b32 s2, s0
-; GFX10-W32-NEXT:    s_mov_b32 s3, s0
-; GFX10-W32-NEXT:    s_mov_b32 s4, s0
-; GFX10-W32-NEXT:    s_mov_b32 s5, s0
-; GFX10-W32-NEXT:    s_mov_b32 s6, s0
-; GFX10-W32-NEXT:    s_mov_b32 s7, s0
 ; GFX10-W32-NEXT:    image_sample v[0:3], v[0:1], s[0:7], s[0:3] dmask:0xf dim:SQ_RSRC_IMG_2D
 ; GFX10-W32-NEXT:    s_cbranch_execz .LBB35_3
 ; GFX10-W32-NEXT:    s_branch .LBB35_4
@@ -2275,17 +2167,9 @@ define amdgpu_ps <4 x float> @test_scc(i32 inreg %sel, i32 %idx) #1 {
 ; GFX10-W32-NEXT:  .LBB35_3: ; %if
 ; GFX10-W32-NEXT:    s_waitcnt vmcnt(0)
 ; GFX10-W32-NEXT:    v_mov_b32_e32 v0, 0
-; GFX10-W32-NEXT:    s_mov_b32 s0, 0
-; GFX10-W32-NEXT:    s_mov_b32 s1, s0
-; GFX10-W32-NEXT:    s_mov_b32 s2, s0
-; GFX10-W32-NEXT:    s_mov_b32 s3, s0
-; GFX10-W32-NEXT:    s_mov_b32 s4, s0
-; GFX10-W32-NEXT:    s_mov_b32 s5, s0
-; GFX10-W32-NEXT:    s_mov_b32 s6, s0
-; GFX10-W32-NEXT:    s_mov_b32 s7, s0
 ; GFX10-W32-NEXT:    image_sample v[0:3], v0, s[0:7], s[0:3] dmask:0xf dim:SQ_RSRC_IMG_1D
 ; GFX10-W32-NEXT:  .LBB35_4: ; %end
-; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s8
+; GFX10-W32-NEXT:    s_and_b32 exec_lo, exec_lo, s1
 ; GFX10-W32-NEXT:    v_mov_b32_e32 v5, 1.0
 ; GFX10-W32-NEXT:    buffer_store_dword v5, v4, s[0:3], 0 idxen
 ; GFX10-W32-NEXT:    s_waitcnt vmcnt(0)

From c8e7a87b1ed6b00dc2c3543a80c892d5948f8849 Mon Sep 17 00:00:00 2001
From: Sam James <sam@gentoo.org>
Date: Tue, 8 Nov 2022 01:36:43 +0000
Subject: [PATCH 34/84] [CMake] Fix -Wstrict-prototypes

Fixes warnings (or errors, if someone injects -Werror in their build system,
which happens in fact with some folks vendoring LLVM too) with Clang 16:
```
+/var/tmp/portage.notmp/portage/sys-devel/llvm-15.0.4/work/llvm_build-abi_x86_64.amd64/CMakeFiles/CMakeTmp/src.c:3:9: warning: a function declaration without a prototype
is deprecated in all versions of C [-Wstrict-prototypes]
-/var/tmp/portage.notmp/portage/sys-devel/llvm-14.0.4/work/llvm_build-abi_x86_64.amd64/CMakeFiles/CMakeTmp/src.c:3:9: error: a function declaration without a prototype is
deprecated in all versions of C [-Werror,-Wstrict-prototypes]
 int main() {return 0;}
         ^
          void
```

Differential Revision: https://reviews.llvm.org/D137503

(cherry picked from commit 32a2af44e1e882f13d1cc2817f0a8d4d8b375d4d)
---
 .../cmake/Modules/CompilerRTDarwinUtils.cmake |  2 +-
 compiler-rt/cmake/config-ix.cmake             |  2 +-
 compiler-rt/lib/builtins/CMakeLists.txt       |  2 +-
 libcxx/cmake/config-ix.cmake                  |  2 +-
 libcxxabi/cmake/config-ix.cmake               |  2 +-
 libunwind/cmake/config-ix.cmake               |  2 +-
 lldb/tools/debugserver/source/CMakeLists.txt  |  2 +-
 llvm/cmake/config-ix.cmake                    |  2 +-
 llvm/cmake/modules/FindFFI.cmake              |  2 +-
 llvm/cmake/modules/FindTerminfo.cmake         |  2 +-
 llvm/cmake/modules/FindZ3.cmake               |  3 ++-
 llvm/cmake/modules/HandleLLVMOptions.cmake    |  2 +-
 openmp/runtime/cmake/config-ix.cmake          |  2 +-
 polly/lib/External/CMakeLists.txt             | 24 +++++++++----------
 14 files changed, 26 insertions(+), 25 deletions(-)

diff --git a/compiler-rt/cmake/Modules/CompilerRTDarwinUtils.cmake b/compiler-rt/cmake/Modules/CompilerRTDarwinUtils.cmake
index 2c9983c6a1ae36..640c7e7124c99a 100644
--- a/compiler-rt/cmake/Modules/CompilerRTDarwinUtils.cmake
+++ b/compiler-rt/cmake/Modules/CompilerRTDarwinUtils.cmake
@@ -116,7 +116,7 @@ function(darwin_test_archs os valid_archs)
   if(NOT TEST_COMPILE_ONLY)
     message(STATUS "Finding valid architectures for ${os}...")
     set(SIMPLE_C ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/src.c)
-    file(WRITE ${SIMPLE_C} "#include <stdio.h>\nint main() { printf(__FILE__); return 0; }\n")
+    file(WRITE ${SIMPLE_C} "#include <stdio.h>\nint main(void) { printf(__FILE__); return 0; }\n")
 
     set(os_linker_flags)
     foreach(flag ${DARWIN_${os}_LINK_FLAGS})
diff --git a/compiler-rt/cmake/config-ix.cmake b/compiler-rt/cmake/config-ix.cmake
index cd45176cf2ba76..9077e8f9ffe044 100644
--- a/compiler-rt/cmake/config-ix.cmake
+++ b/compiler-rt/cmake/config-ix.cmake
@@ -209,7 +209,7 @@ set(COMPILER_RT_SUPPORTED_ARCH)
 # runtime libraries supported by our current compilers cross-compiling
 # abilities.
 set(SIMPLE_SOURCE ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/simple.cc)
-file(WRITE ${SIMPLE_SOURCE} "#include <stdlib.h>\n#include <stdio.h>\nint main() { printf(\"hello, world\"); }\n")
+file(WRITE ${SIMPLE_SOURCE} "#include <stdlib.h>\n#include <stdio.h>\nint main(void) { printf(\"hello, world\"); }\n")
 
 # Detect whether the current target platform is 32-bit or 64-bit, and setup
 # the correct commandline flags needed to attempt to target 32-bit and 64-bit.
diff --git a/compiler-rt/lib/builtins/CMakeLists.txt b/compiler-rt/lib/builtins/CMakeLists.txt
index ec668e294d6d72..df02682ae00f99 100644
--- a/compiler-rt/lib/builtins/CMakeLists.txt
+++ b/compiler-rt/lib/builtins/CMakeLists.txt
@@ -745,7 +745,7 @@ else ()
                            SOURCE "#if !(__ARM_FP & 0x8)
                                    #error No double-precision support!
                                    #endif
-                                   int main() { return 0; }")
+                                   int main(void) { return 0; }")
           if(NOT COMPILER_RT_HAS_${arch}_VFP_DP)
             list(REMOVE_ITEM ${arch}_SOURCES ${arm_Thumb1_VFPv2_DP_SOURCES})
           endif()
diff --git a/libcxx/cmake/config-ix.cmake b/libcxx/cmake/config-ix.cmake
index 209e6214a47180..e65d3207285284 100644
--- a/libcxx/cmake/config-ix.cmake
+++ b/libcxx/cmake/config-ix.cmake
@@ -94,7 +94,7 @@ if(CMAKE_CXX_COMPILER_ID MATCHES "Clang")
   set(CMAKE_REQUIRED_FLAGS "${CMAKE_REQUIRED_FLAGS} -Werror=unknown-pragmas")
   check_c_source_compiles("
 #pragma comment(lib, \"c\")
-int main() { return 0; }
+int main(void) { return 0; }
 " C_SUPPORTS_COMMENT_LIB_PRAGMA)
   cmake_pop_check_state()
 endif()
diff --git a/libcxxabi/cmake/config-ix.cmake b/libcxxabi/cmake/config-ix.cmake
index 079cabf25da5a2..fa16a108e98ad0 100644
--- a/libcxxabi/cmake/config-ix.cmake
+++ b/libcxxabi/cmake/config-ix.cmake
@@ -77,7 +77,7 @@ if(CMAKE_CXX_COMPILER_ID MATCHES "Clang")
   set(CMAKE_REQUIRED_FLAGS "${CMAKE_REQUIRED_FLAGS} -Werror=unknown-pragmas")
   check_c_source_compiles("
 #pragma comment(lib, \"c\")
-int main() { return 0; }
+int main(void) { return 0; }
 " C_SUPPORTS_COMMENT_LIB_PRAGMA)
   cmake_pop_check_state()
 endif()
diff --git a/libunwind/cmake/config-ix.cmake b/libunwind/cmake/config-ix.cmake
index c9b65b3cefc082..1b027cf3721390 100644
--- a/libunwind/cmake/config-ix.cmake
+++ b/libunwind/cmake/config-ix.cmake
@@ -85,7 +85,7 @@ if(CMAKE_CXX_COMPILER_ID MATCHES "Clang")
   set(CMAKE_REQUIRED_FLAGS "${CMAKE_REQUIRED_FLAGS} -Werror=unknown-pragmas")
   check_c_source_compiles("
 #pragma comment(lib, \"c\")
-int main() { return 0; }
+int main(void) { return 0; }
 " C_SUPPORTS_COMMENT_LIB_PRAGMA)
   cmake_pop_check_state()
 endif()
diff --git a/lldb/tools/debugserver/source/CMakeLists.txt b/lldb/tools/debugserver/source/CMakeLists.txt
index f636e387bf1f0b..c6e7e8cf49e85e 100644
--- a/lldb/tools/debugserver/source/CMakeLists.txt
+++ b/lldb/tools/debugserver/source/CMakeLists.txt
@@ -95,7 +95,7 @@ check_c_source_compiles(
     #else
     #error Not building for ARM64
     #endif
-    int main() { return 0; }
+    int main(void) { return 0; }
     "
     BUILDING_FOR_ARM64_OSX
 )
diff --git a/llvm/cmake/config-ix.cmake b/llvm/cmake/config-ix.cmake
index 83512760d8dde2..7e657fd1532de6 100644
--- a/llvm/cmake/config-ix.cmake
+++ b/llvm/cmake/config-ix.cmake
@@ -71,7 +71,7 @@ if(APPLE)
   CHECK_C_SOURCE_COMPILES("
      static const char *__crashreporter_info__ = 0;
      asm(\".desc ___crashreporter_info__, 0x10\");
-     int main() { return 0; }"
+     int main(void) { return 0; }"
     HAVE_CRASHREPORTER_INFO)
 endif()
 
diff --git a/llvm/cmake/modules/FindFFI.cmake b/llvm/cmake/modules/FindFFI.cmake
index b0d859af89598d..a493a89d630171 100644
--- a/llvm/cmake/modules/FindFFI.cmake
+++ b/llvm/cmake/modules/FindFFI.cmake
@@ -45,7 +45,7 @@ if(FFI_LIBRARIES)
     struct ffi_cif;
     typedef struct ffi_cif ffi_cif;
     void ffi_call(ffi_cif *cif, void (*fn)(void), void *rvalue, void **avalue);
-    int main() { ffi_call(0, 0, 0, 0); }"
+    int main(void) { ffi_call(0, 0, 0, 0); }"
     HAVE_FFI_CALL)
   cmake_pop_check_state()
 endif()
diff --git a/llvm/cmake/modules/FindTerminfo.cmake b/llvm/cmake/modules/FindTerminfo.cmake
index 65edb80fa69a8e..eef1f95853eb27 100644
--- a/llvm/cmake/modules/FindTerminfo.cmake
+++ b/llvm/cmake/modules/FindTerminfo.cmake
@@ -20,7 +20,7 @@ if(Terminfo_LIBRARIES)
   list(APPEND CMAKE_REQUIRED_LIBRARIES ${Terminfo_LIBRARIES})
   check_c_source_compiles("
     int setupterm(char *term, int filedes, int *errret);
-    int main() { return setupterm(0, 0, 0); }"
+    int main(void) { return setupterm(0, 0, 0); }"
     Terminfo_LINKABLE)
   cmake_pop_check_state()
 endif()
diff --git a/llvm/cmake/modules/FindZ3.cmake b/llvm/cmake/modules/FindZ3.cmake
index 118b1eac3b3222..6fb56d74184dbe 100644
--- a/llvm/cmake/modules/FindZ3.cmake
+++ b/llvm/cmake/modules/FindZ3.cmake
@@ -18,8 +18,9 @@ function(check_z3_version z3_include z3_lib)
   # The program that will be executed to print Z3's version.
   file(WRITE ${CMAKE_BINARY_DIR}${CMAKE_FILES_DIRECTORY}/CMakeTmp/testz3.cpp
        "#include <assert.h>
+        #include <stdio.h> 
         #include <z3.h>
-        int main() {
+        int main(void) {
           unsigned int major, minor, build, rev;
           Z3_get_version(&major, &minor, &build, &rev);
           printf(\"%u.%u.%u\", major, minor, build);
diff --git a/llvm/cmake/modules/HandleLLVMOptions.cmake b/llvm/cmake/modules/HandleLLVMOptions.cmake
index 56d05f5b5fcedf..0fca934be9cf33 100644
--- a/llvm/cmake/modules/HandleLLVMOptions.cmake
+++ b/llvm/cmake/modules/HandleLLVMOptions.cmake
@@ -779,7 +779,7 @@ if (LLVM_ENABLE_WARNINGS AND (LLVM_COMPILER_IS_GCC_COMPATIBLE OR CLANG_CL))
   # line is also a // comment.
   set(OLD_CMAKE_REQUIRED_FLAGS ${CMAKE_REQUIRED_FLAGS})
   set(CMAKE_REQUIRED_FLAGS "${CMAKE_REQUIRED_FLAGS} -Werror -Wcomment")
-  CHECK_C_SOURCE_COMPILES("// \\\\\\n//\\nint main() {return 0;}"
+  CHECK_C_SOURCE_COMPILES("// \\\\\\n//\\nint main(void) {return 0;}"
                           C_WCOMMENT_ALLOWS_LINE_WRAP)
   set(CMAKE_REQUIRED_FLAGS ${OLD_CMAKE_REQUIRED_FLAGS})
   if (NOT C_WCOMMENT_ALLOWS_LINE_WRAP)
diff --git a/openmp/runtime/cmake/config-ix.cmake b/openmp/runtime/cmake/config-ix.cmake
index 775c58f9848411..bd7585545b7252 100644
--- a/openmp/runtime/cmake/config-ix.cmake
+++ b/openmp/runtime/cmake/config-ix.cmake
@@ -27,7 +27,7 @@ function(libomp_check_version_symbols retval)
     void func2() { printf(\"World\"); }
     __asm__(\".symver func1, func@VER1\");
     __asm__(\".symver func2, func@VER2\");
-    int main() {
+    int main(void) {
       func1();
       func2();
       return 0;
diff --git a/polly/lib/External/CMakeLists.txt b/polly/lib/External/CMakeLists.txt
index 2f912e7daeb218..c0a5b32e283f2a 100644
--- a/polly/lib/External/CMakeLists.txt
+++ b/polly/lib/External/CMakeLists.txt
@@ -64,7 +64,7 @@ if (POLLY_BUNDLED_ISL)
     check_c_source_compiles("
     ${_includes}
     ${_type} typeVar;
-    int main() {
+    int main(void) {
     return 0;
     }
     " ${_variable})
@@ -73,7 +73,7 @@ if (POLLY_BUNDLED_ISL)
 
   check_c_source_compiles("
   int func(void) __attribute__((__warn_unused_result__));
-  int main() { return 0; }
+  int main(void) { return 0; }
   " HAS_ATTRIBUTE_WARN_UNUSED_RESULT)
   set(GCC_WARN_UNUSED_RESULT)
   if (HAS_ATTRIBUTE_WARN_UNUSED_RESULT)
@@ -82,22 +82,22 @@ if (POLLY_BUNDLED_ISL)
 
   check_c_source_compiles("
   __attribute__ ((unused)) static void foo(void);
-  int main() { return 0; }
+  int main(void) { return 0; }
   " HAVE___ATTRIBUTE__)
 
 
   check_c_source_compiles_numeric("
   #include <strings.h>
-  int main() { (void)ffs(0); return 0; }
+  int main(void) { (void)ffs(0); return 0; }
   " HAVE_DECL_FFS)
 
   check_c_source_compiles_numeric("
-  int main() { (void)__builtin_ffs(0); return 0; }
+  int main(void) { (void)__builtin_ffs(0); return 0; }
   " HAVE_DECL___BUILTIN_FFS)
 
   check_c_source_compiles_numeric("
   #include <intrin.h>
-  int main() { (void)_BitScanForward(NULL, 0); return 0; }
+  int main(void) { (void)_BitScanForward(NULL, 0); return 0; }
   " HAVE_DECL__BITSCANFORWARD)
 
   if (NOT HAVE_DECL_FFS AND
@@ -109,12 +109,12 @@ if (POLLY_BUNDLED_ISL)
 
   check_c_source_compiles_numeric("
   #include <strings.h>
-  int main() { (void)strcasecmp(\"\", \"\"); return 0; }
+  int main(void) { (void)strcasecmp(\"\", \"\"); return 0; }
   " HAVE_DECL_STRCASECMP)
 
   check_c_source_compiles_numeric("
   #include <string.h>
-  int main() { (void)_stricmp(\"\", \"\"); return 0; }
+  int main(void) { (void)_stricmp(\"\", \"\"); return 0; }
   " HAVE_DECL__STRICMP)
 
   if (NOT HAVE_DECL_STRCASECMP AND NOT HAVE_DECL__STRICMP)
@@ -124,12 +124,12 @@ if (POLLY_BUNDLED_ISL)
 
   check_c_source_compiles_numeric("
   #include <strings.h>
-  int main() { (void)strncasecmp(\"\", \"\", 0); return 0; }
+  int main(void) { (void)strncasecmp(\"\", \"\", 0); return 0; }
   " HAVE_DECL_STRNCASECMP)
 
   check_c_source_compiles_numeric("
   #include <string.h>
-  int main() { (void)_strnicmp(\"\", \"\", 0); return 0; }
+  int main(void) { (void)_strnicmp(\"\", \"\", 0); return 0; }
   " HAVE_DECL__STRNICMP)
 
   if (NOT HAVE_DECL_STRNCASECMP AND NOT HAVE_DECL__STRNICMP)
@@ -139,12 +139,12 @@ if (POLLY_BUNDLED_ISL)
 
   check_c_source_compiles_numeric("
   #include <stdio.h>
-  int main() { snprintf((void*)0, 0, \" \"); return 0; }
+  int main(void) { snprintf((void*)0, 0, \" \"); return 0; }
   " HAVE_DECL_SNPRINTF)
 
   check_c_source_compiles_numeric("
   #include <stdio.h>
-  int main() { _snprintf((void*)0, 0, \" \"); return 0; }
+  int main(void) { _snprintf((void*)0, 0, \" \"); return 0; }
   " HAVE_DECL__SNPRINTF)
 
   if (NOT HAVE_DECL_SNPRINTF AND NOT HAVE_DECL__SNPRINTF)

From 931b6d51d84e2a5cbbdc925d546819d4d3b7c63e Mon Sep 17 00:00:00 2001
From: Aaron Ballman <aaron@aaronballman.com>
Date: Wed, 2 Nov 2022 07:56:43 -0400
Subject: [PATCH 35/84] Reenable POSIX builtin library functions in gnu2x mode

gnu17 and earlier modes automatically expose several POSIX C APIs, and
this was accidentally disabled for gnu2x in
7d644e1215b376ec5e915df9ea2eeb56e2d94626.

This restores the behavior for gnu2x mode (without changing the
behavior in C standards modes instead of GNU modes).

Fixes #56607
---
 clang/docs/ReleaseNotes.rst    |  4 ++++
 clang/lib/Sema/SemaLookup.cpp  |  8 +++-----
 clang/test/Sema/gnu-builtins.c | 13 +++++++++++++
 3 files changed, 20 insertions(+), 5 deletions(-)
 create mode 100644 clang/test/Sema/gnu-builtins.c

diff --git a/clang/docs/ReleaseNotes.rst b/clang/docs/ReleaseNotes.rst
index a1ee8f0459aedb..13cca2ebbfb89d 100644
--- a/clang/docs/ReleaseNotes.rst
+++ b/clang/docs/ReleaseNotes.rst
@@ -227,6 +227,10 @@ Bug Fixes
   `Issue 57377 <https://github.com/llvm/llvm-project/issues/57377>`_.
 - Fix a crash when a ``btf_type_tag`` attribute is applied to the pointee of
   a function pointer.
+- Clang 14 predeclared some builtin POSIX library functions in ``gnu2x`` mode,
+  and Clang 15 accidentally stopped predeclaring those functions in that
+  language mode. Clang 16 now predeclares those functions again. This fixes
+  `Issue 56607 <https://github.com/llvm/llvm-project/issues/56607>`_.
 
 Improvements to Clang's diagnostics
 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
diff --git a/clang/lib/Sema/SemaLookup.cpp b/clang/lib/Sema/SemaLookup.cpp
index 68158ec977cfe9..5d0d87fd2422da 100644
--- a/clang/lib/Sema/SemaLookup.cpp
+++ b/clang/lib/Sema/SemaLookup.cpp
@@ -939,11 +939,9 @@ bool Sema::LookupBuiltin(LookupResult &R) {
 
       // If this is a builtin on this (or all) targets, create the decl.
       if (unsigned BuiltinID = II->getBuiltinID()) {
-        // In C++, C2x, and OpenCL (spec v1.2 s6.9.f), we don't have any
-        // predefined library functions like 'malloc'. Instead, we'll just
-        // error.
-        if ((getLangOpts().CPlusPlus || getLangOpts().OpenCL ||
-             getLangOpts().C2x) &&
+        // In C++ and OpenCL (spec v1.2 s6.9.f), we don't have any predefined
+        // library functions like 'malloc'. Instead, we'll just error.
+        if ((getLangOpts().CPlusPlus || getLangOpts().OpenCL) &&
             Context.BuiltinInfo.isPredefinedLibFunction(BuiltinID))
           return false;
 
diff --git a/clang/test/Sema/gnu-builtins.c b/clang/test/Sema/gnu-builtins.c
new file mode 100644
index 00000000000000..c4da8b39363cdd
--- /dev/null
+++ b/clang/test/Sema/gnu-builtins.c
@@ -0,0 +1,13 @@
+// RUN: %clang_cc1 -fsyntax-only -verify=gnu -std=gnu17 %s
+// RUN: %clang_cc1 -fsyntax-only -verify=gnu -std=gnu2x %s
+// RUN: %clang_cc1 -fsyntax-only -verify=std -std=c17 %s
+// RUN: %clang_cc1 -fsyntax-only -verify=std -std=c2x %s
+
+// std-no-diagnostics
+
+// 'index' is a builtin library function, but only in GNU mode. So this should
+// give an error in GNU modes but be okay in non-GNU mode.
+// FIXME: the error is correct, but these notes are pretty awful.
+int index; // gnu-error {{redefinition of 'index' as different kind of symbol}} \
+              gnu-note {{unguarded header; consider using #ifdef guards or #pragma once}} \
+              gnu-note {{previous definition is here}}

From 58ba50a52edeff3cae9cfa3bdd0ee000873ffef9 Mon Sep 17 00:00:00 2001
From: =?UTF-8?q?Micha=C5=82=20G=C3=B3rny?= <mgorny@gentoo.org>
Date: Mon, 7 Nov 2022 14:46:58 +0100
Subject: [PATCH 36/84] [cmake] Add missing CMakePushCheckState include to
 FindLibEdit.cmake

Add the missing include to fix an error when `cmake_push_check_state()`
is called and incidentally the CMakePushCheckState module is not loaded
by any other check running prior to `FindLibEdit.cmake`:

    CMake Error at /var/no-tmpfs/portage/dev-util/lldb-15.0.4/work/cmake/Modules/FindLibEdit.cmake:24 (cmake_push_check_state):
      Unknown CMake command "cmake_push_check_state".
    Call Stack (most recent call first):
      cmake/modules/LLDBConfig.cmake:52 (find_package)
      cmake/modules/LLDBConfig.cmake:59 (add_optional_dependency)
      CMakeLists.txt:28 (include)

Gentoo Bug: https://bugs.gentoo.org/880065

Differential Revision: https://reviews.llvm.org/D137555

(cherry picked from commit 3676a86a4322e8c2b9c541f057b5d3704146b8f3)
---
 cmake/Modules/FindLibEdit.cmake | 1 +
 1 file changed, 1 insertion(+)

diff --git a/cmake/Modules/FindLibEdit.cmake b/cmake/Modules/FindLibEdit.cmake
index 7e62d4d839ae17..de8f5a2e710137 100644
--- a/cmake/Modules/FindLibEdit.cmake
+++ b/cmake/Modules/FindLibEdit.cmake
@@ -21,6 +21,7 @@ find_library(LibEdit_LIBRARIES NAMES edit HINTS ${PC_LIBEDIT_LIBRARY_DIRS})
 
 include(CheckIncludeFile)
 if(LibEdit_INCLUDE_DIRS AND EXISTS "${LibEdit_INCLUDE_DIRS}/histedit.h")
+  include(CMakePushCheckState)
   cmake_push_check_state()
   list(APPEND CMAKE_REQUIRED_INCLUDES ${LibEdit_INCLUDE_DIRS})
   list(APPEND CMAKE_REQUIRED_LIBRARIES ${LibEdit_LIBRARIES})

From 6750e341b076d10a336c662ed6916500fdb20105 Mon Sep 17 00:00:00 2001
From: "chenglin.bi" <chenglin.bi@linaro.org>
Date: Wed, 9 Nov 2022 05:07:44 +0800
Subject: [PATCH 37/84] [TypePromotion] Replace Zext to Truncate for the case
 src bitwidth is larger

Fix: https://github.com/llvm/llvm-project/issues/58843

Reviewed By: samtebbs

Differential Revision: https://reviews.llvm.org/D137613

(cherry picked from commit 597f44409236bf7fa933a4ce18af23772e28fb43)
---
 llvm/lib/CodeGen/TypePromotion.cpp            |  8 +++++++-
 .../TypePromotion/AArch64/pr58843.ll          | 20 +++++++++++++++++++
 2 files changed, 27 insertions(+), 1 deletion(-)
 create mode 100644 llvm/test/Transforms/TypePromotion/AArch64/pr58843.ll

diff --git a/llvm/lib/CodeGen/TypePromotion.cpp b/llvm/lib/CodeGen/TypePromotion.cpp
index 8dc8d381ad1663..a63118067139fd 100644
--- a/llvm/lib/CodeGen/TypePromotion.cpp
+++ b/llvm/lib/CodeGen/TypePromotion.cpp
@@ -569,7 +569,8 @@ void IRPromoter::TruncateSinks() {
 void IRPromoter::Cleanup() {
   LLVM_DEBUG(dbgs() << "IR Promotion: Cleanup..\n");
   // Some zexts will now have become redundant, along with their trunc
-  // operands, so remove them
+  // operands, so remove them.
+  // Some zexts need to be replaced with truncate if src bitwidth is larger.
   for (auto *V : Visited) {
     if (!isa<ZExtInst>(V))
       continue;
@@ -584,6 +585,11 @@ void IRPromoter::Cleanup() {
                         << "\n");
       ReplaceAllUsersOfWith(ZExt, Src);
       continue;
+    } else if (ZExt->getSrcTy()->getScalarSizeInBits() > PromotedWidth) {
+      IRBuilder<> Builder{ZExt};
+      Value *Trunc = Builder.CreateTrunc(Src, ZExt->getDestTy());
+      ReplaceAllUsersOfWith(ZExt, Trunc);
+      continue;
     }
 
     // We've inserted a trunc for a zext sink, but we already know that the
diff --git a/llvm/test/Transforms/TypePromotion/AArch64/pr58843.ll b/llvm/test/Transforms/TypePromotion/AArch64/pr58843.ll
new file mode 100644
index 00000000000000..983a32029c6526
--- /dev/null
+++ b/llvm/test/Transforms/TypePromotion/AArch64/pr58843.ll
@@ -0,0 +1,20 @@
+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
+; RUN: opt -mtriple=aarch64 -type-promotion -verify -S %s -o - | FileCheck %s
+target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
+
+; Check the case don't crash due to zext source type bitwidth
+; larger than dest type bitwidth.
+define i1 @test(i8 %arg) {
+; CHECK-LABEL: @test(
+; CHECK-NEXT:    [[EXT1:%.*]] = zext i8 [[ARG:%.*]] to i64
+; CHECK-NEXT:    [[TMP1:%.*]] = and i64 [[EXT1]], 7
+; CHECK-NEXT:    [[TMP2:%.*]] = trunc i64 [[TMP1]] to i32
+; CHECK-NEXT:    [[CMP:%.*]] = icmp ne i32 [[TMP2]], 0
+; CHECK-NEXT:    ret i1 [[CMP]]
+;
+  %ext1 = zext i8 %arg to i64
+  %trunc = trunc i64 %ext1 to i3
+  %ext2 = zext i3 %trunc to i8
+  %cmp = icmp ne i8 %ext2, 0
+  ret i1 %cmp
+}

From d75ae21044ad893572855cefb0c0898a771b2094 Mon Sep 17 00:00:00 2001
From: Sam James <sam@gentoo.org>
Date: Wed, 19 Oct 2022 19:50:20 +0100
Subject: [PATCH 38/84] Set LLVM_ATOMIC_LIB variable for convenient linking
 against libatomic

* Set LLVM_ATOMIC_LIB to keep track of when we need to link against libatomic.
* Add detection of mold linker which is required for this.
* Use --as-needed when linking against libatomic as a bonus. On some platforms,
  libatomic may be required only sometimes.

Bug: https://bugs.gentoo.org/832675
Thanks-to: Arfrever Frehtes Taifersar Arahesis <Arfrever@Apache.Org>
Tested-by: erhard_f@mailbox.org <erhard_f@mailbox.org>

Differential Revision: https://reviews.llvm.org/D136280

(cherry picked from commit fa981b541365190ae646d2dce575706cd0626cf7)
---
 llvm/cmake/modules/AddLLVM.cmake     |  1 +
 llvm/cmake/modules/CheckAtomic.cmake | 13 +++++++++++++
 llvm/lib/Support/CMakeLists.txt      |  4 +---
 llvm/tools/dsymutil/CMakeLists.txt   |  4 +---
 4 files changed, 16 insertions(+), 6 deletions(-)

diff --git a/llvm/cmake/modules/AddLLVM.cmake b/llvm/cmake/modules/AddLLVM.cmake
index 057431208322e7..1f0507f395cf68 100644
--- a/llvm/cmake/modules/AddLLVM.cmake
+++ b/llvm/cmake/modules/AddLLVM.cmake
@@ -212,6 +212,7 @@ if (NOT DEFINED LLVM_LINKER_DETECTED AND NOT WIN32)
   else()
     if("${stdout}" MATCHES "^mold")
       set(LLVM_LINKER_DETECTED YES CACHE INTERNAL "")
+      set(LLVM_LINKER_IS_MOLD YES CACHE INTERNAL "")
       message(STATUS "Linker detection: mold")
     elseif("${stdout}" MATCHES "GNU gold")
       set(LLVM_LINKER_DETECTED YES CACHE INTERNAL "")
diff --git a/llvm/cmake/modules/CheckAtomic.cmake b/llvm/cmake/modules/CheckAtomic.cmake
index 3c5ba72993a3a1..f11cadf39ff6b6 100644
--- a/llvm/cmake/modules/CheckAtomic.cmake
+++ b/llvm/cmake/modules/CheckAtomic.cmake
@@ -82,6 +82,19 @@ elseif(LLVM_COMPILER_IS_GCC_COMPATIBLE OR CMAKE_CXX_COMPILER_ID MATCHES "XL")
   endif()
 endif()
 
+# Set variable LLVM_ATOMIC_LIB specifying flags for linking against libatomic.
+if(HAVE_CXX_ATOMICS_WITH_LIB OR HAVE_CXX_ATOMICS64_WITH_LIB)
+  # Use options --push-state, --as-needed and --pop-state if linker is known to support them.
+  # Use single option -Wl of compiler driver to avoid incorrect re-ordering of options by CMake.
+  if(LLVM_LINKER_IS_GNULD OR LLVM_LINKER_IS_GOLD OR LLVM_LINKER_IS_LLD OR LLVM_LINKER_IS_MOLD)
+    set(LLVM_ATOMIC_LIB "-Wl,--push-state,--as-needed,-latomic,--pop-state")
+  else()
+    set(LLVM_ATOMIC_LIB "-latomic")
+  endif()
+else()
+  set(LLVM_ATOMIC_LIB)
+endif()
+
 ## TODO: This define is only used for the legacy atomic operations in
 ## llvm's Atomic.h, which should be replaced.  Other code simply
 ## assumes C++11 <atomic> works.
diff --git a/llvm/lib/Support/CMakeLists.txt b/llvm/lib/Support/CMakeLists.txt
index 806cbc884cc5d8..ff23ec74df9628 100644
--- a/llvm/lib/Support/CMakeLists.txt
+++ b/llvm/lib/Support/CMakeLists.txt
@@ -59,9 +59,7 @@ elseif( CMAKE_HOST_UNIX )
   if( LLVM_ENABLE_TERMINFO )
     set(imported_libs ${imported_libs} Terminfo::terminfo)
   endif()
-  if( LLVM_ENABLE_THREADS AND (HAVE_LIBATOMIC OR HAVE_CXX_LIBATOMICS64) )
-    set(system_libs ${system_libs} atomic)
-  endif()
+  set(system_libs ${system_libs} ${LLVM_ATOMIC_LIB})
   set(system_libs ${system_libs} ${LLVM_PTHREAD_LIB})
   if( UNIX AND NOT (BEOS OR HAIKU) )
     set(system_libs ${system_libs} m)
diff --git a/llvm/tools/dsymutil/CMakeLists.txt b/llvm/tools/dsymutil/CMakeLists.txt
index a255c1c5daf51a..38028cd3d80a34 100644
--- a/llvm/tools/dsymutil/CMakeLists.txt
+++ b/llvm/tools/dsymutil/CMakeLists.txt
@@ -40,6 +40,4 @@ if(APPLE)
   target_link_libraries(dsymutil PRIVATE "-framework CoreFoundation")
 endif(APPLE)
 
-if(HAVE_CXX_ATOMICS_WITH_LIB OR HAVE_CXX_ATOMICS64_WITH_LIB)
-  target_link_libraries(dsymutil PRIVATE atomic)
-endif()
+target_link_libraries(dsymutil PRIVATE ${LLVM_ATOMIC_LIB})

From 4c3d83810ad7bde70b2665df9a15947695e92adb Mon Sep 17 00:00:00 2001
From: Sam James <sam@gentoo.org>
Date: Wed, 19 Oct 2022 20:09:34 +0100
Subject: [PATCH 39/84] Link liblldCOFF against libatomic when necessary

Also simplify code for liblldCommon using the new LLVM_ATOMIC_LIB variable.

Depends on D136280.

Bug: https://bugs.gentoo.org/832675
Thanks-to: Arfrever Frehtes Taifersar Arahesis <Arfrever@Apache.Org>
Tested-by: erhard_f@mailbox.org <erhard_f@mailbox.org>

Differential Revision: https://reviews.llvm.org/D136281

(cherry picked from commit f0b451c77f14947e3e7d314f048679fa2f5c6298)
---
 lld/COFF/CMakeLists.txt   | 1 +
 lld/Common/CMakeLists.txt | 9 ++-------
 2 files changed, 3 insertions(+), 7 deletions(-)

diff --git a/lld/COFF/CMakeLists.txt b/lld/COFF/CMakeLists.txt
index d289bd5910348a..55aec26854c8d8 100644
--- a/lld/COFF/CMakeLists.txt
+++ b/lld/COFF/CMakeLists.txt
@@ -44,6 +44,7 @@ add_lld_library(lldCOFF
   LINK_LIBS
   lldCommon
   ${LLVM_PTHREAD_LIB}
+  ${LLVM_ATOMIC_LIB}
 
   DEPENDS
   COFFOptionsTableGen
diff --git a/lld/Common/CMakeLists.txt b/lld/Common/CMakeLists.txt
index 1ae7da1f5f7f07..9c23ed39522350 100644
--- a/lld/Common/CMakeLists.txt
+++ b/lld/Common/CMakeLists.txt
@@ -1,9 +1,3 @@
-set(LLD_SYSTEM_LIBS ${LLVM_PTHREAD_LIB})
-
-if(NOT HAVE_CXX_ATOMICS64_WITHOUT_LIB)
-  list(APPEND LLD_SYSTEM_LIBS atomic)
-endif()
-
 find_first_existing_vc_file("${LLVM_MAIN_SRC_DIR}" llvm_vc)
 find_first_existing_vc_file("${LLD_SOURCE_DIR}" lld_vc)
 
@@ -54,7 +48,8 @@ add_lld_library(lldCommon
   Target
 
   LINK_LIBS
-  ${LLD_SYSTEM_LIBS}
+  ${LLVM_PTHREAD_LIB}
+  ${LLVM_ATOMIC_LIB}
 
   DEPENDS
   intrinsics_gen

From 0988addf2680b3717be47fd6f2493f33fe886f90 Mon Sep 17 00:00:00 2001
From: Sam James <sam@gentoo.org>
Date: Wed, 19 Oct 2022 20:12:10 +0100
Subject: [PATCH 40/84] Link libclangBasic against libatomic when necessary.

This is necessary at least on PPC32.

Depends on D136280.

Bug: https://bugs.gentoo.org/874024
Thanks-to: Arfrever Frehtes Taifersar Arahesis <Arfrever@Apache.Org>
Tested-by: erhard_f@mailbox.org <erhard_f@mailbox.org>

Differential Revision: https://reviews.llvm.org/D136282

(cherry picked from commit 20132d8eaa68a6c53e152718beda1dc0f4c9ff6c)
---
 clang/CMakeLists.txt           | 1 +
 clang/lib/Basic/CMakeLists.txt | 4 ++++
 2 files changed, 5 insertions(+)

diff --git a/clang/CMakeLists.txt b/clang/CMakeLists.txt
index 13d76e7fd935a7..e3bc4b468fb66c 100644
--- a/clang/CMakeLists.txt
+++ b/clang/CMakeLists.txt
@@ -117,6 +117,7 @@ if(CLANG_BUILT_STANDALONE)
   include(TableGen)
   include(HandleLLVMOptions)
   include(VersionFromVCS)
+  include(CheckAtomic)
   include(GetErrcMessages)
   include(LLVMDistributionSupport)
 
diff --git a/clang/lib/Basic/CMakeLists.txt b/clang/lib/Basic/CMakeLists.txt
index 3e052c0cf99570..c38c9fddb4240e 100644
--- a/clang/lib/Basic/CMakeLists.txt
+++ b/clang/lib/Basic/CMakeLists.txt
@@ -110,3 +110,7 @@ add_clang_library(clangBasic
   omp_gen
   )
 
+target_link_libraries(clangBasic
+  PRIVATE
+  ${LLVM_ATOMIC_LIB}
+)

From 11c3a21f8d1ba21c7744ba9d272c26c2ce3c58a0 Mon Sep 17 00:00:00 2001
From: Balazs Benics <benicsbalazs@gmail.com>
Date: Thu, 13 Oct 2022 08:41:31 +0200
Subject: [PATCH 41/84] [analyzer] Workaround crash on encountering Class
 non-type template parameters

The Clang Static Analyzer will crash on this code:
```lang=C++
struct Box {
  int value;
};
template <Box V> int get() {
  return V.value;
}
template int get<Box{-1}>();
```
https://godbolt.org/z/5Yb1sMMMb

The problem is that we don't account for encountering `TemplateParamObjectDecl`s
within the `DeclRefExpr` handler in the `ExprEngine`.

IMO we should create a new memregion for representing such template
param objects, to model their language semantics.
Such as:
 - it should have global static storage
 - for two identical values, their addresses should be identical as well
http://eel.is/c%2B%2Bdraft/temp.param#8

I was thinking of introducing a `TemplateParamObjectRegion` under `DeclRegion`
for this purpose. It could have `TemplateParamObjectDecl` as a field.

The `TemplateParamObjectDecl::getValue()` returns `APValue`, which might
represent multiple levels of structures, unions and other goodies -
making the transformation from `APValue` to `SVal` a bit complicated.

That being said, for now, I think having `Unknowns` for such cases is
definitely an improvement to crashing, hence I'm proposing this patch.

Reviewed By: xazax.hun

Differential Revision: https://reviews.llvm.org/D135763

(cherry picked from commit b062ee7dc4515b0a42157717105839627d5542bb)
---
 clang/lib/StaticAnalyzer/Core/ExprEngine.cpp  |  6 ++++
 .../test/Analysis/template-param-objects.cpp  | 33 +++++++++++++++++++
 2 files changed, 39 insertions(+)
 create mode 100644 clang/test/Analysis/template-param-objects.cpp

diff --git a/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp b/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp
index 19149d0798229a..ab65612bce90ea 100644
--- a/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp
+++ b/clang/lib/StaticAnalyzer/Core/ExprEngine.cpp
@@ -2839,6 +2839,12 @@ void ExprEngine::VisitCommonDeclRefExpr(const Expr *Ex, const NamedDecl *D,
     return;
   }
 
+  if (const auto *TPO = dyn_cast<TemplateParamObjectDecl>(D)) {
+    // FIXME: We should meaningfully implement this.
+    (void)TPO;
+    return;
+  }
+
   llvm_unreachable("Support for this Decl not implemented.");
 }
 
diff --git a/clang/test/Analysis/template-param-objects.cpp b/clang/test/Analysis/template-param-objects.cpp
new file mode 100644
index 00000000000000..dde95fa62cb655
--- /dev/null
+++ b/clang/test/Analysis/template-param-objects.cpp
@@ -0,0 +1,33 @@
+// RUN: %clang_analyze_cc1 -analyzer-checker=core,debug.ExprInspection \
+// RUN:    -analyzer-config eagerly-assume=false -std=c++20 -verify %s
+
+template <class T> void clang_analyzer_dump(T);
+void clang_analyzer_eval(bool);
+
+struct Box {
+  int value;
+};
+bool operator ==(Box lhs, Box rhs) {
+  return lhs.value == rhs.value;
+}
+template <Box V> void dumps() {
+  clang_analyzer_dump(V);        // expected-warning {{lazyCompoundVal}}
+  clang_analyzer_dump(&V);       // expected-warning {{Unknown}}
+  clang_analyzer_dump(V.value);  // expected-warning {{Unknown}} FIXME: It should be '6 S32b'.
+  clang_analyzer_dump(&V.value); // expected-warning {{Unknown}}
+}
+template void dumps<Box{6}>();
+
+// [temp.param].7.3.2:
+// "All such template parameters in the program of the same type with the
+// same value denote the same template parameter object."
+template <Box A1, Box A2, Box B1, Box B2> void stable_addresses() {
+  clang_analyzer_eval(&A1 == &A2); // expected-warning {{UNKNOWN}} FIXME: It should be TRUE.
+  clang_analyzer_eval(&B1 == &B2); // expected-warning {{UNKNOWN}} FIXME: It should be TRUE.
+  clang_analyzer_eval(&A1 == &B2); // expected-warning {{UNKNOWN}} FIXME: It should be FALSE.
+
+  clang_analyzer_eval(A1 == A2); // expected-warning {{UNKNOWN}} FIXME: It should be TRUE.
+  clang_analyzer_eval(B1 == B2); // expected-warning {{UNKNOWN}} FIXME: It should be TRUE.
+  clang_analyzer_eval(A1 == B2); // expected-warning {{UNKNOWN}} FIXME: It should be FALSE.
+}
+template void stable_addresses<Box{1}, Box{1}, Box{2}, Box{2}>();

From 68799e789fc5f2a5ff25beffa4dc8828780c08fb Mon Sep 17 00:00:00 2001
From: Arthur Eubanks <aeubanks@google.com>
Date: Tue, 1 Nov 2022 11:37:10 -0700
Subject: [PATCH 42/84] [GlobalOpt] Don't remove inalloca from varargs
 functions

Varargs and inalloca have a weird interaction where varargs are actually
passed via the inalloca alloca. Removing inalloca breaks the varargs
because they're still not passed as separate arguments.

Fixes #58718

Reviewed By: rnk

Differential Revision: https://reviews.llvm.org/D137182

(cherry picked from commit 8c49b01a1ee051ab2c09be4cffc83656ccc0fbe6)
---
 llvm/lib/Transforms/IPO/GlobalOpt.cpp         |  2 +-
 .../Transforms/GlobalOpt/inalloca-varargs.ll  | 38 +++++++++++++++++++
 2 files changed, 39 insertions(+), 1 deletion(-)
 create mode 100644 llvm/test/Transforms/GlobalOpt/inalloca-varargs.ll

diff --git a/llvm/lib/Transforms/IPO/GlobalOpt.cpp b/llvm/lib/Transforms/IPO/GlobalOpt.cpp
index 6df0409256bbd3..6fc7b29c5b78ae 100644
--- a/llvm/lib/Transforms/IPO/GlobalOpt.cpp
+++ b/llvm/lib/Transforms/IPO/GlobalOpt.cpp
@@ -2003,7 +2003,7 @@ OptimizeFunctions(Module &M,
     // FIXME: We should also hoist alloca affected by this to the entry
     // block if possible.
     if (F.getAttributes().hasAttrSomewhere(Attribute::InAlloca) &&
-        !F.hasAddressTaken() && !hasMustTailCallers(&F)) {
+        !F.hasAddressTaken() && !hasMustTailCallers(&F) && !F.isVarArg()) {
       RemoveAttribute(&F, Attribute::InAlloca);
       Changed = true;
     }
diff --git a/llvm/test/Transforms/GlobalOpt/inalloca-varargs.ll b/llvm/test/Transforms/GlobalOpt/inalloca-varargs.ll
new file mode 100644
index 00000000000000..188210782edd98
--- /dev/null
+++ b/llvm/test/Transforms/GlobalOpt/inalloca-varargs.ll
@@ -0,0 +1,38 @@
+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature
+; RUN: opt -passes=globalopt -S < %s | FileCheck %s
+
+define i32 @main(ptr %a) {
+; CHECK-LABEL: define {{[^@]+}}@main
+; CHECK-SAME: (ptr [[A:%.*]]) local_unnamed_addr {
+; CHECK-NEXT:    [[ARGMEM:%.*]] = alloca inalloca <{ ptr, i32 }>, align 4
+; CHECK-NEXT:    store ptr [[A]], ptr [[ARGMEM]], align 8
+; CHECK-NEXT:    [[G0:%.*]] = getelementptr inbounds <{ ptr, i32 }>, ptr [[ARGMEM]], i32 0, i32 1
+; CHECK-NEXT:    store i32 5, ptr [[G0]], align 4
+; CHECK-NEXT:    [[CALL3:%.*]] = call i32 (ptr, ...) @i(ptr inalloca(ptr) [[ARGMEM]])
+; CHECK-NEXT:    ret i32 [[CALL3]]
+;
+  %argmem = alloca inalloca <{ ptr, i32 }>, align 4
+  store ptr %a, ptr %argmem, align 8
+  %g0 = getelementptr inbounds <{ ptr, i32 }>, ptr %argmem, i32 0, i32 1
+  store i32 5, ptr %g0, align 4
+  %call3 = call i32 (ptr, ...) @i(ptr inalloca(ptr) %argmem)
+  ret i32 %call3
+}
+
+define internal i32 @i(ptr inalloca(ptr) %a, ...) {
+; CHECK-LABEL: define {{[^@]+}}@i
+; CHECK-SAME: (ptr inalloca(ptr) [[A:%.*]], ...) unnamed_addr {
+; CHECK-NEXT:    [[AP:%.*]] = alloca ptr, align 4
+; CHECK-NEXT:    call void @llvm.va_start(ptr [[AP]])
+; CHECK-NEXT:    [[ARGP_CUR:%.*]] = load ptr, ptr [[AP]], align 4
+; CHECK-NEXT:    [[L:%.*]] = load i32, ptr [[ARGP_CUR]], align 4
+; CHECK-NEXT:    ret i32 [[L]]
+;
+  %ap = alloca ptr, align 4
+  call void @llvm.va_start(ptr %ap)
+  %argp.cur = load ptr, ptr %ap, align 4
+  %l = load i32, ptr %argp.cur, align 4
+  ret i32 %l
+}
+
+declare void @llvm.va_start(ptr)

From 392963bb1daf7ec8822a0f02929a8ada17eb0a0a Mon Sep 17 00:00:00 2001
From: Jitka Plesnikova <jplesnik@redhat.com>
Date: Wed, 21 Sep 2022 11:42:46 +0200
Subject: [PATCH 43/84] [lldb] Fix 'error: non-const lvalue...' caused by SWIG
 4.1.0

Fix the failure caused by change in SwigValueWraper for C++11 and later
for improved move semantics in SWIG commit.

https://github.com/swig/swig/commit/d1055f4b3d51cb8060893f8036846ac743302dab
(cherry picked from commit f0a25fe0b746f56295d5c02116ba28d2f965c175)
---
 lldb/bindings/python/python-typemaps.swig | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/lldb/bindings/python/python-typemaps.swig b/lldb/bindings/python/python-typemaps.swig
index bf3de66b91bf1a..d45431c771ca3b 100644
--- a/lldb/bindings/python/python-typemaps.swig
+++ b/lldb/bindings/python/python-typemaps.swig
@@ -435,7 +435,7 @@ template <> bool SetNumberFromPyObject<double>(double &number, PyObject *obj) {
 
 %typemap(out) lldb::FileSP {
   $result = nullptr;
-  lldb::FileSP &sp = $1;
+  const lldb::FileSP &sp = $1;
   if (sp) {
     PythonFile pyfile = unwrapOrSetPythonException(PythonFile::FromFile(*sp));
     if (!pyfile.IsValid())

From dc8f6ffc3bf297098a1dfd3fbce801afbe9f5238 Mon Sep 17 00:00:00 2001
From: serge-sans-paille <sguelton@redhat.com>
Date: Thu, 29 Sep 2022 21:48:38 +0200
Subject: [PATCH 44/84] [lldb] Get rid of __STDC_LIMIT_MACROS and
 __STDC_CONSTANT_MACROS

C++11 made the use of these macro obsolete, see https://sourceware.org/bugzilla/show_bug.cgi?id=15366

As a side effect this prevents https://github.com/swig/swig/issues/2193.

Differential Revision: https://reviews.llvm.org/D134877

(cherry picked from commit 81fc5f7909a4ef5a8d4b5da2a10f77f7cb01ba63)
---
 lldb/bindings/CMakeLists.txt  | 2 --
 lldb/bindings/interfaces.swig | 3 ---
 2 files changed, 5 deletions(-)

diff --git a/lldb/bindings/CMakeLists.txt b/lldb/bindings/CMakeLists.txt
index c8aa0bcf968178..9eed2f1e629994 100644
--- a/lldb/bindings/CMakeLists.txt
+++ b/lldb/bindings/CMakeLists.txt
@@ -26,8 +26,6 @@ set(SWIG_COMMON_FLAGS
   -features autodoc
   -I${LLDB_SOURCE_DIR}/include
   -I${CMAKE_CURRENT_SOURCE_DIR}
-  -D__STDC_LIMIT_MACROS
-  -D__STDC_CONSTANT_MACROS
   ${DARWIN_EXTRAS}
 )
 
diff --git a/lldb/bindings/interfaces.swig b/lldb/bindings/interfaces.swig
index c9a6d0f0605686..021c7683d1709b 100644
--- a/lldb/bindings/interfaces.swig
+++ b/lldb/bindings/interfaces.swig
@@ -1,8 +1,5 @@
 /* Various liblldb typedefs that SWIG needs to know about.  */
 #define __extension__ /* Undefine GCC keyword to make Swig happy when processing glibc's stdint.h. */
-/* The ISO C99 standard specifies that in C++ implementations limit macros such
-   as INT32_MAX should only be defined if __STDC_LIMIT_MACROS is. */
-#define __STDC_LIMIT_MACROS
 %include "stdint.i"
 
 %include "lldb/lldb-defines.h"

From a399896637584c86acd61afca5bbfe8ed76a7c7d Mon Sep 17 00:00:00 2001
From: Florian Hahn <flo@fhahn.com>
Date: Sun, 13 Nov 2022 22:05:37 +0000
Subject: [PATCH 45/84] [VectorUtils] Skip interleave members with diff type
 and alloca sizes.

Currently, codegen doesn't support cases where the type size doesn't
match the alloc size. Skip them for now.

Fixes #58722.

(cherry picked from commit 758699c39984296f20a4dac44c6892065601c4cd)
---
 llvm/lib/Analysis/VectorUtils.cpp             |   7 +-
 ...interleave-allocsize-not-equal-typesize.ll | 141 ++++++++++++++++++
 2 files changed, 147 insertions(+), 1 deletion(-)
 create mode 100644 llvm/test/Transforms/LoopVectorize/AArch64/interleave-allocsize-not-equal-typesize.ll

diff --git a/llvm/lib/Analysis/VectorUtils.cpp b/llvm/lib/Analysis/VectorUtils.cpp
index c4795a80ead249..bc20f33f174c4e 100644
--- a/llvm/lib/Analysis/VectorUtils.cpp
+++ b/llvm/lib/Analysis/VectorUtils.cpp
@@ -1110,6 +1110,12 @@ void InterleavedAccessInfo::collectConstStrideAccesses(
         continue;
       Type *ElementTy = getLoadStoreType(&I);
 
+      // Currently, codegen doesn't support cases where the type size doesn't
+      // match the alloc size. Skip them for now.
+      uint64_t Size = DL.getTypeAllocSize(ElementTy);
+      if (Size * 8 != DL.getTypeSizeInBits(ElementTy))
+        continue;
+
       // We don't check wrapping here because we don't know yet if Ptr will be
       // part of a full group or a group with gaps. Checking wrapping for all
       // pointers (even those that end up in groups with no gaps) will be overly
@@ -1121,7 +1127,6 @@ void InterleavedAccessInfo::collectConstStrideAccesses(
                                     /*Assume=*/true, /*ShouldCheckWrap=*/false);
 
       const SCEV *Scev = replaceSymbolicStrideSCEV(PSE, Strides, Ptr);
-      uint64_t Size = DL.getTypeAllocSize(ElementTy);
       AccessStrideInfo[&I] = StrideDescriptor(Stride, Scev, Size,
                                               getLoadStoreAlignment(&I));
     }
diff --git a/llvm/test/Transforms/LoopVectorize/AArch64/interleave-allocsize-not-equal-typesize.ll b/llvm/test/Transforms/LoopVectorize/AArch64/interleave-allocsize-not-equal-typesize.ll
new file mode 100644
index 00000000000000..32ca12ee7e0ef3
--- /dev/null
+++ b/llvm/test/Transforms/LoopVectorize/AArch64/interleave-allocsize-not-equal-typesize.ll
@@ -0,0 +1,141 @@
+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
+; RUN: opt -passes=loop-vectorize -S %s | FileCheck %s
+
+target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
+target triple = "aarch64-unknown-linux-gnu"
+
+; Make sure LV does not crash when analyzing potential interleave groups with
+; accesses where the typesize doesn't match to allocsize.
+define void @pr58722_load_interleave_group(ptr %src, ptr %dst) {
+; CHECK-LABEL: @pr58722_load_interleave_group(
+; CHECK-NEXT:  entry:
+; CHECK-NEXT:    br i1 false, label [[SCALAR_PH:%.*]], label [[VECTOR_MEMCHECK:%.*]]
+; CHECK:       vector.memcheck:
+; CHECK-NEXT:    [[UGLYGEP:%.*]] = getelementptr i8, ptr [[DST:%.*]], i64 40004
+; CHECK-NEXT:    [[UGLYGEP1:%.*]] = getelementptr i8, ptr [[SRC:%.*]], i64 80007
+; CHECK-NEXT:    [[BOUND0:%.*]] = icmp ult ptr [[DST]], [[UGLYGEP1]]
+; CHECK-NEXT:    [[BOUND1:%.*]] = icmp ult ptr [[SRC]], [[UGLYGEP]]
+; CHECK-NEXT:    [[FOUND_CONFLICT:%.*]] = and i1 [[BOUND0]], [[BOUND1]]
+; CHECK-NEXT:    br i1 [[FOUND_CONFLICT]], label [[SCALAR_PH]], label [[VECTOR_PH:%.*]]
+; CHECK:       vector.ph:
+; CHECK-NEXT:    br label [[VECTOR_BODY:%.*]]
+; CHECK:       vector.body:
+; CHECK-NEXT:    [[INDEX:%.*]] = phi i64 [ 0, [[VECTOR_PH]] ], [ [[INDEX_NEXT:%.*]], [[VECTOR_BODY]] ]
+; CHECK-NEXT:    [[TMP0:%.*]] = add i64 [[INDEX]], 0
+; CHECK-NEXT:    [[TMP1:%.*]] = add i64 [[INDEX]], 1
+; CHECK-NEXT:    [[TMP2:%.*]] = add i64 [[INDEX]], 2
+; CHECK-NEXT:    [[TMP3:%.*]] = add i64 [[INDEX]], 3
+; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds i64, ptr [[SRC]], i64 [[TMP0]]
+; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds i64, ptr [[SRC]], i64 [[TMP1]]
+; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds i64, ptr [[SRC]], i64 [[TMP2]]
+; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds i64, ptr [[SRC]], i64 [[TMP3]]
+; CHECK-NEXT:    [[TMP8:%.*]] = load i32, ptr [[TMP4]], align 4, !alias.scope !0
+; CHECK-NEXT:    [[TMP9:%.*]] = load i32, ptr [[TMP5]], align 4, !alias.scope !0
+; CHECK-NEXT:    [[TMP10:%.*]] = insertelement <2 x i32> poison, i32 [[TMP8]], i32 0
+; CHECK-NEXT:    [[TMP11:%.*]] = insertelement <2 x i32> [[TMP10]], i32 [[TMP9]], i32 1
+; CHECK-NEXT:    [[TMP12:%.*]] = load i32, ptr [[TMP6]], align 4, !alias.scope !0
+; CHECK-NEXT:    [[TMP13:%.*]] = load i32, ptr [[TMP7]], align 4, !alias.scope !0
+; CHECK-NEXT:    [[TMP14:%.*]] = insertelement <2 x i32> poison, i32 [[TMP12]], i32 0
+; CHECK-NEXT:    [[TMP15:%.*]] = insertelement <2 x i32> [[TMP14]], i32 [[TMP13]], i32 1
+; CHECK-NEXT:    [[TMP16:%.*]] = getelementptr inbounds i32, ptr [[TMP4]], i64 1
+; CHECK-NEXT:    [[TMP17:%.*]] = getelementptr inbounds i32, ptr [[TMP5]], i64 1
+; CHECK-NEXT:    [[TMP18:%.*]] = getelementptr inbounds i32, ptr [[TMP6]], i64 1
+; CHECK-NEXT:    [[TMP19:%.*]] = getelementptr inbounds i32, ptr [[TMP7]], i64 1
+; CHECK-NEXT:    [[TMP20:%.*]] = load i24, ptr [[TMP16]], align 4, !alias.scope !0
+; CHECK-NEXT:    [[TMP21:%.*]] = load i24, ptr [[TMP17]], align 4, !alias.scope !0
+; CHECK-NEXT:    [[TMP22:%.*]] = insertelement <2 x i24> poison, i24 [[TMP20]], i32 0
+; CHECK-NEXT:    [[TMP23:%.*]] = insertelement <2 x i24> [[TMP22]], i24 [[TMP21]], i32 1
+; CHECK-NEXT:    [[TMP24:%.*]] = load i24, ptr [[TMP18]], align 4, !alias.scope !0
+; CHECK-NEXT:    [[TMP25:%.*]] = load i24, ptr [[TMP19]], align 4, !alias.scope !0
+; CHECK-NEXT:    [[TMP26:%.*]] = insertelement <2 x i24> poison, i24 [[TMP24]], i32 0
+; CHECK-NEXT:    [[TMP27:%.*]] = insertelement <2 x i24> [[TMP26]], i24 [[TMP25]], i32 1
+; CHECK-NEXT:    [[TMP28:%.*]] = zext <2 x i24> [[TMP23]] to <2 x i32>
+; CHECK-NEXT:    [[TMP29:%.*]] = zext <2 x i24> [[TMP27]] to <2 x i32>
+; CHECK-NEXT:    [[TMP30:%.*]] = add <2 x i32> [[TMP11]], [[TMP28]]
+; CHECK-NEXT:    [[TMP31:%.*]] = add <2 x i32> [[TMP15]], [[TMP29]]
+; CHECK-NEXT:    [[TMP32:%.*]] = getelementptr inbounds i32, ptr [[DST]], i64 [[TMP0]]
+; CHECK-NEXT:    [[TMP33:%.*]] = getelementptr inbounds i32, ptr [[DST]], i64 [[TMP2]]
+; CHECK-NEXT:    [[TMP34:%.*]] = getelementptr inbounds i32, ptr [[TMP32]], i32 0
+; CHECK-NEXT:    store <2 x i32> [[TMP30]], ptr [[TMP34]], align 4, !alias.scope !3, !noalias !0
+; CHECK-NEXT:    [[TMP35:%.*]] = getelementptr inbounds i32, ptr [[TMP32]], i32 2
+; CHECK-NEXT:    store <2 x i32> [[TMP31]], ptr [[TMP35]], align 4, !alias.scope !3, !noalias !0
+; CHECK-NEXT:    [[INDEX_NEXT]] = add nuw i64 [[INDEX]], 4
+; CHECK-NEXT:    [[TMP36:%.*]] = icmp eq i64 [[INDEX_NEXT]], 10000
+; CHECK-NEXT:    br i1 [[TMP36]], label [[MIDDLE_BLOCK:%.*]], label [[VECTOR_BODY]], !llvm.loop [[LOOP5:![0-9]+]]
+; CHECK:       middle.block:
+; CHECK-NEXT:    [[CMP_N:%.*]] = icmp eq i64 10001, 10000
+; CHECK-NEXT:    br i1 [[CMP_N]], label [[EXIT:%.*]], label [[SCALAR_PH]]
+; CHECK:       scalar.ph:
+; CHECK-NEXT:    [[BC_RESUME_VAL:%.*]] = phi i64 [ 10000, [[MIDDLE_BLOCK]] ], [ 0, [[ENTRY:%.*]] ], [ 0, [[VECTOR_MEMCHECK]] ]
+; CHECK-NEXT:    br label [[LOOP:%.*]]
+; CHECK:       loop:
+; CHECK-NEXT:    [[IV:%.*]] = phi i64 [ [[BC_RESUME_VAL]], [[SCALAR_PH]] ], [ [[IV_NEXT:%.*]], [[LOOP]] ]
+; CHECK-NEXT:    [[GEP_IV:%.*]] = getelementptr inbounds i64, ptr [[SRC]], i64 [[IV]]
+; CHECK-NEXT:    [[V1:%.*]] = load i32, ptr [[GEP_IV]], align 4
+; CHECK-NEXT:    [[GEP:%.*]] = getelementptr inbounds i32, ptr [[GEP_IV]], i64 1
+; CHECK-NEXT:    [[V2:%.*]] = load i24, ptr [[GEP]], align 4
+; CHECK-NEXT:    [[V2_EXT:%.*]] = zext i24 [[V2]] to i32
+; CHECK-NEXT:    [[SUM:%.*]] = add i32 [[V1]], [[V2_EXT]]
+; CHECK-NEXT:    [[GEP_DST:%.*]] = getelementptr inbounds i32, ptr [[DST]], i64 [[IV]]
+; CHECK-NEXT:    store i32 [[SUM]], ptr [[GEP_DST]], align 4
+; CHECK-NEXT:    [[IV_NEXT]] = add i64 [[IV]], 1
+; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i64 [[IV]], 10000
+; CHECK-NEXT:    br i1 [[CMP]], label [[EXIT]], label [[LOOP]], !llvm.loop [[LOOP7:![0-9]+]]
+; CHECK:       exit:
+; CHECK-NEXT:    ret void
+;
+entry:
+  br label %loop
+
+loop:
+  %iv = phi i64 [ 0, %entry ], [ %iv.next, %loop ]
+  %gep.iv = getelementptr inbounds i64, ptr %src, i64 %iv
+  %v1 = load i32, ptr %gep.iv, align 4
+  %gep = getelementptr inbounds i32, ptr %gep.iv, i64 1
+  %v2 = load i24, ptr %gep, align 4
+  %v2.ext = zext i24 %v2 to i32
+  %sum = add i32 %v1, %v2.ext
+  %gep.dst = getelementptr inbounds i32, ptr %dst, i64 %iv
+  store i32 %sum, ptr %gep.dst
+  %iv.next = add i64 %iv, 1
+  %cmp = icmp eq i64 %iv, 10000
+  br i1 %cmp, label %exit, label %loop
+
+exit:
+  ret void
+}
+
+define void @pr58722_store_interleave_group(ptr %src, ptr %dst) {
+; CHECK-LABEL: @pr58722_store_interleave_group(
+; CHECK-NEXT:  entry:
+; CHECK-NEXT:    br label [[LOOP:%.*]]
+; CHECK:       loop:
+; CHECK-NEXT:    [[IV:%.*]] = phi i32 [ 0, [[ENTRY:%.*]] ], [ [[IV_NEXT:%.*]], [[LOOP]] ]
+; CHECK-NEXT:    [[GEP_IV:%.*]] = getelementptr inbounds i64, ptr [[SRC:%.*]], i32 [[IV]]
+; CHECK-NEXT:    store i32 [[IV]], ptr [[GEP_IV]], align 4
+; CHECK-NEXT:    [[GEP:%.*]] = getelementptr inbounds i64, ptr [[GEP_IV]], i64 1
+; CHECK-NEXT:    [[TRUNC_IV:%.*]] = trunc i32 [[IV]] to i24
+; CHECK-NEXT:    store i24 [[TRUNC_IV]], ptr [[GEP]], align 4
+; CHECK-NEXT:    [[IV_NEXT]] = add i32 [[IV]], 2
+; CHECK-NEXT:    [[CMP:%.*]] = icmp eq i32 [[IV]], 10000
+; CHECK-NEXT:    br i1 [[CMP]], label [[EXIT:%.*]], label [[LOOP]]
+; CHECK:       exit:
+; CHECK-NEXT:    ret void
+;
+entry:
+  br label %loop
+
+loop:
+  %iv = phi i32 [ 0, %entry ], [ %iv.next, %loop ]
+  %gep.iv = getelementptr inbounds i64, ptr %src, i32 %iv
+  store i32 %iv, ptr %gep.iv
+  %gep = getelementptr inbounds i64, ptr %gep.iv, i64 1
+  %trunc.iv = trunc i32 %iv to i24
+  store i24 %trunc.iv, ptr %gep
+  %iv.next = add i32 %iv, 2
+  %cmp = icmp eq i32 %iv, 10000
+  br i1 %cmp, label %exit, label %loop
+
+exit:
+  ret void
+}

From 154e88af7ec97d9b9f389e55d45bf07108a9a097 Mon Sep 17 00:00:00 2001
From: Tom Stellard <tstellar@redhat.com>
Date: Tue, 15 Nov 2022 22:28:29 -0800
Subject: [PATCH 46/84] Bump version to 15.0.5

---
 libcxx/include/__config                                     | 2 +-
 llvm/CMakeLists.txt                                         | 2 +-
 llvm/utils/gn/secondary/llvm/version.gni                    | 2 +-
 llvm/utils/lit/lit/__init__.py                              | 2 +-
 utils/bazel/llvm-project-overlay/clang/BUILD.bazel          | 6 +++---
 .../clang/include/clang/Config/config.h                     | 2 +-
 utils/bazel/llvm-project-overlay/lld/BUILD.bazel            | 2 +-
 .../llvm/include/llvm/Config/llvm-config.h                  | 4 ++--
 8 files changed, 11 insertions(+), 11 deletions(-)

diff --git a/libcxx/include/__config b/libcxx/include/__config
index 810189c94a94c4..d5ac34eba37a2f 100644
--- a/libcxx/include/__config
+++ b/libcxx/include/__config
@@ -36,7 +36,7 @@
 
 #ifdef __cplusplus
 
-#  define _LIBCPP_VERSION 15004
+#  define _LIBCPP_VERSION 15005
 
 #  define _LIBCPP_CONCAT_IMPL(_X, _Y) _X##_Y
 #  define _LIBCPP_CONCAT(_X, _Y) _LIBCPP_CONCAT_IMPL(_X, _Y)
diff --git a/llvm/CMakeLists.txt b/llvm/CMakeLists.txt
index 3d6f5e6f9d3dae..b101a1a187c9fd 100644
--- a/llvm/CMakeLists.txt
+++ b/llvm/CMakeLists.txt
@@ -22,7 +22,7 @@ if(NOT DEFINED LLVM_VERSION_MINOR)
   set(LLVM_VERSION_MINOR 0)
 endif()
 if(NOT DEFINED LLVM_VERSION_PATCH)
-  set(LLVM_VERSION_PATCH 4)
+  set(LLVM_VERSION_PATCH 5)
 endif()
 if(NOT DEFINED LLVM_VERSION_SUFFIX)
   set(LLVM_VERSION_SUFFIX)
diff --git a/llvm/utils/gn/secondary/llvm/version.gni b/llvm/utils/gn/secondary/llvm/version.gni
index 3b890e00bec321..391132f1a316a5 100644
--- a/llvm/utils/gn/secondary/llvm/version.gni
+++ b/llvm/utils/gn/secondary/llvm/version.gni
@@ -1,4 +1,4 @@
 llvm_version_major = 15
 llvm_version_minor = 0
-llvm_version_patch = 4
+llvm_version_patch = 5
 llvm_version = "$llvm_version_major.$llvm_version_minor.$llvm_version_patch"
diff --git a/llvm/utils/lit/lit/__init__.py b/llvm/utils/lit/lit/__init__.py
index 04f6e94535e42d..e3c8693c04218a 100644
--- a/llvm/utils/lit/lit/__init__.py
+++ b/llvm/utils/lit/lit/__init__.py
@@ -2,7 +2,7 @@
 
 __author__ = 'Daniel Dunbar'
 __email__ = 'daniel@minormatter.com'
-__versioninfo__ = (15, 0, 4)
+__versioninfo__ = (15, 0, 5)
 __version__ = '.'.join(str(v) for v in __versioninfo__) + 'dev'
 
 __all__ = []
diff --git a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
index 96b462717be9a8..8f21799d4888b7 100644
--- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
@@ -358,11 +358,11 @@ genrule(
     name = "basic_version_gen",
     outs = ["include/clang/Basic/Version.inc"],
     cmd = (
-        "echo '#define CLANG_VERSION 15.0.4' >> $@\n" +
+        "echo '#define CLANG_VERSION 15.0.5' >> $@\n" +
         "echo '#define CLANG_VERSION_MAJOR 15' >> $@\n" +
         "echo '#define CLANG_VERSION_MINOR 0' >> $@\n" +
-        "echo '#define CLANG_VERSION_PATCHLEVEL 4' >> $@\n" +
-        "echo '#define CLANG_VERSION_STRING \"15.0.4\"' >> $@\n"
+        "echo '#define CLANG_VERSION_PATCHLEVEL 5' >> $@\n" +
+        "echo '#define CLANG_VERSION_STRING \"15.0.5\"' >> $@\n"
     ),
 )
 
diff --git a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
index 5d157492eae377..ec15fccc089b32 100644
--- a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
+++ b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
@@ -93,7 +93,7 @@
 /* CLANG_HAVE_RLIMITS defined conditionally below */
 
 /* The LLVM product name and version */
-#define BACKEND_PACKAGE_STRING "LLVM 15.0.4"
+#define BACKEND_PACKAGE_STRING "LLVM 15.0.5"
 
 /* Linker version detected at compile time. */
 /* #undef HOST_LINK_VERSION */
diff --git a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
index e3a8c98ffa2288..b4e7f5ccbdc4e2 100644
--- a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
@@ -13,7 +13,7 @@ package(
 genrule(
     name = "config_version_gen",
     outs = ["include/lld/Common/Version.inc"],
-    cmd = "echo '#define LLD_VERSION_STRING \"15.0.4\"' > $@",
+    cmd = "echo '#define LLD_VERSION_STRING \"15.0.5\"' > $@",
 )
 
 genrule(
diff --git a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
index 7a86202e8e0d5d..16ffcbf0d2f6a6 100644
--- a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
+++ b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
@@ -80,10 +80,10 @@
 #define LLVM_VERSION_MINOR 0
 
 /* Patch version of the LLVM API */
-#define LLVM_VERSION_PATCH 4
+#define LLVM_VERSION_PATCH 5
 
 /* LLVM version string */
-#define LLVM_VERSION_STRING "15.0.4"
+#define LLVM_VERSION_STRING "15.0.5"
 
 /* Whether LLVM records statistics for use with GetStatistics(),
  * PrintStatistics() or PrintStatisticsJSON()

From 25a36ca5c791611588a455e7e7e8a3593e90f9a3 Mon Sep 17 00:00:00 2001
From: Tom Stellard <tstellar@redhat.com>
Date: Mon, 21 Nov 2022 10:38:24 -0800
Subject: [PATCH 47/84] Bump version to 15.0.6

---
 libcxx/include/__config                                     | 2 +-
 llvm/CMakeLists.txt                                         | 2 +-
 llvm/utils/gn/secondary/llvm/version.gni                    | 2 +-
 llvm/utils/lit/lit/__init__.py                              | 2 +-
 utils/bazel/llvm-project-overlay/clang/BUILD.bazel          | 6 +++---
 .../clang/include/clang/Config/config.h                     | 2 +-
 utils/bazel/llvm-project-overlay/lld/BUILD.bazel            | 2 +-
 .../llvm/include/llvm/Config/llvm-config.h                  | 4 ++--
 8 files changed, 11 insertions(+), 11 deletions(-)

diff --git a/libcxx/include/__config b/libcxx/include/__config
index d5ac34eba37a2f..5f62b974170f9b 100644
--- a/libcxx/include/__config
+++ b/libcxx/include/__config
@@ -36,7 +36,7 @@
 
 #ifdef __cplusplus
 
-#  define _LIBCPP_VERSION 15005
+#  define _LIBCPP_VERSION 15006
 
 #  define _LIBCPP_CONCAT_IMPL(_X, _Y) _X##_Y
 #  define _LIBCPP_CONCAT(_X, _Y) _LIBCPP_CONCAT_IMPL(_X, _Y)
diff --git a/llvm/CMakeLists.txt b/llvm/CMakeLists.txt
index b101a1a187c9fd..28e28cfe7b6a53 100644
--- a/llvm/CMakeLists.txt
+++ b/llvm/CMakeLists.txt
@@ -22,7 +22,7 @@ if(NOT DEFINED LLVM_VERSION_MINOR)
   set(LLVM_VERSION_MINOR 0)
 endif()
 if(NOT DEFINED LLVM_VERSION_PATCH)
-  set(LLVM_VERSION_PATCH 5)
+  set(LLVM_VERSION_PATCH 6)
 endif()
 if(NOT DEFINED LLVM_VERSION_SUFFIX)
   set(LLVM_VERSION_SUFFIX)
diff --git a/llvm/utils/gn/secondary/llvm/version.gni b/llvm/utils/gn/secondary/llvm/version.gni
index 391132f1a316a5..00e1dc6f1411e3 100644
--- a/llvm/utils/gn/secondary/llvm/version.gni
+++ b/llvm/utils/gn/secondary/llvm/version.gni
@@ -1,4 +1,4 @@
 llvm_version_major = 15
 llvm_version_minor = 0
-llvm_version_patch = 5
+llvm_version_patch = 6
 llvm_version = "$llvm_version_major.$llvm_version_minor.$llvm_version_patch"
diff --git a/llvm/utils/lit/lit/__init__.py b/llvm/utils/lit/lit/__init__.py
index e3c8693c04218a..b34d17b9dc4795 100644
--- a/llvm/utils/lit/lit/__init__.py
+++ b/llvm/utils/lit/lit/__init__.py
@@ -2,7 +2,7 @@
 
 __author__ = 'Daniel Dunbar'
 __email__ = 'daniel@minormatter.com'
-__versioninfo__ = (15, 0, 5)
+__versioninfo__ = (15, 0, 6)
 __version__ = '.'.join(str(v) for v in __versioninfo__) + 'dev'
 
 __all__ = []
diff --git a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
index 8f21799d4888b7..5ee87d51651998 100644
--- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
@@ -358,11 +358,11 @@ genrule(
     name = "basic_version_gen",
     outs = ["include/clang/Basic/Version.inc"],
     cmd = (
-        "echo '#define CLANG_VERSION 15.0.5' >> $@\n" +
+        "echo '#define CLANG_VERSION 15.0.6' >> $@\n" +
         "echo '#define CLANG_VERSION_MAJOR 15' >> $@\n" +
         "echo '#define CLANG_VERSION_MINOR 0' >> $@\n" +
-        "echo '#define CLANG_VERSION_PATCHLEVEL 5' >> $@\n" +
-        "echo '#define CLANG_VERSION_STRING \"15.0.5\"' >> $@\n"
+        "echo '#define CLANG_VERSION_PATCHLEVEL 6' >> $@\n" +
+        "echo '#define CLANG_VERSION_STRING \"15.0.6\"' >> $@\n"
     ),
 )
 
diff --git a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
index ec15fccc089b32..ff4feb2b4af9b7 100644
--- a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
+++ b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
@@ -93,7 +93,7 @@
 /* CLANG_HAVE_RLIMITS defined conditionally below */
 
 /* The LLVM product name and version */
-#define BACKEND_PACKAGE_STRING "LLVM 15.0.5"
+#define BACKEND_PACKAGE_STRING "LLVM 15.0.6"
 
 /* Linker version detected at compile time. */
 /* #undef HOST_LINK_VERSION */
diff --git a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
index b4e7f5ccbdc4e2..6ba06c7944134d 100644
--- a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
@@ -13,7 +13,7 @@ package(
 genrule(
     name = "config_version_gen",
     outs = ["include/lld/Common/Version.inc"],
-    cmd = "echo '#define LLD_VERSION_STRING \"15.0.5\"' > $@",
+    cmd = "echo '#define LLD_VERSION_STRING \"15.0.6\"' > $@",
 )
 
 genrule(
diff --git a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
index 16ffcbf0d2f6a6..a44e9f60c0e16d 100644
--- a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
+++ b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
@@ -80,10 +80,10 @@
 #define LLVM_VERSION_MINOR 0
 
 /* Patch version of the LLVM API */
-#define LLVM_VERSION_PATCH 5
+#define LLVM_VERSION_PATCH 6
 
 /* LLVM version string */
-#define LLVM_VERSION_STRING "15.0.5"
+#define LLVM_VERSION_STRING "15.0.6"
 
 /* Whether LLVM records statistics for use with GetStatistics(),
  * PrintStatistics() or PrintStatisticsJSON()

From e6e61e9b2ef7c0fa3fe2cd7c612e00ecf57a9dd8 Mon Sep 17 00:00:00 2001
From: Bill Wendling <morbo@google.com>
Date: Thu, 17 Nov 2022 16:07:15 -0800
Subject: [PATCH 48/84] Revert "Reapply: Add an error message to the default
 SIGPIPE handler"

This patch is spamming compiles with unhelpful and confusing messages.
E.g. the Linux kernel uses "grep -q" in several places. It's meant to
quit with a return code of zero when the first match is found. This can
cause a SIGPIPE signal, but that's expected, and there's no way to turn
this error message off to avoid spurious error messages.

UNIX03 apparently doesn't require printing an error message on SIGPIPE,
but specifically when there's an error on the stdout stream in a normal
program flow, e.g. when SIGPIPE trap is disabled.

A separate patch is planned to address the specific case we care most
about (involving llvm-nm).

This reverts commit b89bcefa6202e310eb3167dd1c37f1807377ec8d.

Link: https://github.com/llvm/llvm-project/issues/59037
Link: https://github.com/ClangBuiltLinux/linux/issues/1651

Differential Revision: https://reviews.llvm.org/D138244

(cherry picked from commit 4787efa38066adb51e2c049499d25b3610c0877b)
---
 llvm/lib/Support/Unix/Signals.inc          |  4 ----
 llvm/test/Support/unix03-sigpipe-exit.test | 26 ----------------------
 2 files changed, 30 deletions(-)
 delete mode 100644 llvm/test/Support/unix03-sigpipe-exit.test

diff --git a/llvm/lib/Support/Unix/Signals.inc b/llvm/lib/Support/Unix/Signals.inc
index bf145bffe8bf27..23ac012b9e005b 100644
--- a/llvm/lib/Support/Unix/Signals.inc
+++ b/llvm/lib/Support/Unix/Signals.inc
@@ -432,10 +432,6 @@ void llvm::sys::SetOneShotPipeSignalFunction(void (*Handler)()) {
 }
 
 void llvm::sys::DefaultOneShotPipeSignalHandler() {
-  // UNIX03 conformance requires a non-zero exit code and an error message
-  // to stderr when writing to a closed stdout fails.
-  errs() << "error: write on a pipe with no reader\n";
-
   // Send a special return code that drivers can check for, from sysexits.h.
   exit(EX_IOERR);
 }
diff --git a/llvm/test/Support/unix03-sigpipe-exit.test b/llvm/test/Support/unix03-sigpipe-exit.test
deleted file mode 100644
index 01680841db0011..00000000000000
--- a/llvm/test/Support/unix03-sigpipe-exit.test
+++ /dev/null
@@ -1,26 +0,0 @@
-## Test that when writing to a closed stdout, LLVM tools finish with a non-zero
-## exit code and an error message on stderr. The test uses llvm-cxxfilt, but
-## it's a logic from the default SIGPIPE handler, so it applies to all the tools.
-## This is required for UNIX03 conformance.
-
-# UNSUPPORTED: system-windows
-
-# RUN: not %python %s llvm-cxxfilt 2>&1 | FileCheck %s
-# CHECK: error: write on a pipe with no reader
-
-import subprocess
-import sys
-
-with subprocess.Popen([sys.argv[1]], stdout=subprocess.PIPE, stdin=subprocess.PIPE) as process:
-  process.stdout.close()
-
-  # llvm-cxxfilt with no extra arguments runs interactively and writes input
-  # to output. Writing continuously to stdin should trigger SIGPIPE when the
-  # subprocess attempts to write out bytes to a closed stdout.
-  try:
-    while True:
-      process.stdin.write("foo\n".encode("utf-8"))
-  except BrokenPipeError:
-    # Clear stdin, pipe is broken and closing it on cleanup will raise an exception.
-    process.stdin = None
-sys.exit(process.returncode)

From abcd0341d8465d55d7293dfc7142fef5055047fa Mon Sep 17 00:00:00 2001
From: Brett Werling <bwerl.dev@gmail.com>
Date: Wed, 16 Nov 2022 08:16:11 -0800
Subject: [PATCH 49/84] [ELF] Handle GCC collect2 -plugin-opt= on Windows

Follows up on commit cd5d5ce235081005173566c99c592550021de058 by
additionally ignoring relative paths ending in "lto-wrapper.exe" as
can be the case for GCC cross-compiled for Windows.

Reviewed By: tejohnson

Differential Revision: https://reviews.llvm.org/D138065

(cherry picked from commit cf4f35b78871aecc21e663067c57e60595bd7197)
---
 lld/ELF/Driver.cpp               | 9 ++++++---
 lld/test/ELF/lto-plugin-ignore.s | 2 ++
 2 files changed, 8 insertions(+), 3 deletions(-)

diff --git a/lld/ELF/Driver.cpp b/lld/ELF/Driver.cpp
index 296fb4220012e0..58d86377643053 100644
--- a/lld/ELF/Driver.cpp
+++ b/lld/ELF/Driver.cpp
@@ -1330,12 +1330,15 @@ static void readConfigs(opt::InputArgList &args) {
     parseClangOption(std::string("-") + arg->getValue(), arg->getSpelling());
 
   // GCC collect2 passes -plugin-opt=path/to/lto-wrapper with an absolute or
-  // relative path. Just ignore. If not ended with "lto-wrapper", consider it an
+  // relative path. Just ignore. If not ended with "lto-wrapper" (or
+  // "lto-wrapper.exe" for GCC cross-compiled for Windows), consider it an
   // unsupported LLVMgold.so option and error.
-  for (opt::Arg *arg : args.filtered(OPT_plugin_opt_eq))
-    if (!StringRef(arg->getValue()).endswith("lto-wrapper"))
+  for (opt::Arg *arg : args.filtered(OPT_plugin_opt_eq)) {
+    StringRef v(arg->getValue());
+    if (!v.endswith("lto-wrapper") && !v.endswith("lto-wrapper.exe"))
       error(arg->getSpelling() + ": unknown plugin option '" + arg->getValue() +
             "'");
+  }
 
   config->passPlugins = args::getStrings(args, OPT_load_pass_plugins);
 
diff --git a/lld/test/ELF/lto-plugin-ignore.s b/lld/test/ELF/lto-plugin-ignore.s
index 2935bad149deeb..dd39139b624394 100644
--- a/lld/test/ELF/lto-plugin-ignore.s
+++ b/lld/test/ELF/lto-plugin-ignore.s
@@ -8,7 +8,9 @@
 # RUN: ld.lld %t.o -o /dev/null \
 # RUN:   -plugin path/to/liblto_plugin.so \
 # RUN:   -plugin-opt=/path/to/lto-wrapper \
+# RUN:   -plugin-opt=/path/to/lto-wrapper.exe \
 # RUN:   -plugin-opt=relative/path/to/lto-wrapper \
+# RUN:   -plugin-opt=relative/path/to/lto-wrapper.exe \
 # RUN:   -plugin-opt=-fresolution=zed \
 # RUN:   -plugin-opt=-pass-through=-lgcc \
 # RUN:   -plugin-opt=-pass-through=-lgcc_eh \

From 088f33605d8a61ff519c580a71b1dd57d16a03f8 Mon Sep 17 00:00:00 2001
From: yronglin <yronglin777@gmail.com>
Date: Thu, 17 Nov 2022 23:06:21 +0800
Subject: [PATCH 50/84] [CodeGen][ARM] Fix ARMABIInfo::EmitVAAarg crash with
 empty record type variadic arg

Fix ARMABIInfo::EmitVAAarg crash with empty record type variadic arg

Open issue: https://github.com/llvm/llvm-project/issues/58794

Reviewed By: rjmccall

Differential Revision: https://reviews.llvm.org/D138137

(cherry picked from commit 80f444646c62ccc8b2399d60ac91e62e6e576da6)
---
 clang/lib/CodeGen/TargetInfo.cpp |  8 ++++----
 clang/test/CodeGen/arm-vaarg.c   | 23 +++++++++++++++++++++++
 2 files changed, 27 insertions(+), 4 deletions(-)
 create mode 100644 clang/test/CodeGen/arm-vaarg.c

diff --git a/clang/lib/CodeGen/TargetInfo.cpp b/clang/lib/CodeGen/TargetInfo.cpp
index 36e10e4df4c192..44743fa0206f4d 100644
--- a/clang/lib/CodeGen/TargetInfo.cpp
+++ b/clang/lib/CodeGen/TargetInfo.cpp
@@ -7047,10 +7047,10 @@ Address ARMABIInfo::EmitVAArg(CodeGenFunction &CGF, Address VAListAddr,
 
   // Empty records are ignored for parameter passing purposes.
   if (isEmptyRecord(getContext(), Ty, true)) {
-    Address Addr = Address(CGF.Builder.CreateLoad(VAListAddr),
-                           getVAListElementType(CGF), SlotSize);
-    Addr = CGF.Builder.CreateElementBitCast(Addr, CGF.ConvertTypeForMem(Ty));
-    return Addr;
+    VAListAddr = CGF.Builder.CreateElementBitCast(VAListAddr, CGF.Int8PtrTy);
+    auto *Load = CGF.Builder.CreateLoad(VAListAddr);
+    Address Addr = Address(Load, CGF.Int8Ty, SlotSize);
+    return CGF.Builder.CreateElementBitCast(Addr, CGF.ConvertTypeForMem(Ty));
   }
 
   CharUnits TySize = getContext().getTypeSizeInChars(Ty);
diff --git a/clang/test/CodeGen/arm-vaarg.c b/clang/test/CodeGen/arm-vaarg.c
new file mode 100644
index 00000000000000..4dab397a20de46
--- /dev/null
+++ b/clang/test/CodeGen/arm-vaarg.c
@@ -0,0 +1,23 @@
+// RUN: %clang -Xclang -no-opaque-pointers -mfloat-abi=soft -target arm-linux-gnu -emit-llvm -S -o - %s | FileCheck %s
+
+struct Empty {};
+
+struct Empty emptyvar;
+
+void take_args(int a, ...) {
+// CHECK: [[ALLOCA_VA_LIST:%[a-zA-Z0-9._]+]] = alloca %struct.__va_list, align 4
+// CHECK: call void @llvm.va_start
+// CHECK-NEXT: [[AP_ADDR:%[a-zA-Z0-9._]+]] = bitcast %struct.__va_list* [[ALLOCA_VA_LIST]] to i8**
+// CHECK-NEXT: [[LOAD_AP:%[a-zA-Z0-9._]+]] = load i8*, i8** [[AP_ADDR]], align 4
+// CHECK-NEXT: [[EMPTY_PTR:%[a-zA-Z0-9._]+]] = bitcast i8* [[LOAD_AP]] to %struct.Empty*
+
+  // It's conceivable that EMPTY_PTR may not actually be a valid pointer
+  // (e.g. it's at the very bottom of the stack and the next page is
+  // invalid). This doesn't matter provided it's never loaded (there's no
+  // well-defined way to tell), but it becomes a problem if we do try to use it.
+// CHECK-NOT: load %struct.Empty, %struct.Empty* [[EMPTY_PTR]]
+  __builtin_va_list l;
+  __builtin_va_start(l, a);
+  emptyvar = __builtin_va_arg(l, struct Empty);
+  __builtin_va_end(l);
+}

From a8af9f679231a55b8a0f5707d8727679a98f4b06 Mon Sep 17 00:00:00 2001
From: Tom Stellard <tstellar@redhat.com>
Date: Fri, 6 Jan 2023 13:09:17 -0800
Subject: [PATCH 51/84] Bump version to 15.0.7

---
 libcxx/include/__config                                     | 2 +-
 llvm/CMakeLists.txt                                         | 2 +-
 llvm/utils/gn/secondary/llvm/version.gni                    | 2 +-
 llvm/utils/lit/lit/__init__.py                              | 2 +-
 utils/bazel/llvm-project-overlay/clang/BUILD.bazel          | 6 +++---
 .../clang/include/clang/Config/config.h                     | 2 +-
 utils/bazel/llvm-project-overlay/lld/BUILD.bazel            | 2 +-
 .../llvm/include/llvm/Config/llvm-config.h                  | 4 ++--
 8 files changed, 11 insertions(+), 11 deletions(-)

diff --git a/libcxx/include/__config b/libcxx/include/__config
index 5f62b974170f9b..c97cbae96fbacf 100644
--- a/libcxx/include/__config
+++ b/libcxx/include/__config
@@ -36,7 +36,7 @@
 
 #ifdef __cplusplus
 
-#  define _LIBCPP_VERSION 15006
+#  define _LIBCPP_VERSION 15007
 
 #  define _LIBCPP_CONCAT_IMPL(_X, _Y) _X##_Y
 #  define _LIBCPP_CONCAT(_X, _Y) _LIBCPP_CONCAT_IMPL(_X, _Y)
diff --git a/llvm/CMakeLists.txt b/llvm/CMakeLists.txt
index 28e28cfe7b6a53..db207e3328bebc 100644
--- a/llvm/CMakeLists.txt
+++ b/llvm/CMakeLists.txt
@@ -22,7 +22,7 @@ if(NOT DEFINED LLVM_VERSION_MINOR)
   set(LLVM_VERSION_MINOR 0)
 endif()
 if(NOT DEFINED LLVM_VERSION_PATCH)
-  set(LLVM_VERSION_PATCH 6)
+  set(LLVM_VERSION_PATCH 7)
 endif()
 if(NOT DEFINED LLVM_VERSION_SUFFIX)
   set(LLVM_VERSION_SUFFIX)
diff --git a/llvm/utils/gn/secondary/llvm/version.gni b/llvm/utils/gn/secondary/llvm/version.gni
index 00e1dc6f1411e3..d485a133f9219b 100644
--- a/llvm/utils/gn/secondary/llvm/version.gni
+++ b/llvm/utils/gn/secondary/llvm/version.gni
@@ -1,4 +1,4 @@
 llvm_version_major = 15
 llvm_version_minor = 0
-llvm_version_patch = 6
+llvm_version_patch = 7
 llvm_version = "$llvm_version_major.$llvm_version_minor.$llvm_version_patch"
diff --git a/llvm/utils/lit/lit/__init__.py b/llvm/utils/lit/lit/__init__.py
index b34d17b9dc4795..928d6db8d3cd12 100644
--- a/llvm/utils/lit/lit/__init__.py
+++ b/llvm/utils/lit/lit/__init__.py
@@ -2,7 +2,7 @@
 
 __author__ = 'Daniel Dunbar'
 __email__ = 'daniel@minormatter.com'
-__versioninfo__ = (15, 0, 6)
+__versioninfo__ = (15, 0, 7)
 __version__ = '.'.join(str(v) for v in __versioninfo__) + 'dev'
 
 __all__ = []
diff --git a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
index 5ee87d51651998..59932954c949aa 100644
--- a/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/clang/BUILD.bazel
@@ -358,11 +358,11 @@ genrule(
     name = "basic_version_gen",
     outs = ["include/clang/Basic/Version.inc"],
     cmd = (
-        "echo '#define CLANG_VERSION 15.0.6' >> $@\n" +
+        "echo '#define CLANG_VERSION 15.0.7' >> $@\n" +
         "echo '#define CLANG_VERSION_MAJOR 15' >> $@\n" +
         "echo '#define CLANG_VERSION_MINOR 0' >> $@\n" +
-        "echo '#define CLANG_VERSION_PATCHLEVEL 6' >> $@\n" +
-        "echo '#define CLANG_VERSION_STRING \"15.0.6\"' >> $@\n"
+        "echo '#define CLANG_VERSION_PATCHLEVEL 7' >> $@\n" +
+        "echo '#define CLANG_VERSION_STRING \"15.0.7\"' >> $@\n"
     ),
 )
 
diff --git a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
index ff4feb2b4af9b7..5ee35630d35ae3 100644
--- a/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
+++ b/utils/bazel/llvm-project-overlay/clang/include/clang/Config/config.h
@@ -93,7 +93,7 @@
 /* CLANG_HAVE_RLIMITS defined conditionally below */
 
 /* The LLVM product name and version */
-#define BACKEND_PACKAGE_STRING "LLVM 15.0.6"
+#define BACKEND_PACKAGE_STRING "LLVM 15.0.7"
 
 /* Linker version detected at compile time. */
 /* #undef HOST_LINK_VERSION */
diff --git a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
index 6ba06c7944134d..06b57f39e3330b 100644
--- a/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
+++ b/utils/bazel/llvm-project-overlay/lld/BUILD.bazel
@@ -13,7 +13,7 @@ package(
 genrule(
     name = "config_version_gen",
     outs = ["include/lld/Common/Version.inc"],
-    cmd = "echo '#define LLD_VERSION_STRING \"15.0.6\"' > $@",
+    cmd = "echo '#define LLD_VERSION_STRING \"15.0.7\"' > $@",
 )
 
 genrule(
diff --git a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
index a44e9f60c0e16d..1d5c3a4e879bdf 100644
--- a/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
+++ b/utils/bazel/llvm-project-overlay/llvm/include/llvm/Config/llvm-config.h
@@ -80,10 +80,10 @@
 #define LLVM_VERSION_MINOR 0
 
 /* Patch version of the LLVM API */
-#define LLVM_VERSION_PATCH 6
+#define LLVM_VERSION_PATCH 7
 
 /* LLVM version string */
-#define LLVM_VERSION_STRING "15.0.6"
+#define LLVM_VERSION_STRING "15.0.7"
 
 /* Whether LLVM records statistics for use with GetStatistics(),
  * PrintStatistics() or PrintStatisticsJSON()

From 74d3ba1af5c09b85331c90105c461484762ee3e4 Mon Sep 17 00:00:00 2001
From: Bill Wendling <morbo@google.com>
Date: Tue, 13 Dec 2022 15:06:29 -0800
Subject: [PATCH 52/84] [X86] Don't zero out %eax if both %al and %ah are used

The iterator over super and sub registers doesn't include both 8-bit
registers in its list. So if both registers are used and only one of
them is live on return, then we need to make sure that the other 8-bit
register is also marked as live and not zeroed out.

Reviewed By: nickdesaulniers

Differential Revision: https://reviews.llvm.org/D139679

(cherry picked from commit 14d4cddc5506fb0fd3c4ac556b4edd970aa151eb)
---
 llvm/lib/CodeGen/PrologEpilogInserter.cpp     |   8 +-
 .../CodeGen/X86/zero-call-used-regs-i386.ll   | 112 ++++++++++++++++++
 2 files changed, 119 insertions(+), 1 deletion(-)
 create mode 100644 llvm/test/CodeGen/X86/zero-call-used-regs-i386.ll

diff --git a/llvm/lib/CodeGen/PrologEpilogInserter.cpp b/llvm/lib/CodeGen/PrologEpilogInserter.cpp
index 85d051cfdbe713..a8d40edd88d3af 100644
--- a/llvm/lib/CodeGen/PrologEpilogInserter.cpp
+++ b/llvm/lib/CodeGen/PrologEpilogInserter.cpp
@@ -1237,7 +1237,13 @@ void PEI::insertZeroCallUsedRegs(MachineFunction &MF) {
         if (!MO.isReg())
           continue;
 
-        for (MCPhysReg SReg : TRI.sub_and_superregs_inclusive(MO.getReg()))
+        MCRegister Reg = MO.getReg();
+
+        // This picks up sibling registers (e.q. %al -> %ah).
+        for (MCRegUnitIterator Unit(Reg, &TRI); Unit.isValid(); ++Unit)
+          RegsToZero.reset(*Unit);
+
+        for (MCPhysReg SReg : TRI.sub_and_superregs_inclusive(Reg))
           RegsToZero.reset(SReg);
       }
     }
diff --git a/llvm/test/CodeGen/X86/zero-call-used-regs-i386.ll b/llvm/test/CodeGen/X86/zero-call-used-regs-i386.ll
new file mode 100644
index 00000000000000..33e501ca8503c4
--- /dev/null
+++ b/llvm/test/CodeGen/X86/zero-call-used-regs-i386.ll
@@ -0,0 +1,112 @@
+; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
+; RUN: llc < %s -mtriple=i386-unknown-linux-gnu -opaque-pointers | FileCheck %s --check-prefix=I386
+;
+; Make sure we don't zero out %eax when both %ah and %al are used.
+;
+; PR1766: https://github.com/ClangBuiltLinux/linux/issues/1766
+
+%struct.maple_subtree_state = type { ptr }
+
+@mas_data_end_type = dso_local local_unnamed_addr global i32 0, align 4
+@ma_meta_end_mn_0_0_0_0_0_0 = dso_local local_unnamed_addr global i8 0, align 1
+@mt_pivots_0 = dso_local local_unnamed_addr global i8 0, align 1
+@mas_data_end___trans_tmp_2 = dso_local local_unnamed_addr global ptr null, align 4
+@mt_slots_0 = dso_local local_unnamed_addr global i8 0, align 1
+
+define dso_local zeroext i1 @test1(ptr nocapture noundef readonly %0) local_unnamed_addr "zero-call-used-regs"="used-gpr" nounwind {
+; I386-LABEL: test1:
+; I386:       # %bb.0:
+; I386-NEXT:    pushl %ebx
+; I386-NEXT:    subl $24, %esp
+; I386-NEXT:    movl {{[0-9]+}}(%esp), %eax
+; I386-NEXT:    movl (%eax), %eax
+; I386-NEXT:    movzbl (%eax), %ebx
+; I386-NEXT:    calll bar
+; I386-NEXT:    testb %al, %al
+; I386-NEXT:    # implicit-def: $al
+; I386-NEXT:    # kill: killed $al
+; I386-NEXT:    je .LBB0_6
+; I386-NEXT:  # %bb.1:
+; I386-NEXT:    cmpl $0, mas_data_end_type
+; I386-NEXT:    je .LBB0_3
+; I386-NEXT:  # %bb.2:
+; I386-NEXT:    movzbl ma_meta_end_mn_0_0_0_0_0_0, %eax
+; I386-NEXT:    movb %al, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
+; I386-NEXT:    jmp .LBB0_6
+; I386-NEXT:  .LBB0_3:
+; I386-NEXT:    movb mt_pivots_0, %ah
+; I386-NEXT:    movb %ah, %al
+; I386-NEXT:    decb %al
+; I386-NEXT:    movl mas_data_end___trans_tmp_2, %ecx
+; I386-NEXT:    movsbl %al, %edx
+; I386-NEXT:    cmpl $0, (%ecx,%edx,4)
+; I386-NEXT:    je .LBB0_5
+; I386-NEXT:  # %bb.4:
+; I386-NEXT:    movb %al, %ah
+; I386-NEXT:  .LBB0_5:
+; I386-NEXT:    movb %ah, {{[-0-9]+}}(%e{{[sb]}}p) # 1-byte Spill
+; I386-NEXT:  .LBB0_6:
+; I386-NEXT:    movb mt_slots_0, %bh
+; I386-NEXT:    leal {{[0-9]+}}(%esp), %eax
+; I386-NEXT:    movl %eax, (%esp)
+; I386-NEXT:    calll baz
+; I386-NEXT:    subl $4, %esp
+; I386-NEXT:    cmpb %bh, %bl
+; I386-NEXT:    jae .LBB0_8
+; I386-NEXT:  # %bb.7:
+; I386-NEXT:    movsbl {{[-0-9]+}}(%e{{[sb]}}p), %eax # 1-byte Folded Reload
+; I386-NEXT:    movl %eax, (%esp)
+; I386-NEXT:    calll gaz
+; I386-NEXT:  .LBB0_8:
+; I386-NEXT:    movb $1, %al
+; I386-NEXT:    addl $24, %esp
+; I386-NEXT:    popl %ebx
+; I386-NEXT:    xorl %ecx, %ecx
+; I386-NEXT:    xorl %edx, %edx
+; I386-NEXT:    retl
+  %2 = alloca %struct.maple_subtree_state, align 4
+  %3 = load ptr, ptr %0, align 4
+  %4 = load i8, ptr %3, align 1
+  %5 = tail call zeroext i1 @bar()
+  br i1 %5, label %6, label %20
+
+6:                                                ; preds = %1
+  %7 = load i32, ptr @mas_data_end_type, align 4
+  %8 = icmp eq i32 %7, 0
+  br i1 %8, label %11, label %9
+
+9:                                                ; preds = %6
+  %10 = load i8, ptr @ma_meta_end_mn_0_0_0_0_0_0, align 1
+  br label %20
+
+11:                                               ; preds = %6
+  %12 = load i8, ptr @mt_pivots_0, align 1
+  %13 = add i8 %12, -1
+  %14 = load ptr, ptr @mas_data_end___trans_tmp_2, align 4
+  %15 = sext i8 %13 to i32
+  %16 = getelementptr inbounds [1 x i32], ptr %14, i32 0, i32 %15
+  %17 = load i32, ptr %16, align 4
+  %18 = icmp eq i32 %17, 0
+  %19 = select i1 %18, i8 %12, i8 %13
+  br label %20
+
+20:                                               ; preds = %11, %9, %1
+  %21 = phi i8 [ undef, %1 ], [ %10, %9 ], [ %19, %11 ]
+  %22 = load i8, ptr @mt_slots_0, align 1
+  call void @baz(ptr nonnull sret(%struct.maple_subtree_state) align 4 %2)
+  %23 = icmp ult i8 %4, %22
+  br i1 %23, label %24, label %25
+
+24:                                               ; preds = %20
+  call void @gaz(i8 noundef signext %21)
+  br label %25
+
+25:                                               ; preds = %20, %24
+  ret i1 true
+}
+
+declare dso_local zeroext i1 @bar(...) local_unnamed_addr
+
+declare dso_local void @baz(ptr sret(%struct.maple_subtree_state) align 4, ...) local_unnamed_addr
+
+declare dso_local void @gaz(i8 noundef signext) local_unnamed_addr

From 67fd0d2af4bf9e939ebcccb2b66552a31789af94 Mon Sep 17 00:00:00 2001
From: "chenglin.bi" <chenglin.bi@linaro.org>
Date: Tue, 3 Jan 2023 18:12:15 +0800
Subject: [PATCH 53/84] [TypePromotion] Add truncate in ConvertTruncs when the
 original truncate type is not extend type

If the src type is not extend type, after convert the truncate to and we need to truncate the and also to make sure the all user is legal.

The old fix D137613 doesn't work when the truncate convert to and have the other users. So this time I try to add the truncate after and to avoid all these potential issues.

Fix: #59554

Reviewed By: samparker

Differential Revision: https://reviews.llvm.org/D140869

(cherry picked from commit a0b470c9848c638e86f97eca53063642e07cea67)
---
 llvm/lib/CodeGen/TypePromotion.cpp            |  8 ++---
 .../TypePromotion/AArch64/pr58843.ll          | 20 -----------
 .../TypePromotion/AArch64/trunc-zext-chain.ll | 36 +++++++++++++++++++
 3 files changed, 38 insertions(+), 26 deletions(-)
 delete mode 100644 llvm/test/Transforms/TypePromotion/AArch64/pr58843.ll

diff --git a/llvm/lib/CodeGen/TypePromotion.cpp b/llvm/lib/CodeGen/TypePromotion.cpp
index a63118067139fd..36e3c1245f1caf 100644
--- a/llvm/lib/CodeGen/TypePromotion.cpp
+++ b/llvm/lib/CodeGen/TypePromotion.cpp
@@ -570,7 +570,6 @@ void IRPromoter::Cleanup() {
   LLVM_DEBUG(dbgs() << "IR Promotion: Cleanup..\n");
   // Some zexts will now have become redundant, along with their trunc
   // operands, so remove them.
-  // Some zexts need to be replaced with truncate if src bitwidth is larger.
   for (auto *V : Visited) {
     if (!isa<ZExtInst>(V))
       continue;
@@ -585,11 +584,6 @@ void IRPromoter::Cleanup() {
                         << "\n");
       ReplaceAllUsersOfWith(ZExt, Src);
       continue;
-    } else if (ZExt->getSrcTy()->getScalarSizeInBits() > PromotedWidth) {
-      IRBuilder<> Builder{ZExt};
-      Value *Trunc = Builder.CreateTrunc(Src, ZExt->getDestTy());
-      ReplaceAllUsersOfWith(ZExt, Trunc);
-      continue;
     }
 
     // We've inserted a trunc for a zext sink, but we already know that the
@@ -626,6 +620,8 @@ void IRPromoter::ConvertTruncs() {
     ConstantInt *Mask =
         ConstantInt::get(SrcTy, APInt::getMaxValue(NumBits).getZExtValue());
     Value *Masked = Builder.CreateAnd(Trunc->getOperand(0), Mask);
+    if (SrcTy != ExtTy)
+      Masked = Builder.CreateTrunc(Masked, ExtTy);
 
     if (auto *I = dyn_cast<Instruction>(Masked))
       NewInsts.insert(I);
diff --git a/llvm/test/Transforms/TypePromotion/AArch64/pr58843.ll b/llvm/test/Transforms/TypePromotion/AArch64/pr58843.ll
deleted file mode 100644
index 983a32029c6526..00000000000000
--- a/llvm/test/Transforms/TypePromotion/AArch64/pr58843.ll
+++ /dev/null
@@ -1,20 +0,0 @@
-; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
-; RUN: opt -mtriple=aarch64 -type-promotion -verify -S %s -o - | FileCheck %s
-target datalayout = "e-m:e-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128"
-
-; Check the case don't crash due to zext source type bitwidth
-; larger than dest type bitwidth.
-define i1 @test(i8 %arg) {
-; CHECK-LABEL: @test(
-; CHECK-NEXT:    [[EXT1:%.*]] = zext i8 [[ARG:%.*]] to i64
-; CHECK-NEXT:    [[TMP1:%.*]] = and i64 [[EXT1]], 7
-; CHECK-NEXT:    [[TMP2:%.*]] = trunc i64 [[TMP1]] to i32
-; CHECK-NEXT:    [[CMP:%.*]] = icmp ne i32 [[TMP2]], 0
-; CHECK-NEXT:    ret i1 [[CMP]]
-;
-  %ext1 = zext i8 %arg to i64
-  %trunc = trunc i64 %ext1 to i3
-  %ext2 = zext i3 %trunc to i8
-  %cmp = icmp ne i8 %ext2, 0
-  ret i1 %cmp
-}
diff --git a/llvm/test/Transforms/TypePromotion/AArch64/trunc-zext-chain.ll b/llvm/test/Transforms/TypePromotion/AArch64/trunc-zext-chain.ll
index 0a846ba115ec30..bcf8dfdd7cb0b2 100644
--- a/llvm/test/Transforms/TypePromotion/AArch64/trunc-zext-chain.ll
+++ b/llvm/test/Transforms/TypePromotion/AArch64/trunc-zext-chain.ll
@@ -177,3 +177,39 @@ latch:                                             ; preds = %bb14, %bb9
 exit:
   ret i64 %var30
 }
+
+; Check the case don't crash due to zext source type bitwidth
+; larger than dest type bitwidth.
+define i1 @pr58843(i8 %arg) {
+; CHECK-LABEL: @pr58843(
+; CHECK-NEXT:    [[EXT1:%.*]] = zext i8 [[ARG:%.*]] to i64
+; CHECK-NEXT:    [[TMP1:%.*]] = and i64 [[EXT1]], 7
+; CHECK-NEXT:    [[TMP2:%.*]] = trunc i64 [[TMP1]] to i32
+; CHECK-NEXT:    [[CMP:%.*]] = icmp ne i32 [[TMP2]], 0
+; CHECK-NEXT:    ret i1 [[CMP]]
+;
+  %ext1 = zext i8 %arg to i64
+  %trunc = trunc i64 %ext1 to i3
+  %ext2 = zext i3 %trunc to i8
+  %cmp = icmp ne i8 %ext2, 0
+  ret i1 %cmp
+}
+
+; Check the case don't crash due to xor two op have different
+; types
+define i1 @pr59554(i8 %arg) {
+; CHECK-LABEL: @pr59554(
+; CHECK-NEXT:    [[ARG_EXT:%.*]] = zext i8 [[ARG:%.*]] to i64
+; CHECK-NEXT:    [[TMP1:%.*]] = and i64 [[ARG_EXT]], 7
+; CHECK-NEXT:    [[TMP2:%.*]] = trunc i64 [[TMP1]] to i32
+; CHECK-NEXT:    [[SWITCH_TABLEIDX:%.*]] = xor i32 [[TMP2]], 1
+; CHECK-NEXT:    [[SWITCH_LOBIT:%.*]] = icmp ne i32 [[TMP2]], 0
+; CHECK-NEXT:    ret i1 [[SWITCH_LOBIT]]
+;
+  %arg.ext = zext i8 %arg to i64
+  %trunc = trunc i64 %arg.ext to i3
+  %switch.tableidx = xor i3 %trunc, 1
+  %switch.maskindex = zext i3 %trunc to i8
+  %switch.lobit = icmp ne i8 %switch.maskindex, 0
+  ret i1 %switch.lobit
+}

From 1095870e8ceddc5371f446f4e7c3473f89a461cd Mon Sep 17 00:00:00 2001
From: Dan Gohman <dev@sunfishcode.online>
Date: Mon, 17 Oct 2022 13:36:19 -0700
Subject: [PATCH 54/84] [wasm-ld] Define a `__heap_end` symbol marking the end
 of allocated memory.

Define a `__heap_end` symbol that marks the end of the memory region
that starts at `__heap_base`. This will allow malloc implementations to
know how much memory they can use at `__heap_base` even if someone has
done a `memory.grow` before they can initialize their state.

Differential Revision: https://reviews.llvm.org/D136110
---
 lld/test/wasm/export-all.s             |  7 +++++--
 lld/test/wasm/mutable-global-exports.s |  7 +++++--
 lld/wasm/Driver.cpp                    |  1 +
 lld/wasm/Symbols.cpp                   |  1 +
 lld/wasm/Symbols.h                     | 11 +++++++----
 lld/wasm/Writer.cpp                    | 16 +++++++++++++---
 6 files changed, 32 insertions(+), 11 deletions(-)

diff --git a/lld/test/wasm/export-all.s b/lld/test/wasm/export-all.s
index 009da9f6a38170..5af835ce485e29 100644
--- a/lld/test/wasm/export-all.s
+++ b/lld/test/wasm/export-all.s
@@ -40,9 +40,12 @@ foo:
 # CHECK-NEXT:       - Name:            __heap_base
 # CHECK-NEXT:         Kind:            GLOBAL
 # CHECK-NEXT:         Index:           4
-# CHECK-NEXT:       - Name:            __memory_base
+# CHECK-NEXT:       - Name:            __heap_end
 # CHECK-NEXT:         Kind:            GLOBAL
 # CHECK-NEXT:         Index:           5
-# CHECK-NEXT:       - Name:            __table_base
+# CHECK-NEXT:       - Name:            __memory_base
 # CHECK-NEXT:         Kind:            GLOBAL
 # CHECK-NEXT:         Index:           6
+# CHECK-NEXT:       - Name:            __table_base
+# CHECK-NEXT:         Kind:            GLOBAL
+# CHECK-NEXT:         Index:           7
diff --git a/lld/test/wasm/mutable-global-exports.s b/lld/test/wasm/mutable-global-exports.s
index e2e45ff93a4bca..98009610ac55f2 100644
--- a/lld/test/wasm/mutable-global-exports.s
+++ b/lld/test/wasm/mutable-global-exports.s
@@ -79,10 +79,13 @@ _start:
 # CHECK-ALL-NEXT:      - Name:            __heap_base
 # CHECK-ALL-NEXT:        Kind:            GLOBAL
 # CHECK-ALL-NEXT:        Index:           5
-# CHECK-ALL-NEXT:      - Name:            __memory_base
+# CHECK-ALL-NEXT:      - Name:            __heap_end
 # CHECK-ALL-NEXT:        Kind:            GLOBAL
 # CHECK-ALL-NEXT:        Index:           6
-# CHECK-ALL-NEXT:      - Name:            __table_base
+# CHECK-ALL-NEXT:      - Name:            __memory_base
 # CHECK-ALL-NEXT:        Kind:            GLOBAL
 # CHECK-ALL-NEXT:        Index:           7
+# CHECK-ALL-NEXT:      - Name:            __table_base
+# CHECK-ALL-NEXT:        Kind:            GLOBAL
+# CHECK-ALL-NEXT:        Index:           8
 # CHECK-ALL-NEXT:  - Type:            CODE
diff --git a/lld/wasm/Driver.cpp b/lld/wasm/Driver.cpp
index 0a0f0c8a05bd7a..4afbfe24110f81 100644
--- a/lld/wasm/Driver.cpp
+++ b/lld/wasm/Driver.cpp
@@ -681,6 +681,7 @@ static void createOptionalSymbols() {
   if (!config->isPic) {
     WasmSym::globalBase = symtab->addOptionalDataSymbol("__global_base");
     WasmSym::heapBase = symtab->addOptionalDataSymbol("__heap_base");
+    WasmSym::heapEnd = symtab->addOptionalDataSymbol("__heap_end");
     WasmSym::definedMemoryBase = symtab->addOptionalDataSymbol("__memory_base");
     WasmSym::definedTableBase = symtab->addOptionalDataSymbol("__table_base");
     if (config->is64.value_or(false))
diff --git a/lld/wasm/Symbols.cpp b/lld/wasm/Symbols.cpp
index e0670cea6425e3..a79c5bec3b3bbb 100644
--- a/lld/wasm/Symbols.cpp
+++ b/lld/wasm/Symbols.cpp
@@ -83,6 +83,7 @@ DefinedData *WasmSym::dsoHandle;
 DefinedData *WasmSym::dataEnd;
 DefinedData *WasmSym::globalBase;
 DefinedData *WasmSym::heapBase;
+DefinedData *WasmSym::heapEnd;
 DefinedData *WasmSym::initMemoryFlag;
 GlobalSymbol *WasmSym::stackPointer;
 GlobalSymbol *WasmSym::tlsBase;
diff --git a/lld/wasm/Symbols.h b/lld/wasm/Symbols.h
index c17b720a90fae7..32e75a69c5f800 100644
--- a/lld/wasm/Symbols.h
+++ b/lld/wasm/Symbols.h
@@ -538,11 +538,14 @@ struct WasmSym {
   // Symbol marking the end of the data and bss.
   static DefinedData *dataEnd;
 
-  // __heap_base
-  // Symbol marking the end of the data, bss and explicit stack.  Any linear
-  // memory following this address is not used by the linked code and can
-  // therefore be used as a backing store for brk()/malloc() implementations.
+  // __heap_base/__heap_end
+  // Symbols marking the beginning and end of the "heap". It starts at the end
+  // of the data, bss and explicit stack, and extends to the end of the linear
+  // memory allocated by wasm-ld. This region of memory is not used by the
+  // linked code, so it may be used as a backing store for `sbrk` or `malloc`
+  // implementations.
   static DefinedData *heapBase;
+  static DefinedData *heapEnd;
 
   // __wasm_init_memory_flag
   // Symbol whose contents are nonzero iff memory has already been initialized.
diff --git a/lld/wasm/Writer.cpp b/lld/wasm/Writer.cpp
index f98c95526c9e0c..f6bbaa02b571d8 100644
--- a/lld/wasm/Writer.cpp
+++ b/lld/wasm/Writer.cpp
@@ -340,10 +340,20 @@ void Writer::layoutMemory() {
             Twine(maxMemorySetting));
     memoryPtr = config->initialMemory;
   }
-  out.memorySec->numMemoryPages =
-      alignTo(memoryPtr, WasmPageSize) / WasmPageSize;
+
+  memoryPtr = alignTo(memoryPtr, WasmPageSize);
+
+  out.memorySec->numMemoryPages = memoryPtr / WasmPageSize;
   log("mem: total pages = " + Twine(out.memorySec->numMemoryPages));
 
+  if (WasmSym::heapEnd) {
+    // Set `__heap_end` to follow the end of the statically allocated linear
+    // memory. The fact that this comes last means that a malloc/brk
+    // implementation can grow the heap at runtime.
+    log("mem: heap end    = " + Twine(memoryPtr));
+    WasmSym::heapEnd->setVA(memoryPtr);
+  }
+
   if (config->maxMemory != 0) {
     if (config->maxMemory != alignTo(config->maxMemory, WasmPageSize))
       error("maximum memory must be " + Twine(WasmPageSize) + "-byte aligned");
@@ -363,7 +373,7 @@ void Writer::layoutMemory() {
       if (config->isPic)
         max = maxMemorySetting;
       else
-        max = alignTo(memoryPtr, WasmPageSize);
+        max = memoryPtr;
     }
     out.memorySec->maxMemoryPages = max / WasmPageSize;
     log("mem: max pages   = " + Twine(out.memorySec->maxMemoryPages));

From 948cadd6d4247f7a5bd8fd6b1386062653d54c84 Mon Sep 17 00:00:00 2001
From: Josh Stone <jistone@redhat.com>
Date: Tue, 3 Jan 2023 16:04:45 -0800
Subject: [PATCH 55/84] [RegAllocFast] Handle new debug values for spills

These new debug values get inserted after the place where the spill
happens, which means they won't be reached by the reverse traversal of
basic block instructions. This would crash or fail assertions if they
contained any virtual registers to be replaced. We can manually handle
the new debug values right away to resolve this.

Fixes https://github.com/llvm/llvm-project/issues/59172

Reviewed By: StephenTozer

Differential Revision: https://reviews.llvm.org/D139590

(cherry picked from commit 87f57f459e7acbb00a6ca4ee6dec6014c5a97e07)
---
 llvm/lib/CodeGen/RegAllocFast.cpp             |   3 +
 .../PowerPC/regalloc-fast-debug-spill.ll      | 250 ++++++++++++++++++
 2 files changed, 253 insertions(+)
 create mode 100644 llvm/test/CodeGen/PowerPC/regalloc-fast-debug-spill.ll

diff --git a/llvm/lib/CodeGen/RegAllocFast.cpp b/llvm/lib/CodeGen/RegAllocFast.cpp
index 9e4e26f1392edc..cb552f212fbb75 100644
--- a/llvm/lib/CodeGen/RegAllocFast.cpp
+++ b/llvm/lib/CodeGen/RegAllocFast.cpp
@@ -443,6 +443,9 @@ void RegAllocFast::spill(MachineBasicBlock::iterator Before, Register VirtReg,
     SpilledOperandsMap[MO->getParent()].push_back(MO);
   for (auto MISpilledOperands : SpilledOperandsMap) {
     MachineInstr &DBG = *MISpilledOperands.first;
+    // We don't have enough support for tracking operands of DBG_VALUE_LISTs.
+    if (DBG.isDebugValueList())
+      continue;
     MachineInstr *NewDV = buildDbgValueForSpill(
         *MBB, Before, *MISpilledOperands.first, FI, MISpilledOperands.second);
     assert(NewDV->getParent() == MBB && "dangling parent pointer");
diff --git a/llvm/test/CodeGen/PowerPC/regalloc-fast-debug-spill.ll b/llvm/test/CodeGen/PowerPC/regalloc-fast-debug-spill.ll
new file mode 100644
index 00000000000000..cae3cb3bbdf832
--- /dev/null
+++ b/llvm/test/CodeGen/PowerPC/regalloc-fast-debug-spill.ll
@@ -0,0 +1,250 @@
+; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
+; RUN: llc -O0 < %s | FileCheck %s
+
+; This test would previously crash in RegisterScavenging, or with assertions
+; enabled it would fail when RegAllocFast calls clearVirtRegs. This was due to
+; unhandled virt regs in cloned DBG_VALUE_LIST for spills, which are now skipped.
+; https://github.com/llvm/llvm-project/issues/59172
+
+target datalayout = "e-m:e-i64:64-n32:64-S128-v256:256:256-v512:512:512"
+target triple = "powerpc64le-unknown-linux-gnu"
+
+; Function Attrs: argmemonly nocallback nofree nounwind willreturn
+declare void @llvm.memcpy.p0.p0.i64(ptr noalias nocapture writeonly, ptr noalias nocapture readonly, i64, i1 immarg) #0
+
+; Function Attrs: nocallback nofree nosync nounwind readnone speculatable willreturn
+declare void @llvm.dbg.value(metadata, metadata, metadata) #1
+
+define void @read_to_end(i1 %0) personality ptr null {
+; CHECK-LABEL: read_to_end:
+; CHECK:       # %bb.0:
+; CHECK-NEXT:    mflr 0
+; CHECK-NEXT:    std 0, 16(1)
+; CHECK-NEXT:    stdu 1, -80(1)
+; CHECK-NEXT:    .cfi_def_cfa_offset 80
+; CHECK-NEXT:    .cfi_offset lr, 16
+; CHECK-NEXT:    andi. 3, 3, 1
+; CHECK-NEXT:    mfocrf 3, 128
+; CHECK-NEXT:    rlwinm 3, 3, 1, 0, 0
+; CHECK-NEXT:    stw 3, 60(1)
+; CHECK-NEXT:    ld 3, 0(0)
+; CHECK-NEXT:    std 3, 64(1) # 8-byte Folded Spill
+; CHECK-NEXT:    li 3, 0
+; CHECK-NEXT:    std 3, 72(1) # 8-byte Folded Spill
+; CHECK-NEXT:    #DEBUG_VALUE: spec_extend<u8, alloc::alloc::Global>:iterator <- [DW_OP_LLVM_arg 0, DW_OP_LLVM_arg 1, DW_OP_constu 1, DW_OP_mul, DW_OP_plus, DW_OP_stack_value, DW_OP_LLVM_fragment 64 64] undef, $x3
+; CHECK-NEXT:    creqv 20, 20, 20
+; CHECK-NEXT:    crxor 20, 1, 20
+; CHECK-NEXT:    bc 12, 20, .LBB0_2
+; CHECK-NEXT:    b .LBB0_1
+; CHECK-NEXT:  .LBB0_1:
+; CHECK-NEXT:    addi 1, 1, 80
+; CHECK-NEXT:    ld 0, 16(1)
+; CHECK-NEXT:    mtlr 0
+; CHECK-NEXT:    blr
+; CHECK-NEXT:  .LBB0_2:
+; CHECK-NEXT:    ld 5, 72(1) # 8-byte Folded Reload
+; CHECK-NEXT:    ld 4, 64(1) # 8-byte Folded Reload
+; CHECK-NEXT:    li 3, 0
+; CHECK-NEXT:    bl memcpy
+; CHECK-NEXT:    nop
+; CHECK-NEXT:    lwz 4, 60(1)
+; CHECK-NEXT:    # implicit-def: $cr5lt
+; CHECK-NEXT:    mfocrf 3, 4
+; CHECK-NEXT:    rlwimi 3, 4, 12, 20, 20
+; CHECK-NEXT:    mtocrf 4, 3
+; CHECK-NEXT:    bc 12, 20, .LBB0_4
+; CHECK-NEXT:    b .LBB0_3
+; CHECK-NEXT:  .LBB0_3:
+; CHECK-NEXT:    b .LBB0_4
+; CHECK-NEXT:  .LBB0_4:
+; CHECK-NEXT:    addi 1, 1, 80
+; CHECK-NEXT:    ld 0, 16(1)
+; CHECK-NEXT:    mtlr 0
+; CHECK-NEXT:    blr
+  %2 = load ptr, ptr null, align 8
+  %3 = sub i64 0, 0
+  call void @llvm.dbg.value(metadata !DIArgList(ptr %2, i64 %3), metadata !129, metadata !DIExpression(DW_OP_LLVM_arg, 0, DW_OP_LLVM_arg, 1, DW_OP_constu, 1, DW_OP_mul, DW_OP_plus, DW_OP_stack_value, DW_OP_LLVM_fragment, 64, 64)), !dbg !140
+  br i1 %0, label %4, label %5
+
+4:                                                ; preds = %1
+  ret void
+
+5:                                                ; preds = %1
+  tail call void @llvm.memcpy.p0.p0.i64(ptr null, ptr %2, i64 %3, i1 false)
+  br i1 %0, label %7, label %6
+
+6:                                                ; preds = %5
+  br label %7
+
+7:                                                ; preds = %6, %5
+  ret void
+}
+
+attributes #0 = { argmemonly nocallback nofree nounwind willreturn }
+attributes #1 = { nocallback nofree nosync nounwind readnone speculatable willreturn }
+
+!llvm.module.flags = !{!0}
+!llvm.dbg.cu = !{!1}
+
+!0 = !{i32 2, !"Debug Info Version", i32 3}
+!1 = distinct !DICompileUnit(language: DW_LANG_Rust, file: !2, producer: "clang LLVM (rustc version 1.67.0-dev)", isOptimized: true, runtimeVersion: 0, emissionKind: FullDebug, enums: !3, globals: !4)
+!2 = !DIFile(filename: "library/std/src/lib.rs/@/std.ff910444-cgu.11", directory: "/home/jistone/rust")
+!3 = !{}
+!4 = !{!5, !12, !18, !23, !28, !34, !43, !49, !52, !58, !64, !68, !77, !81, !86, !90, !98, !102, !106, !111, !117, !124}
+!5 = !DIGlobalVariableExpression(var: !6, expr: !DIExpression())
+!6 = distinct !DIGlobalVariable(name: "<alloc::string::String as core::fmt::Write>::{vtable}", scope: null, file: !7, type: !8, isLocal: true, isDefinition: true)
+!7 = !DIFile(filename: "<unknown>", directory: "")
+!8 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<alloc::string::String as core::fmt::Write>::{vtable_type}", file: !7, size: 384, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !9, templateParams: !3, identifier: "1ec913b2a90798f33a12cdc627a17d3d")
+!9 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "String", scope: !10, file: !7, size: 192, align: 64, elements: !3, templateParams: !3, identifier: "b616ccc9e18737e903266aae12eea82")
+!10 = !DINamespace(name: "string", scope: !11)
+!11 = !DINamespace(name: "alloc", scope: null)
+!12 = !DIGlobalVariableExpression(var: !13, expr: !DIExpression())
+!13 = distinct !DIGlobalVariable(name: "<core::cell::BorrowMutError as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !14, isLocal: true, isDefinition: true)
+!14 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<core::cell::BorrowMutError as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !15, templateParams: !3, identifier: "7f09904511177108b2e94c43effbe403")
+!15 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "BorrowMutError", scope: !16, file: !7, align: 8, elements: !3, identifier: "acf9edd4524e0ff9a9398905d3ba31a6")
+!16 = !DINamespace(name: "cell", scope: !17)
+!17 = !DINamespace(name: "core", scope: null)
+!18 = !DIGlobalVariableExpression(var: !19, expr: !DIExpression())
+!19 = distinct !DIGlobalVariable(name: "<core::fmt::Error as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !20, isLocal: true, isDefinition: true)
+!20 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<core::fmt::Error as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !21, templateParams: !3, identifier: "84cb7e6d80fc4c532d8f45aaa75a7ae3")
+!21 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Error", scope: !22, file: !7, align: 8, elements: !3, identifier: "abcb9fb1fe4fda8598a8687b517935b")
+!22 = !DINamespace(name: "fmt", scope: !17)
+!23 = !DIGlobalVariableExpression(var: !24, expr: !DIExpression())
+!24 = distinct !DIGlobalVariable(name: "<core::array::TryFromSliceError as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !25, isLocal: true, isDefinition: true)
+!25 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<core::array::TryFromSliceError as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !26, templateParams: !3, identifier: "bafa31943f8233dbf8d2de6a615f899")
+!26 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "TryFromSliceError", scope: !27, file: !7, align: 8, elements: !3, templateParams: !3, identifier: "2dd7cf8d77337f63be7c7f5feb370b37")
+!27 = !DINamespace(name: "array", scope: !17)
+!28 = !DIGlobalVariableExpression(var: !29, expr: !DIExpression())
+!29 = distinct !DIGlobalVariable(name: "<core::num::error::TryFromIntError as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !30, isLocal: true, isDefinition: true)
+!30 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<core::num::error::TryFromIntError as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !31, templateParams: !3, identifier: "3292395ea0f5a7e3e88f36db52eb440c")
+!31 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "TryFromIntError", scope: !32, file: !7, align: 8, elements: !3, templateParams: !3, identifier: "5b131d57d001578fbf4fb83f2028eb12")
+!32 = !DINamespace(name: "error", scope: !33)
+!33 = !DINamespace(name: "num", scope: !17)
+!34 = !DIGlobalVariableExpression(var: !35, expr: !DIExpression())
+!35 = distinct !DIGlobalVariable(name: "OUTPUT_CAPTURE_USED", linkageName: "_ZN3std2io5stdio19OUTPUT_CAPTURE_USED17h6bb564f9f9e20f1bE", scope: !36, file: !39, line: 38, type: !40, isLocal: true, isDefinition: true, align: 8)
+!36 = !DINamespace(name: "stdio", scope: !37)
+!37 = !DINamespace(name: "io", scope: !38)
+!38 = !DINamespace(name: "std", scope: null)
+!39 = !DIFile(filename: "library/std/src/io/stdio.rs", directory: "/home/jistone/rust", checksumkind: CSK_MD5, checksum: "6e6a519ce8370e29f07d850a34a413c1")
+!40 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "AtomicBool", scope: !41, file: !7, size: 8, align: 8, elements: !3, templateParams: !3, identifier: "c1cddf0305d4e6a98a8ddd4b6fdb5b91")
+!41 = !DINamespace(name: "atomic", scope: !42)
+!42 = !DINamespace(name: "sync", scope: !17)
+!43 = !DIGlobalVariableExpression(var: !44, expr: !DIExpression())
+!44 = distinct !DIGlobalVariable(name: "INSTANCE", linkageName: "_ZN3std2io5stdio5stdin8INSTANCE17h225ddf7c6608f4aaE", scope: !45, file: !39, line: 320, type: !46, isLocal: true, isDefinition: true, align: 64)
+!45 = !DINamespace(name: "stdin", scope: !36)
+!46 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "OnceLock<std::sync::mutex::Mutex<std::io::buffered::bufreader::BufReader<std::io::stdio::StdinRaw>>>", scope: !47, file: !7, size: 448, align: 64, elements: !3, templateParams: !3, identifier: "2236c08b0846b8b2f33c235183822718")
+!47 = !DINamespace(name: "once_lock", scope: !48)
+!48 = !DINamespace(name: "sync", scope: !38)
+!49 = !DIGlobalVariableExpression(var: !50, expr: !DIExpression())
+!50 = distinct !DIGlobalVariable(name: "STDOUT", linkageName: "_ZN3std2io5stdio6STDOUT17hd8472b9eb112f94aE", scope: !36, file: !39, line: 554, type: !51, isLocal: true, isDefinition: true, align: 64)
+!51 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "OnceLock<std::sys_common::remutex::ReentrantMutex<core::cell::RefCell<std::io::buffered::linewriter::LineWriter<std::io::stdio::StdoutRaw>>>>", scope: !47, file: !7, size: 512, align: 64, elements: !3, templateParams: !3, identifier: "31535135376bcf9dc80438cb0beaa95")
+!52 = !DIGlobalVariableExpression(var: !53, expr: !DIExpression())
+!53 = distinct !DIGlobalVariable(name: "INSTANCE", linkageName: "_ZN3std2io5stdio6stderr8INSTANCE17he81b75fda1609dccE", scope: !54, file: !39, line: 844, type: !55, isLocal: true, isDefinition: true, align: 64)
+!54 = !DINamespace(name: "stderr", scope: !36)
+!55 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "ReentrantMutex<core::cell::RefCell<std::io::stdio::StderrRaw>>", scope: !56, file: !7, size: 192, align: 64, elements: !3, templateParams: !3, identifier: "5c48123cbde8afbfd832b70e8bb014b")
+!56 = !DINamespace(name: "remutex", scope: !57)
+!57 = !DINamespace(name: "sys_common", scope: !38)
+!58 = !DIGlobalVariableExpression(var: !59, expr: !DIExpression())
+!59 = distinct !DIGlobalVariable(name: "<std::io::Write::write_fmt::Adapter<std::io::stdio::StdoutLock> as core::fmt::Write>::{vtable}", scope: null, file: !7, type: !60, isLocal: true, isDefinition: true)
+!60 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<std::io::Write::write_fmt::Adapter<std::io::stdio::StdoutLock> as core::fmt::Write>::{vtable_type}", file: !7, size: 384, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !61, templateParams: !3, identifier: "43681bec3eba7b0defb75fd847230ef3")
+!61 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Adapter<std::io::stdio::StdoutLock>", scope: !62, file: !7, size: 128, align: 64, elements: !3, templateParams: !3, identifier: "eda3cd8f60f00feb7019a3d90d2413dd")
+!62 = !DINamespace(name: "write_fmt", scope: !63)
+!63 = !DINamespace(name: "Write", scope: !37)
+!64 = !DIGlobalVariableExpression(var: !65, expr: !DIExpression())
+!65 = distinct !DIGlobalVariable(name: "<std::io::Write::write_fmt::Adapter<std::io::stdio::StderrLock> as core::fmt::Write>::{vtable}", scope: null, file: !7, type: !66, isLocal: true, isDefinition: true)
+!66 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<std::io::Write::write_fmt::Adapter<std::io::stdio::StderrLock> as core::fmt::Write>::{vtable_type}", file: !7, size: 384, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !67, templateParams: !3, identifier: "2235adf22355a080446df25ada963d8f")
+!67 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Adapter<std::io::stdio::StderrLock>", scope: !62, file: !7, size: 128, align: 64, elements: !3, templateParams: !3, identifier: "50f418463bae1beffe989359452b170a")
+!68 = !DIGlobalVariableExpression(var: !69, expr: !DIExpression())
+!69 = distinct !DIGlobalVariable(name: "__KEY", linkageName: "_ZN3std2io5stdio14OUTPUT_CAPTURE7__getit5__KEY17h82ea5b0c4e81236dE", scope: !70, file: !72, line: 331, type: !73, isLocal: true, isDefinition: true, align: 64)
+!70 = !DINamespace(name: "__getit", scope: !71)
+!71 = !DINamespace(name: "OUTPUT_CAPTURE", scope: !36)
+!72 = !DIFile(filename: "library/std/src/thread/local.rs", directory: "/home/jistone/rust", checksumkind: CSK_MD5, checksum: "e3766fd5751a888dc2040f63031e944e")
+!73 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Key<core::cell::Cell<core::option::Option<alloc::sync::Arc<std::sync::mutex::Mutex<alloc::vec::Vec<u8, alloc::alloc::Global>>>>>>", scope: !74, file: !7, size: 192, align: 64, elements: !3, templateParams: !3, identifier: "4d1514f685cbd010d7b86d2eef080b6c")
+!74 = !DINamespace(name: "fast", scope: !75)
+!75 = !DINamespace(name: "local", scope: !76)
+!76 = !DINamespace(name: "thread", scope: !38)
+!77 = !DIGlobalVariableExpression(var: !78, expr: !DIExpression())
+!78 = distinct !DIGlobalVariable(name: "<i32 as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !79, isLocal: true, isDefinition: true)
+!79 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<i32 as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !80, templateParams: !3, identifier: "1a7c0806435616633a284f48de1194c5")
+!80 = !DIBasicType(name: "i32", size: 32, encoding: DW_ATE_signed)
+!81 = !DIGlobalVariableExpression(var: !82, expr: !DIExpression())
+!82 = distinct !DIGlobalVariable(name: "<std::path::PathBuf as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !83, isLocal: true, isDefinition: true)
+!83 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<std::path::PathBuf as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !84, templateParams: !3, identifier: "8e82e7dafb168f2995a6711175975a8")
+!84 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "PathBuf", scope: !85, file: !7, size: 192, align: 64, elements: !3, templateParams: !3, identifier: "85bd755ad2187534379df2cc01ef53a0")
+!85 = !DINamespace(name: "path", scope: !38)
+!86 = !DIGlobalVariableExpression(var: !87, expr: !DIExpression())
+!87 = distinct !DIGlobalVariable(name: "<bool as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !88, isLocal: true, isDefinition: true)
+!88 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<bool as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !89, templateParams: !3, identifier: "a8f7c32dd1df279746df60c6d46ce35e")
+!89 = !DIBasicType(name: "bool", size: 8, encoding: DW_ATE_boolean)
+!90 = !DIGlobalVariableExpression(var: !91, expr: !DIExpression())
+!91 = distinct !DIGlobalVariable(name: "STATX_STATE", linkageName: "_ZN3std3sys4unix2fs9try_statx11STATX_STATE17h465ade0d62262837E", scope: !92, file: !96, line: 157, type: !97, isLocal: true, isDefinition: true, align: 8)
+!92 = !DINamespace(name: "try_statx", scope: !93)
+!93 = !DINamespace(name: "fs", scope: !94)
+!94 = !DINamespace(name: "unix", scope: !95)
+!95 = !DINamespace(name: "sys", scope: !38)
+!96 = !DIFile(filename: "library/std/src/sys/unix/fs.rs", directory: "/home/jistone/rust", checksumkind: CSK_MD5, checksum: "594559328c68ee77afe955cd571273ee")
+!97 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "AtomicU8", scope: !41, file: !7, size: 8, align: 8, elements: !3, templateParams: !3, identifier: "dda3b691bea8e1b5292414dd97926af2")
+!98 = !DIGlobalVariableExpression(var: !99, expr: !DIExpression())
+!99 = distinct !DIGlobalVariable(name: "<&bool as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !100, isLocal: true, isDefinition: true)
+!100 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<&bool as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !101, templateParams: !3, identifier: "5e8d2c48c9cc79c318e2bd28b03e141a")
+!101 = !DIDerivedType(tag: DW_TAG_pointer_type, name: "&bool", baseType: !89, size: 64, align: 64, dwarfAddressSpace: 0)
+!102 = !DIGlobalVariableExpression(var: !103, expr: !DIExpression())
+!103 = distinct !DIGlobalVariable(name: "<&i32 as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !104, isLocal: true, isDefinition: true)
+!104 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<&i32 as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !105, templateParams: !3, identifier: "d4029746615b6a868ffbc67515d99878")
+!105 = !DIDerivedType(tag: DW_TAG_pointer_type, name: "&i32", baseType: !80, size: 64, align: 64, dwarfAddressSpace: 0)
+!106 = !DIGlobalVariableExpression(var: !107, expr: !DIExpression())
+!107 = distinct !DIGlobalVariable(name: "<&u32 as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !108, isLocal: true, isDefinition: true)
+!108 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<&u32 as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !109, templateParams: !3, identifier: "178e0e76b9d9178d686381b2d05a7777")
+!109 = !DIDerivedType(tag: DW_TAG_pointer_type, name: "&u32", baseType: !110, size: 64, align: 64, dwarfAddressSpace: 0)
+!110 = !DIBasicType(name: "u32", size: 32, encoding: DW_ATE_unsigned)
+!111 = !DIGlobalVariableExpression(var: !112, expr: !DIExpression())
+!112 = distinct !DIGlobalVariable(name: "<&core::option::Option<std::sys::unix::time::SystemTime> as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !113, isLocal: true, isDefinition: true)
+!113 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<&core::option::Option<std::sys::unix::time::SystemTime> as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !114, templateParams: !3, identifier: "7ca8386b4d420d719587fa3255329a7a")
+!114 = !DIDerivedType(tag: DW_TAG_pointer_type, name: "&core::option::Option<std::sys::unix::time::SystemTime>", baseType: !115, size: 64, align: 64, dwarfAddressSpace: 0)
+!115 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Option<std::sys::unix::time::SystemTime>", scope: !116, file: !7, size: 128, align: 64, elements: !3, templateParams: !3, identifier: "ad8474e495013fa1e3af4a6b53a05f4b")
+!116 = !DINamespace(name: "option", scope: !17)
+!117 = !DIGlobalVariableExpression(var: !118, expr: !DIExpression())
+!118 = distinct !DIGlobalVariable(name: "HAS_CLONE3", linkageName: "_ZN3std3sys4unix7process13process_inner66_$LT$impl$u20$std..sys..unix..process..process_common..Command$GT$7do_fork10HAS_CLONE317h7d23eb353ae1c9a8E", scope: !119, file: !123, line: 148, type: !40, isLocal: true, isDefinition: true, align: 8)
+!119 = !DINamespace(name: "do_fork", scope: !120)
+!120 = !DINamespace(name: "{impl#0}", scope: !121)
+!121 = !DINamespace(name: "process_inner", scope: !122)
+!122 = !DINamespace(name: "process", scope: !94)
+!123 = !DIFile(filename: "library/std/src/sys/unix/process/process_unix.rs", directory: "/home/jistone/rust", checksumkind: CSK_MD5, checksum: "91761d638041a5dd66c0a64d968debe6")
+!124 = !DIGlobalVariableExpression(var: !125, expr: !DIExpression())
+!125 = distinct !DIGlobalVariable(name: "<core::num::nonzero::NonZeroI32 as core::fmt::Debug>::{vtable}", scope: null, file: !7, type: !126, isLocal: true, isDefinition: true)
+!126 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "<core::num::nonzero::NonZeroI32 as core::fmt::Debug>::{vtable_type}", file: !7, size: 256, align: 64, flags: DIFlagArtificial, elements: !3, vtableHolder: !127, templateParams: !3, identifier: "13903f30d26ee5869ef7a3fc63a2e03d")
+!127 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "NonZeroI32", scope: !128, file: !7, size: 32, align: 32, elements: !3, templateParams: !3, identifier: "e292f11a32f1ce5cf3b26864e4a0f5e5")
+!128 = !DINamespace(name: "nonzero", scope: !33)
+!129 = !DILocalVariable(name: "iterator", arg: 2, scope: !130, file: !131, line: 83, type: !137)
+!130 = distinct !DISubprogram(name: "spec_extend<u8, alloc::alloc::Global>", linkageName: "_ZN132_$LT$alloc..vec..Vec$LT$T$C$A$GT$$u20$as$u20$alloc..vec..spec_extend..SpecExtend$LT$$RF$T$C$core..slice..iter..Iter$LT$T$GT$$GT$$GT$11spec_extend17hb56b69f474ec1e6dE", scope: !132, file: !131, line: 83, type: !135, scopeLine: 83, flags: DIFlagPrototyped, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition | DISPFlagOptimized, unit: !1, templateParams: !3, retainedNodes: !3)
+!131 = !DIFile(filename: "library/alloc/src/vec/spec_extend.rs", directory: "/home/jistone/rust", checksumkind: CSK_MD5, checksum: "0614d5dabe9e343254af1b3fa1ec7315")
+!132 = !DINamespace(name: "{impl#4}", scope: !133)
+!133 = !DINamespace(name: "spec_extend", scope: !134)
+!134 = !DINamespace(name: "vec", scope: !11)
+!135 = distinct !DISubroutineType(types: !136)
+!136 = !{null}
+!137 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Iter<u8>", scope: !138, file: !7, size: 128, align: 64, elements: !3, templateParams: !3, identifier: "c31ab6f02ccece1f1a6e93425acabaa1")
+!138 = !DINamespace(name: "iter", scope: !139)
+!139 = !DINamespace(name: "slice", scope: !17)
+!140 = !DILocation(line: 0, scope: !130, inlinedAt: !141)
+!141 = distinct !DILocation(line: 2392, column: 9, scope: !142, inlinedAt: !146)
+!142 = distinct !DISubprogram(name: "extend_from_slice<u8, alloc::alloc::Global>", linkageName: "_ZN5alloc3vec16Vec$LT$T$C$A$GT$17extend_from_slice17hbc8d29f2694fd768E", scope: !144, file: !143, line: 2391, type: !145, scopeLine: 2391, flags: DIFlagPrototyped, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition | DISPFlagOptimized, unit: !1, templateParams: !3, retainedNodes: !3)
+!143 = !DIFile(filename: "library/alloc/src/vec/mod.rs", directory: "/home/jistone/rust", checksumkind: CSK_MD5, checksum: "0d69d0c0c11b3e47364cf6be0d07c829")
+!144 = distinct !DICompositeType(tag: DW_TAG_structure_type, name: "Vec<u8, alloc::alloc::Global>", scope: !134, file: !7, size: 192, align: 64, elements: !3, templateParams: !3, identifier: "f970dea4d30c1daf847db520fef9390d")
+!145 = distinct !DISubroutineType(types: !136)
+!146 = distinct !DILocation(line: 330, column: 9, scope: !147, inlinedAt: !154)
+!147 = distinct !DILexicalBlock(scope: !149, file: !148, line: 329, column: 9)
+!148 = !DIFile(filename: "library/std/src/io/buffered/bufreader.rs", directory: "/home/jistone/rust", checksumkind: CSK_MD5, checksum: "5375e06de487f85ee2f6d21c8a84ce7d")
+!149 = distinct !DISubprogram(name: "read_to_end<std::io::stdio::StdinRaw>", linkageName: "_ZN82_$LT$std..io..buffered..bufreader..BufReader$LT$R$GT$$u20$as$u20$std..io..Read$GT$11read_to_end17h9f09720ee76e6db9E", scope: !150, file: !148, line: 328, type: !153, scopeLine: 328, flags: DIFlagPrototyped, spFlags: DISPFlagLocalToUnit | DISPFlagDefinition | DISPFlagOptimized, unit: !1, templateParams: !3, retainedNodes: !3)
+!150 = !DINamespace(name: "{impl#3}", scope: !151)
+!151 = !DINamespace(name: "bufreader", scope: !152)
+!152 = !DINamespace(name: "buffered", scope: !37)
+!153 = distinct !DISubroutineType(types: !3)
+!154 = distinct !DILocation(line: 464, column: 9, scope: !155, inlinedAt: !158)
+!155 = distinct !DISubprogram(name: "read_to_end", linkageName: "_ZN59_$LT$std..io..stdio..StdinLock$u20$as$u20$std..io..Read$GT$11read_to_end17h38999a681cc6c5b5E", scope: !156, file: !39, line: 463, type: !157, scopeLine: 463, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition | DISPFlagOptimized, unit: !1, templateParams: !3, retainedNodes: !3)
+!156 = !DINamespace(name: "{impl#7}", scope: !36)
+!157 = distinct !DISubroutineType(types: !3)
+!158 = distinct !DILocation(line: 430, column: 9, scope: !159)
+!159 = distinct !DISubprogram(name: "read_to_end", linkageName: "_ZN55_$LT$std..io..stdio..Stdin$u20$as$u20$std..io..Read$GT$11read_to_end17haba70a09681d41d3E", scope: !160, file: !39, line: 429, type: !161, scopeLine: 429, flags: DIFlagPrototyped, spFlags: DISPFlagDefinition | DISPFlagOptimized, unit: !1, templateParams: !3, retainedNodes: !3)
+!160 = !DINamespace(name: "{impl#5}", scope: !36)
+!161 = !DISubroutineType(types: !3)

From 939f5a33711370697f9ad1de4267cfc7399dfe86 Mon Sep 17 00:00:00 2001
From: Sylvestre Ledru <sylvestre@debian.org>
Date: Sun, 8 Jan 2023 00:32:42 +0100
Subject: [PATCH 56/84] libc++: bring back the unsigned in the return type in
 wcstoull_l

got remove here:
https://github.com/llvm/llvm-project/commit/67b0b02ec9f2bbc57bf8f0550828d97f460ac11f#diff-e41832b8aa26da45585a57c5111531f2e1d07e91a67c4f8bf1cd6d566ae45a2bR42

Differential Revision: https://reviews.llvm.org/D141208

(cherry picked from commit fc87452916c0d8759625aad65e9335778ce9cc68)
---
 libcxx/include/__support/musl/xlocale.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/libcxx/include/__support/musl/xlocale.h b/libcxx/include/__support/musl/xlocale.h
index f564c87885ac13..e674a41fa622aa 100644
--- a/libcxx/include/__support/musl/xlocale.h
+++ b/libcxx/include/__support/musl/xlocale.h
@@ -39,7 +39,7 @@ wcstoll_l(const wchar_t *__nptr, wchar_t **__endptr, int __base, locale_t) {
   return ::wcstoll(__nptr, __endptr, __base);
 }
 
-inline _LIBCPP_HIDE_FROM_ABI long long
+inline _LIBCPP_HIDE_FROM_ABI unsigned long long
 wcstoull_l(const wchar_t *__nptr, wchar_t **__endptr, int __base, locale_t) {
   return ::wcstoull(__nptr, __endptr, __base);
 }

From 8dfdcc7b7bf66834a761bd8de445840ef68e4d1a Mon Sep 17 00:00:00 2001
From: Nikolas Klauser <nikolasklauser@berlin.de>
Date: Thu, 17 Nov 2022 21:34:29 +0100
Subject: [PATCH 57/84] [libc++] Fix memory leaks when throwing inside
 std::vector constructors

Fixes #58392

Reviewed By: ldionne, #libc

Spies: alexfh, hans, joanahalili, dblaikie, libcxx-commits

Differential Revision: https://reviews.llvm.org/D138601
---
 libcxx/include/vector                         | 119 ++++++---
 .../vector.bool/ctor_exceptions.pass.cpp      | 141 +++++++++++
 .../vector/vector.cons/exceptions.pass.cpp    | 229 ++++++++++++++++++
 3 files changed, 453 insertions(+), 36 deletions(-)
 create mode 100644 libcxx/test/std/containers/sequences/vector.bool/ctor_exceptions.pass.cpp
 create mode 100644 libcxx/test/std/containers/sequences/vector/vector.cons/exceptions.pass.cpp

diff --git a/libcxx/include/vector b/libcxx/include/vector
index 252a0f051ff545..63759407ce940b 100644
--- a/libcxx/include/vector
+++ b/libcxx/include/vector
@@ -297,6 +297,7 @@ erase_if(vector<T, Allocator>& c, Predicate pred);    // C++20
 #include <__utility/forward.h>
 #include <__utility/move.h>
 #include <__utility/swap.h>
+#include <__utility/transaction.h>
 #include <climits>
 #include <cstdlib>
 #include <cstring>
@@ -425,18 +426,27 @@ public:
                                     value_type,
                                     typename iterator_traits<_ForwardIterator>::reference>::value>::type* = 0);
 
-    _LIBCPP_CONSTEXPR_AFTER_CXX17 _LIBCPP_INLINE_VISIBILITY
-    ~vector()
-    {
-      __annotate_delete();
-      std::__debug_db_erase_c(this);
+private:
+  class __destroy_vector {
+    public:
+      _LIBCPP_CONSTEXPR __destroy_vector(vector& __vec) : __vec_(__vec) {}
 
-      if (this->__begin_ != nullptr)
-      {
-        __clear();
-        __alloc_traits::deallocate(__alloc(), this->__begin_, capacity());
+      _LIBCPP_CONSTEXPR_AFTER_CXX17 _LIBCPP_HIDE_FROM_ABI void operator()() {
+          __vec_.__annotate_delete();
+          std::__debug_db_erase_c(std::addressof(__vec_));
+
+          if (__vec_.__begin_ != nullptr) {
+            __vec_.__clear();
+            __alloc_traits::deallocate(__vec_.__alloc(), __vec_.__begin_, __vec_.capacity());
+          }
       }
-    }
+
+    private:
+      vector& __vec_;
+  };
+
+public:
+  _LIBCPP_CONSTEXPR_AFTER_CXX17 _LIBCPP_HIDE_FROM_ABI ~vector() { __destroy_vector(*this)(); }
 
     _LIBCPP_CONSTEXPR_AFTER_CXX17 vector(const vector& __x);
     _LIBCPP_CONSTEXPR_AFTER_CXX17 vector(const vector& __x, const __type_identity_t<allocator_type>& __a);
@@ -1075,12 +1085,14 @@ template <class _Tp, class _Allocator>
 _LIBCPP_CONSTEXPR_AFTER_CXX17
 vector<_Tp, _Allocator>::vector(size_type __n)
 {
-    _VSTD::__debug_db_insert_c(this);
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
     if (__n > 0)
     {
         __vallocate(__n);
         __construct_at_end(__n);
     }
+    __guard.__complete();
 }
 
 #if _LIBCPP_STD_VER > 11
@@ -1089,12 +1101,14 @@ _LIBCPP_CONSTEXPR_AFTER_CXX17
 vector<_Tp, _Allocator>::vector(size_type __n, const allocator_type& __a)
     : __end_cap_(nullptr, __a)
 {
-    _VSTD::__debug_db_insert_c(this);
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
     if (__n > 0)
     {
         __vallocate(__n);
         __construct_at_end(__n);
     }
+    __guard.__complete();
 }
 #endif
 
@@ -1102,12 +1116,14 @@ template <class _Tp, class _Allocator>
 _LIBCPP_CONSTEXPR_AFTER_CXX17
 vector<_Tp, _Allocator>::vector(size_type __n, const value_type& __x)
 {
-    _VSTD::__debug_db_insert_c(this);
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
     if (__n > 0)
     {
         __vallocate(__n);
         __construct_at_end(__n, __x);
     }
+    __guard.__complete();
 }
 
 template <class _Tp, class _Allocator>
@@ -1120,9 +1136,11 @@ vector<_Tp, _Allocator>::vector(_InputIterator __first,
                             typename iterator_traits<_InputIterator>::reference>::value,
                           _InputIterator>::type __last)
 {
-    _VSTD::__debug_db_insert_c(this);
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
     for (; __first != __last; ++__first)
         emplace_back(*__first);
+    __guard.__complete();
 }
 
 template <class _Tp, class _Allocator>
@@ -1135,9 +1153,11 @@ vector<_Tp, _Allocator>::vector(_InputIterator __first, _InputIterator __last, c
                             typename iterator_traits<_InputIterator>::reference>::value>::type*)
     : __end_cap_(nullptr, __a)
 {
-    _VSTD::__debug_db_insert_c(this);
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
     for (; __first != __last; ++__first)
         emplace_back(*__first);
+    __guard.__complete();
 }
 
 template <class _Tp, class _Allocator>
@@ -1150,13 +1170,15 @@ vector<_Tp, _Allocator>::vector(_ForwardIterator __first,
                                    typename iterator_traits<_ForwardIterator>::reference>::value,
                                                    _ForwardIterator>::type __last)
 {
-    _VSTD::__debug_db_insert_c(this);
-    size_type __n = static_cast<size_type>(_VSTD::distance(__first, __last));
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
+    size_type __n = static_cast<size_type>(std::distance(__first, __last));
     if (__n > 0)
     {
         __vallocate(__n);
         __construct_at_end(__first, __last, __n);
     }
+    __guard.__complete();
 }
 
 template <class _Tp, class _Allocator>
@@ -1169,13 +1191,15 @@ vector<_Tp, _Allocator>::vector(_ForwardIterator __first, _ForwardIterator __las
                                    typename iterator_traits<_ForwardIterator>::reference>::value>::type*)
     : __end_cap_(nullptr, __a)
 {
-    _VSTD::__debug_db_insert_c(this);
-    size_type __n = static_cast<size_type>(_VSTD::distance(__first, __last));
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
+    size_type __n = static_cast<size_type>(std::distance(__first, __last));
     if (__n > 0)
     {
         __vallocate(__n);
         __construct_at_end(__first, __last, __n);
     }
+    __guard.__complete();
 }
 
 template <class _Tp, class _Allocator>
@@ -1183,13 +1207,15 @@ _LIBCPP_CONSTEXPR_AFTER_CXX17
 vector<_Tp, _Allocator>::vector(const vector& __x)
     : __end_cap_(nullptr, __alloc_traits::select_on_container_copy_construction(__x.__alloc()))
 {
-    _VSTD::__debug_db_insert_c(this);
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
     size_type __n = __x.size();
     if (__n > 0)
     {
         __vallocate(__n);
         __construct_at_end(__x.__begin_, __x.__end_, __n);
     }
+    __guard.__complete();
 }
 
 template <class _Tp, class _Allocator>
@@ -1197,13 +1223,15 @@ _LIBCPP_CONSTEXPR_AFTER_CXX17
 vector<_Tp, _Allocator>::vector(const vector& __x, const __type_identity_t<allocator_type>& __a)
     : __end_cap_(nullptr, __a)
 {
-    _VSTD::__debug_db_insert_c(this);
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
     size_type __n = __x.size();
     if (__n > 0)
     {
         __vallocate(__n);
         __construct_at_end(__x.__begin_, __x.__end_, __n);
     }
+    __guard.__complete();
 }
 
 template <class _Tp, class _Allocator>
@@ -1243,7 +1271,9 @@ vector<_Tp, _Allocator>::vector(vector&& __x, const __type_identity_t<allocator_
     else
     {
         typedef move_iterator<iterator> _Ip;
+        auto __guard = std::__make_transaction(__destroy_vector(*this));
         assign(_Ip(__x.begin()), _Ip(__x.end()));
+        __guard.__complete();
     }
 }
 
@@ -1254,12 +1284,14 @@ _LIBCPP_CONSTEXPR_AFTER_CXX17
 inline _LIBCPP_INLINE_VISIBILITY
 vector<_Tp, _Allocator>::vector(initializer_list<value_type> __il)
 {
-    _VSTD::__debug_db_insert_c(this);
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
     if (__il.size() > 0)
     {
         __vallocate(__il.size());
         __construct_at_end(__il.begin(), __il.end(), __il.size());
     }
+    __guard.__complete();
 }
 
 template <class _Tp, class _Allocator>
@@ -1268,12 +1300,14 @@ inline _LIBCPP_INLINE_VISIBILITY
 vector<_Tp, _Allocator>::vector(initializer_list<value_type> __il, const allocator_type& __a)
     : __end_cap_(nullptr, __a)
 {
-    _VSTD::__debug_db_insert_c(this);
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    std::__debug_db_insert_c(this);
     if (__il.size() > 0)
     {
         __vallocate(__il.size());
         __construct_at_end(__il.begin(), __il.end(), __il.size());
     }
+    __guard.__complete();
 }
 
 #endif // _LIBCPP_CXX03_LANG
@@ -2111,8 +2145,26 @@ public:
 #else
         _NOEXCEPT;
 #endif
-    _LIBCPP_CONSTEXPR_AFTER_CXX17 ~vector();
-    _LIBCPP_CONSTEXPR_AFTER_CXX17 explicit vector(size_type __n);
+
+private:
+  class __destroy_vector {
+    public:
+      _LIBCPP_CONSTEXPR __destroy_vector(vector& __vec) : __vec_(__vec) {}
+
+      _LIBCPP_CONSTEXPR_AFTER_CXX17 _LIBCPP_HIDE_FROM_ABI void operator()() {
+        if (__vec_.__begin_ != nullptr)
+            __storage_traits::deallocate(__vec_.__alloc(), __vec_.__begin_, __vec_.__cap());
+        std::__debug_db_invalidate_all(this);
+      }
+
+    private:
+      vector& __vec_;
+  };
+
+public:
+  _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_AFTER_CXX17 ~vector() { __destroy_vector(*this)(); }
+
+    _LIBCPP_HIDE_FROM_ABI _LIBCPP_CONSTEXPR_AFTER_CXX17 explicit vector(size_type __n);
 #if _LIBCPP_STD_VER > 11
     _LIBCPP_CONSTEXPR_AFTER_CXX17 explicit vector(size_type __n, const allocator_type& __a);
 #endif
@@ -2647,12 +2699,14 @@ vector<bool, _Allocator>::vector(_ForwardIterator __first, _ForwardIterator __la
       __size_(0),
       __cap_alloc_(0, __default_init_tag())
 {
-    size_type __n = static_cast<size_type>(_VSTD::distance(__first, __last));
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    size_type __n = static_cast<size_type>(std::distance(__first, __last));
     if (__n > 0)
     {
         __vallocate(__n);
         __construct_at_end(__first, __last);
     }
+    __guard.__complete();
 }
 
 template <class _Allocator>
@@ -2664,12 +2718,14 @@ vector<bool, _Allocator>::vector(_ForwardIterator __first, _ForwardIterator __la
       __size_(0),
       __cap_alloc_(0, static_cast<__storage_allocator>(__a))
 {
-    size_type __n = static_cast<size_type>(_VSTD::distance(__first, __last));
+    auto __guard = std::__make_transaction(__destroy_vector(*this));
+    size_type __n = static_cast<size_type>(std::distance(__first, __last));
     if (__n > 0)
     {
         __vallocate(__n);
         __construct_at_end(__first, __last);
     }
+    __guard.__complete();
 }
 
 #ifndef _LIBCPP_CXX03_LANG
@@ -2706,15 +2762,6 @@ vector<bool, _Allocator>::vector(initializer_list<value_type> __il, const alloca
 
 #endif // _LIBCPP_CXX03_LANG
 
-template <class _Allocator>
-_LIBCPP_CONSTEXPR_AFTER_CXX17
-vector<bool, _Allocator>::~vector()
-{
-    if (__begin_ != nullptr)
-        __storage_traits::deallocate(__alloc(), __begin_, __cap());
-    std::__debug_db_invalidate_all(this);
-}
-
 template <class _Allocator>
 _LIBCPP_CONSTEXPR_AFTER_CXX17
 vector<bool, _Allocator>::vector(const vector& __v)
diff --git a/libcxx/test/std/containers/sequences/vector.bool/ctor_exceptions.pass.cpp b/libcxx/test/std/containers/sequences/vector.bool/ctor_exceptions.pass.cpp
new file mode 100644
index 00000000000000..592d733de42df7
--- /dev/null
+++ b/libcxx/test/std/containers/sequences/vector.bool/ctor_exceptions.pass.cpp
@@ -0,0 +1,141 @@
+//===----------------------------------------------------------------------===//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+// UNSUPPORTED: no-exceptions
+
+// (bug report: https://llvm.org/PR58392)
+// Check that vector<bool> constructors don't leak memory when an operation inside the constructor throws an exception
+
+#include <type_traits>
+#include <vector>
+
+#include "count_new.h"
+#include "test_iterators.h"
+
+template <class T>
+struct Allocator {
+  using value_type      = T;
+  using is_always_equal = std::false_type;
+
+  template <class U>
+  Allocator(const Allocator<U>&) {}
+
+  Allocator(bool should_throw = true) {
+    if (should_throw)
+      throw 0;
+  }
+
+  T* allocate(int n) { return std::allocator<T>().allocate(n); }
+  void deallocate(T* ptr, int n) { std::allocator<T>().deallocate(ptr, n); }
+
+  friend bool operator==(const Allocator&, const Allocator&) { return false; }
+};
+
+template <class IterCat>
+struct Iterator {
+  using iterator_category = IterCat;
+  using difference_type   = std::ptrdiff_t;
+  using value_type        = bool;
+  using reference         = bool&;
+  using pointer           = bool*;
+
+  int i_;
+  bool b_ = true;
+  Iterator(int i = 0) : i_(i) {}
+  bool& operator*() {
+    if (i_ == 1)
+      throw 1;
+    return b_;
+  }
+
+  friend bool operator==(const Iterator& lhs, const Iterator& rhs) { return lhs.i_ == rhs.i_; }
+
+  friend bool operator!=(const Iterator& lhs, const Iterator& rhs) { return lhs.i_ != rhs.i_; }
+
+  Iterator& operator++() {
+    ++i_;
+    return *this;
+  }
+
+  Iterator operator++(int) {
+    auto tmp = *this;
+    ++i_;
+    return tmp;
+  }
+};
+
+void check_new_delete_called() {
+  assert(globalMemCounter.new_called == globalMemCounter.delete_called);
+  assert(globalMemCounter.new_array_called == globalMemCounter.delete_array_called);
+  assert(globalMemCounter.aligned_new_called == globalMemCounter.aligned_delete_called);
+  assert(globalMemCounter.aligned_new_array_called == globalMemCounter.aligned_delete_array_called);
+}
+
+int main(int, char**) {
+  using AllocVec = std::vector<bool, Allocator<bool> >;
+
+#if TEST_STD_VER >= 14
+  try { // Throw in vector(size_type, const allocator_type&) from allocator
+    Allocator<bool> alloc(false);
+    AllocVec get_alloc(0, alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+#endif  // TEST_STD_VER >= 14
+
+  try { // Throw in vector(InputIterator, InputIterator) from input iterator
+    std::vector<bool> vec((Iterator<std::input_iterator_tag>()), Iterator<std::input_iterator_tag>(2));
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator) from forward iterator
+    std::vector<bool> vec((Iterator<std::forward_iterator_tag>()), Iterator<std::forward_iterator_tag>(2));
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator) from allocator
+    int a[] = {1, 2};
+    AllocVec vec(cpp17_input_iterator<int*>(a), cpp17_input_iterator<int*>(a + 2));
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator, const allocator_type&) from input iterator
+    std::allocator<bool> alloc;
+    std::vector<bool> vec(Iterator<std::input_iterator_tag>(), Iterator<std::input_iterator_tag>(2), alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator, const allocator_type&) from forward iterator
+    std::allocator<bool> alloc;
+    std::vector<bool> vec(Iterator<std::forward_iterator_tag>(), Iterator<std::forward_iterator_tag>(2), alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator, const allocator_type&) from allocator
+    bool a[] = {true, false};
+    Allocator<bool> alloc(false);
+    AllocVec vec(cpp17_input_iterator<bool*>(a), cpp17_input_iterator<bool*>(a + 2), alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator, const allocator_type&) from allocator
+    bool a[] = {true, false};
+    Allocator<bool> alloc(false);
+    AllocVec vec(forward_iterator<bool*>(a), forward_iterator<bool*>(a + 2), alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  return 0;
+}
diff --git a/libcxx/test/std/containers/sequences/vector/vector.cons/exceptions.pass.cpp b/libcxx/test/std/containers/sequences/vector/vector.cons/exceptions.pass.cpp
new file mode 100644
index 00000000000000..26ad7b4fd05aeb
--- /dev/null
+++ b/libcxx/test/std/containers/sequences/vector/vector.cons/exceptions.pass.cpp
@@ -0,0 +1,229 @@
+//===----------------------------------------------------------------------===//
+//
+// Part of the LLVM Project, under the Apache License v2.0 with LLVM Exceptions.
+// See https://llvm.org/LICENSE.txt for license information.
+// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
+//
+//===----------------------------------------------------------------------===//
+
+// UNSUPPORTED: no-exceptions
+
+// (bug report: https://llvm.org/PR58392)
+// Check that vector constructors don't leak memory when an operation inside the constructor throws an exception
+
+#include <type_traits>
+#include <vector>
+
+#include "count_new.h"
+#include "test_iterators.h"
+
+template <class T>
+struct Allocator {
+  using value_type      = T;
+  using is_always_equal = std::false_type;
+
+  Allocator(bool should_throw = true) {
+    if (should_throw)
+      throw 0;
+  }
+
+  T* allocate(int n) { return std::allocator<T>().allocate(n); }
+  void deallocate(T* ptr, int n) { std::allocator<T>().deallocate(ptr, n); }
+
+  friend bool operator==(const Allocator&, const Allocator&) { return false; }
+};
+
+struct ThrowingT {
+  int* throw_after_n_ = nullptr;
+  ThrowingT() { throw 0; }
+
+  ThrowingT(int& throw_after_n) : throw_after_n_(&throw_after_n) {
+    if (throw_after_n == 0)
+      throw 0;
+    --throw_after_n;
+  }
+
+  ThrowingT(const ThrowingT&) {
+    if (throw_after_n_ == nullptr || *throw_after_n_ == 0)
+      throw 1;
+    --*throw_after_n_;
+  }
+
+  ThrowingT& operator=(const ThrowingT&) {
+    if (throw_after_n_ == nullptr || *throw_after_n_ == 0)
+      throw 1;
+    --*throw_after_n_;
+    return *this;
+  }
+};
+
+template <class IterCat>
+struct Iterator {
+  using iterator_category = IterCat;
+  using difference_type   = std::ptrdiff_t;
+  using value_type        = int;
+  using reference         = int&;
+  using pointer           = int*;
+
+  int i_;
+  Iterator(int i = 0) : i_(i) {}
+  int& operator*() {
+    if (i_ == 1)
+      throw 1;
+    return i_;
+  }
+
+  friend bool operator==(const Iterator& lhs, const Iterator& rhs) { return lhs.i_ == rhs.i_; }
+
+  friend bool operator!=(const Iterator& lhs, const Iterator& rhs) { return lhs.i_ != rhs.i_; }
+
+  Iterator& operator++() {
+    ++i_;
+    return *this;
+  }
+
+  Iterator operator++(int) {
+    auto tmp = *this;
+    ++i_;
+    return tmp;
+  }
+};
+
+void check_new_delete_called() {
+  assert(globalMemCounter.new_called == globalMemCounter.delete_called);
+  assert(globalMemCounter.new_array_called == globalMemCounter.delete_array_called);
+  assert(globalMemCounter.aligned_new_called == globalMemCounter.aligned_delete_called);
+  assert(globalMemCounter.aligned_new_array_called == globalMemCounter.aligned_delete_array_called);
+}
+
+int main(int, char**) {
+  using AllocVec = std::vector<int, Allocator<int> >;
+  try { // vector()
+    AllocVec vec;
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(size_type) from type
+    std::vector<ThrowingT> get_alloc(1);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+#if TEST_STD_VER >= 14
+  try { // Throw in vector(size_type, value_type) from type
+    int throw_after = 1;
+    ThrowingT v(throw_after);
+    std::vector<ThrowingT> get_alloc(1, v);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(size_type, const allocator_type&) from allocator
+    Allocator<int> alloc(false);
+    AllocVec get_alloc(0, alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(size_type, const allocator_type&) from the type
+    std::vector<ThrowingT> vec(1, std::allocator<ThrowingT>());
+  } catch (int) {
+  }
+  check_new_delete_called();
+#endif  // TEST_STD_VER >= 14
+
+  try { // Throw in vector(InputIterator, InputIterator) from input iterator
+    std::vector<int> vec((Iterator<std::input_iterator_tag>()), Iterator<std::input_iterator_tag>(2));
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator) from forward iterator
+    std::vector<int> vec((Iterator<std::forward_iterator_tag>()), Iterator<std::forward_iterator_tag>(2));
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator) from allocator
+    int a[] = {1, 2};
+    AllocVec vec(cpp17_input_iterator<int*>(a), cpp17_input_iterator<int*>(a + 2));
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator, const allocator_type&) from input iterator
+    std::allocator<int> alloc;
+    std::vector<int> vec(Iterator<std::input_iterator_tag>(), Iterator<std::input_iterator_tag>(2), alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator, const allocator_type&) from forward iterator
+    std::allocator<int> alloc;
+    std::vector<int> vec(Iterator<std::forward_iterator_tag>(), Iterator<std::forward_iterator_tag>(2), alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator, const allocator_type&) from allocator
+    int a[] = {1, 2};
+    Allocator<int> alloc(false);
+    AllocVec vec(cpp17_input_iterator<int*>(a), cpp17_input_iterator<int*>(a + 2), alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(InputIterator, InputIterator, const allocator_type&) from allocator
+    int a[] = {1, 2};
+    Allocator<int> alloc(false);
+    AllocVec vec(forward_iterator<int*>(a), forward_iterator<int*>(a + 2), alloc);
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(const vector&) from type
+    std::vector<ThrowingT> vec;
+    int throw_after = 0;
+    vec.emplace_back(throw_after);
+    auto vec2 = vec;
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(const vector&, const allocator_type&) from type
+    std::vector<ThrowingT> vec;
+    int throw_after = 1;
+    vec.emplace_back(throw_after);
+    std::vector<ThrowingT> vec2(vec, std::allocator<int>());
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(vector&&, const allocator_type&) from type
+    std::vector<ThrowingT, Allocator<ThrowingT> > vec(Allocator<ThrowingT>(false));
+    int throw_after = 1;
+    vec.emplace_back(throw_after);
+    std::vector<ThrowingT, Allocator<ThrowingT> > vec2(std::move(vec), Allocator<ThrowingT>(false));
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+#if TEST_STD_VER >= 11
+  try { // Throw in vector(initializer_list<value_type>) from type
+    int throw_after = 1;
+    std::vector<ThrowingT> vec({ThrowingT(throw_after)});
+  } catch (int) {
+  }
+  check_new_delete_called();
+
+  try { // Throw in vector(initializer_list<value_type>, const allocator_type&) constructor from type
+    int throw_after = 1;
+    std::vector<ThrowingT> vec({ThrowingT(throw_after)}, std::allocator<ThrowingT>());
+  } catch (int) {
+  }
+  check_new_delete_called();
+#endif // TEST_STD_VER >= 11
+
+  return 0;
+}

From 6dda333befee1774d32e81dd554a07e2b07fb887 Mon Sep 17 00:00:00 2001
From: Valentin Churavy <v.churavy@gmail.com>
Date: Fri, 1 Oct 2021 19:45:59 -0400
Subject: [PATCH 58/84] Revert "[MC] Always emit relocations for same-section
 function references"

This reverts commit 5a5ac65768d124d98a10e8520363a0a4be3f4e38.

(cherry picked from commit ae2638d84b63af89ece7e30f39d435013ce42ee2)
(cherry picked from commit 05848b6d4d8ccc212f3ba9d9f58af42f26983e2c)
---
 llvm/lib/MC/WinCOFFObjectWriter.cpp | 12 +++++-------
 llvm/test/MC/COFF/diff.s            | 25 ++++++++-----------------
 2 files changed, 13 insertions(+), 24 deletions(-)

diff --git a/llvm/lib/MC/WinCOFFObjectWriter.cpp b/llvm/lib/MC/WinCOFFObjectWriter.cpp
index 809ac37c3442f7..8a5e6217329997 100644
--- a/llvm/lib/MC/WinCOFFObjectWriter.cpp
+++ b/llvm/lib/MC/WinCOFFObjectWriter.cpp
@@ -679,14 +679,12 @@ void WinCOFFObjectWriter::executePostLayoutBinding(MCAssembler &Asm,
 bool WinCOFFObjectWriter::isSymbolRefDifferenceFullyResolvedImpl(
     const MCAssembler &Asm, const MCSymbol &SymA, const MCFragment &FB,
     bool InSet, bool IsPCRel) const {
-  // Don't drop relocations between functions, even if they are in the same text
-  // section. Multiple Visual C++ linker features depend on having the
-  // relocations present. The /INCREMENTAL flag will cause these relocations to
-  // point to thunks, and the /GUARD:CF flag assumes that it can use relocations
-  // to approximate the set of all address taken functions. LLD's implementation
-  // of /GUARD:CF also relies on the existance of these relocations.
+  // MS LINK expects to be able to replace all references to a function with a
+  // thunk to implement their /INCREMENTAL feature.  Make sure we don't optimize
+  // away any relocations to functions.
   uint16_t Type = cast<MCSymbolCOFF>(SymA).getType();
-  if ((Type >> COFF::SCT_COMPLEX_TYPE_SHIFT) == COFF::IMAGE_SYM_DTYPE_FUNCTION)
+  if (Asm.isIncrementalLinkerCompatible() &&
+      (Type >> COFF::SCT_COMPLEX_TYPE_SHIFT) == COFF::IMAGE_SYM_DTYPE_FUNCTION)
     return false;
   return MCObjectWriter::isSymbolRefDifferenceFullyResolvedImpl(Asm, SymA, FB,
                                                                 InSet, IsPCRel);
diff --git a/llvm/test/MC/COFF/diff.s b/llvm/test/MC/COFF/diff.s
index 90466b59d02522..640bf8189e0395 100644
--- a/llvm/test/MC/COFF/diff.s
+++ b/llvm/test/MC/COFF/diff.s
@@ -1,14 +1,19 @@
 // RUN: llvm-mc -filetype=obj -triple i686-pc-mingw32 %s | llvm-readobj -S --sr --sd - | FileCheck %s
 
-// COFF resolves differences between labels in the same section, unless that
-// label is declared with function type.
-
 .section baz, "xr"
+	.def	X
+	.scl	2;
+	.type	32;
+	.endef
 	.globl	X
 X:
 	mov	Y-X+42,	%eax
 	retl
 
+	.def	Y
+	.scl	2;
+	.type	32;
+	.endef
 	.globl	Y
 Y:
 	retl
@@ -25,11 +30,6 @@ _foobar:                                # @foobar
 # %bb.0:
 	ret
 
-	.globl	_baz
-_baz:
-	calll	_foobar
-	retl
-
 	.data
 	.globl	_rust_crate             # @rust_crate
 	.align	4
@@ -39,15 +39,6 @@ _rust_crate:
 	.long	_foobar-_rust_crate
 	.long	_foobar-_rust_crate
 
-// Even though _baz and _foobar are in the same .text section, we keep the
-// relocation for compatibility with the VC linker's /guard:cf and /incremental
-// flags, even on mingw.
-
-// CHECK:        Name: .text
-// CHECK:        Relocations [
-// CHECK-NEXT:     0x12 IMAGE_REL_I386_REL32 _foobar
-// CHECK-NEXT:   ]
-
 // CHECK:        Name: .data
 // CHECK:        Relocations [
 // CHECK-NEXT:     0x4 IMAGE_REL_I386_DIR32 _foobar

From 630bca0939f8050d428dc291cc9c527371cd10b9 Mon Sep 17 00:00:00 2001
From: Valentin Churavy <v.churavy@gmail.com>
Date: Sat, 19 May 2018 11:56:55 -0400
Subject: [PATCH 59/84] Allow for custom address spaces

Julia uses addressspaces for GC and we want these to be sanitized as well.

(cherry picked from commit 3f53397f402b67341afe2bcb3a3316606b47d15c)
(cherry picked from commit 58df73b7d510d59462d56092595cf9c91404c601)
---
 llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp b/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp
index d4aa31db8337b1..be95324456dd88 100644
--- a/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp
+++ b/llvm/lib/Transforms/Instrumentation/ThreadSanitizer.cpp
@@ -383,7 +383,9 @@ static bool shouldInstrumentReadWriteFromAddress(const Module *M, Value *Addr) {
   // with them.
   if (Addr) {
     Type *PtrTy = cast<PointerType>(Addr->getType()->getScalarType());
-    if (PtrTy->getPointerAddressSpace() != 0)
+    auto AS = PtrTy->getPointerAddressSpace();
+    // Allow for custom addresspaces
+    if (AS != 0 && AS < 10)
       return false;
   }
 

From 485618de6fb93f78a4e23c9e860185540ab17d8e Mon Sep 17 00:00:00 2001
From: Keno Fischer <keno@juliacomputing.com>
Date: Wed, 29 Sep 2021 15:17:47 -0400
Subject: [PATCH 60/84] [clang/CMake] Respect LLVM_TOOLS_INSTALL_DIR

Otherwise clang installs all of its tools into `bin/` while
LLVM installs its tools into (LLVM_TOOLS_INSTALL_DIR).
I could swear this used to work (and in fact the julia build system
assumes it), but I can't pin down a specific commit that would
have broken this, and julia has been relying on pre-compiled binaries
for a while now (that don't use this setting), so it may have been
broken for quite a while.

Differential Revision: https://reviews.llvm.org/D88630

(cherry picked from commit 6104e14b830c31dffb1b6bce1c6f9a0760993ff1)
(cherry picked from commit f252e1795b885bf83f76ff4b029b0484aefebb31)
(cherry picked from commit 9039ce8ab323e8e0bea24323a7231e4c53070def)
---
 clang/cmake/modules/AddClang.cmake | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/clang/cmake/modules/AddClang.cmake b/clang/cmake/modules/AddClang.cmake
index 21ac332e4f5fc6..1aaf785bdc992e 100644
--- a/clang/cmake/modules/AddClang.cmake
+++ b/clang/cmake/modules/AddClang.cmake
@@ -166,7 +166,7 @@ macro(add_clang_tool name)
       get_target_export_arg(${name} Clang export_to_clangtargets)
       install(TARGETS ${name}
         ${export_to_clangtargets}
-        RUNTIME DESTINATION "${CMAKE_INSTALL_BINDIR}"
+        RUNTIME DESTINATION "${LLVM_TOOLS_INSTALL_DIR}"
         COMPONENT ${name})
 
       if(NOT LLVM_ENABLE_IDE)

From 88aa19dcdeaf49733ba5d05e3c8bb9e149c705c6 Mon Sep 17 00:00:00 2001
From: Valentin Churavy <v.churavy@gmail.com>
Date: Sat, 16 Jan 2021 17:36:09 -0500
Subject: [PATCH 61/84] Don't merge icmps derived from pointers with
 addressspaces

IIUC we can't emit `memcmp` between pointers in addressspaces,
doing so will trigger an assertion since the signature of the memcmp
will not match it's arguments (https://bugs.llvm.org/show_bug.cgi?id=48661).

This PR disables the attempt to merge icmps,
when the pointer is in an addressspace.

Differential Revision: https://reviews.llvm.org/D94813

(cherry picked from commit 458b259600f7efd82387eb7c4e09bdcee328106b)
(cherry picked from commit aaf2d2763f878f73770ccfdaf40f77a565b24a73)
---
 .../Transforms/MergeICmps/addressspaces.ll    | 67 +++++++++++++++++++
 1 file changed, 67 insertions(+)
 create mode 100644 llvm/test/Transforms/MergeICmps/addressspaces.ll

diff --git a/llvm/test/Transforms/MergeICmps/addressspaces.ll b/llvm/test/Transforms/MergeICmps/addressspaces.ll
new file mode 100644
index 00000000000000..9a74b4a5b2ca4b
--- /dev/null
+++ b/llvm/test/Transforms/MergeICmps/addressspaces.ll
@@ -0,0 +1,67 @@
+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
+; RUN: opt < %s -mergeicmps -S | FileCheck %s
+
+source_filename = "=="
+target datalayout = "e-m:e-i64:64-n32:64"
+target triple = "powerpc64le-unknown-linux-gnu"
+
+define void @juliaAS([2 x [5 x i64]] addrspace(11)* nocapture nonnull readonly align 8 dereferenceable(80) %0, [2 x [5 x i64]] addrspace(11)* nocapture nonnull readonly align 8 dereferenceable(80) %1) {
+; CHECK-LABEL: @juliaAS(
+; CHECK-NEXT:  top:
+; CHECK-NEXT:    [[TMP2:%.*]] = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* [[TMP0:%.*]], i64 0, i64 1, i64 2
+; CHECK-NEXT:    [[TMP3:%.*]] = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* [[TMP0]], i64 0, i64 1, i64 3
+; CHECK-NEXT:    [[TMP4:%.*]] = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* [[TMP0]], i64 0, i64 1, i64 4
+; CHECK-NEXT:    [[TMP5:%.*]] = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* [[TMP1:%.*]], i64 0, i64 1, i64 2
+; CHECK-NEXT:    [[TMP6:%.*]] = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* [[TMP1]], i64 0, i64 1, i64 3
+; CHECK-NEXT:    [[TMP7:%.*]] = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* [[TMP1]], i64 0, i64 1, i64 4
+; CHECK-NEXT:    [[TMP8:%.*]] = load i64, i64 addrspace(11)* [[TMP2]], align 8
+; CHECK-NEXT:    [[TMP9:%.*]] = load i64, i64 addrspace(11)* [[TMP5]], align 8
+; CHECK-NEXT:    [[DOTNOT17:%.*]] = icmp eq i64 [[TMP8]], [[TMP9]]
+; CHECK-NEXT:    br i1 [[DOTNOT17]], label [[L70:%.*]], label [[L90:%.*]]
+; CHECK:       L70:
+; CHECK-NEXT:    [[TMP10:%.*]] = load i64, i64 addrspace(11)* [[TMP3]], align 8
+; CHECK-NEXT:    [[TMP11:%.*]] = load i64, i64 addrspace(11)* [[TMP6]], align 8
+; CHECK-NEXT:    [[DOTNOT18:%.*]] = icmp eq i64 [[TMP10]], [[TMP11]]
+; CHECK-NEXT:    br i1 [[DOTNOT18]], label [[L74:%.*]], label [[L90]]
+; CHECK:       L74:
+; CHECK-NEXT:    [[TMP12:%.*]] = load i64, i64 addrspace(11)* [[TMP4]], align 8
+; CHECK-NEXT:    [[TMP13:%.*]] = load i64, i64 addrspace(11)* [[TMP7]], align 8
+; CHECK-NEXT:    [[DOTNOT19:%.*]] = icmp eq i64 [[TMP12]], [[TMP13]]
+; CHECK-NEXT:    br label [[L90]]
+; CHECK:       L90:
+; CHECK-NEXT:    [[VALUE_PHI2_OFF0:%.*]] = phi i1 [ false, [[TOP:%.*]] ], [ [[DOTNOT19]], [[L74]] ], [ false, [[L70]] ]
+; CHECK-NEXT:    ret void
+;
+top:
+  %2 = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* %0, i64 0, i64 1, i64 2
+  %3 = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* %0, i64 0, i64 1, i64 3
+  %4 = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* %0, i64 0, i64 1, i64 4
+  %5 = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* %1, i64 0, i64 1, i64 2
+  %6 = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* %1, i64 0, i64 1, i64 3
+  %7 = getelementptr inbounds [2 x [5 x i64]], [2 x [5 x i64]] addrspace(11)* %1, i64 0, i64 1, i64 4
+  %8 = load i64, i64 addrspace(11)* %2, align 8
+  %9 = load i64, i64 addrspace(11)* %5, align 8
+  %.not17 = icmp eq i64 %8, %9
+  br i1 %.not17, label %L70, label %L90
+
+L70:                                              ; preds = %top
+  %10 = load i64, i64 addrspace(11)* %3, align 8
+  %11 = load i64, i64 addrspace(11)* %6, align 8
+  %.not18 = icmp eq i64 %10, %11
+  br i1 %.not18, label %L74, label %L90
+
+L74:                                              ; preds = %L70
+  %12 = load i64, i64 addrspace(11)* %4, align 8
+  %13 = load i64, i64 addrspace(11)* %7, align 8
+  %.not19 = icmp eq i64 %12, %13
+  br label %L90
+
+L90:                                              ; preds = %L74, %L70, %top
+  %value_phi2.off0 = phi i1 [ false, %top ], [ %.not19, %L74 ], [ false, %L70 ]
+  ret void
+}
+
+!llvm.module.flags = !{!0}
+
+!0 = !{i32 1, !"Debug Info Version", i32 3}
+

From d174fde13ef758046b9b94028127c5a6d1dc3f91 Mon Sep 17 00:00:00 2001
From: Keno Fischer <keno@juliacomputing.com>
Date: Mon, 1 Mar 2021 16:42:05 -0500
Subject: [PATCH 62/84] AArch64: Remove Bad optimization

Removes the code responsible for causing https://bugs.llvm.org/show_bug.cgi?id=49357.
A fix is in progress upstream, but I don't think it's easy, so this
fixes the bug in the meantime. The optimization it does is minor.

(cherry picked from commit e4f1085c5c04e106e5a7ee72c9f4dfe1dccb7b94)
(cherry picked from commit 7627d618e0e62cdb6d9394d37198dab2a02252f1)
---
 llvm/lib/Target/AArch64/AArch64FastISel.cpp | 17 -----------------
 1 file changed, 17 deletions(-)

diff --git a/llvm/lib/Target/AArch64/AArch64FastISel.cpp b/llvm/lib/Target/AArch64/AArch64FastISel.cpp
index 49fffa01a974d6..5769e561c4ce7c 100644
--- a/llvm/lib/Target/AArch64/AArch64FastISel.cpp
+++ b/llvm/lib/Target/AArch64/AArch64FastISel.cpp
@@ -4503,23 +4503,6 @@ bool AArch64FastISel::selectIntExt(const Instruction *I) {
 
   // Try to optimize already sign-/zero-extended values from function arguments.
   bool IsZExt = isa<ZExtInst>(I);
-  if (const auto *Arg = dyn_cast<Argument>(I->getOperand(0))) {
-    if ((IsZExt && Arg->hasZExtAttr()) || (!IsZExt && Arg->hasSExtAttr())) {
-      if (RetVT == MVT::i64 && SrcVT != MVT::i64) {
-        Register ResultReg = createResultReg(&AArch64::GPR64RegClass);
-        BuildMI(*FuncInfo.MBB, FuncInfo.InsertPt, DbgLoc,
-                TII.get(AArch64::SUBREG_TO_REG), ResultReg)
-            .addImm(0)
-            .addReg(SrcReg)
-            .addImm(AArch64::sub_32);
-        SrcReg = ResultReg;
-      }
-
-      updateValueMap(I, SrcReg);
-      return true;
-    }
-  }
-
   unsigned ResultReg = emitIntExt(SrcVT, SrcReg, RetVT, IsZExt);
   if (!ResultReg)
     return false;

From 2a46debe589a1b3f913c0e2f7578e3625d624918 Mon Sep 17 00:00:00 2001
From: Keno Fischer <kfischer@college.harvard.edu>
Date: Sat, 30 Apr 2022 19:00:11 +0100
Subject: [PATCH 63/84] Add support for unwinding during prologue/epilogue

(cherry picked from commit 5393efbd8a4c7555b9f9fdf185c486c6b05f0c19)
---
 libunwind/src/CompactUnwinder.hpp | 156 ++++++++++++++++++++++++++++++
 1 file changed, 156 insertions(+)

diff --git a/libunwind/src/CompactUnwinder.hpp b/libunwind/src/CompactUnwinder.hpp
index 0b2b5e111bfc26..ad0e042cb6ba11 100644
--- a/libunwind/src/CompactUnwinder.hpp
+++ b/libunwind/src/CompactUnwinder.hpp
@@ -310,6 +310,50 @@ int CompactUnwinder_x86_64<A>::stepWithCompactEncodingRBPFrame(
   uint32_t savedRegistersLocations =
       EXTRACT_BITS(compactEncoding, UNWIND_X86_64_RBP_FRAME_REGISTERS);
 
+  // If we have not stored EBP yet
+  if (functionStart == registers.getIP()) {
+    uint64_t rsp = registers.getSP();
+    // old esp is ebp less return address
+    registers.setSP(rsp+8);
+    // pop return address into eip
+    registers.setIP(addressSpace.get64(rsp));
+
+    return UNW_STEP_SUCCESS;
+  } else if (functionStart + 1 == registers.getIP()) {
+    uint64_t rsp = registers.getSP();
+    // old esp is ebp less return address
+    registers.setSP(rsp + 16);
+    // pop return address into eip
+    registers.setIP(addressSpace.get64(rsp + 8));
+
+    return UNW_STEP_SUCCESS;
+  }
+
+  // If we're about to return, we've already popped the base pointer
+  uint8_t b = addressSpace.get8(registers.getIP());
+
+  // This is a hack to detect VZEROUPPER but in between popq rbp and ret
+  // It's not pretty but it works
+  if (b == 0xC5) {
+    if ((b = addressSpace.get8(registers.getIP() + 1)) == 0xF8 &&
+        (b = addressSpace.get8(registers.getIP() + 2)) == 0x77)
+      b = addressSpace.get8(registers.getIP() + 3);
+    else
+      goto skip_ret;
+  }
+
+  if (b == 0xC3 || b == 0xCB || b == 0xC2 || b == 0xCA) {
+    uint64_t rbp = registers.getSP();
+    // old esp is ebp less return address
+    registers.setSP(rbp + 16);
+    // pop return address into eip
+    registers.setIP(addressSpace.get64(rbp + 8));
+
+    return UNW_STEP_SUCCESS;
+  }
+
+  skip_ret:
+
   uint64_t savedRegisters = registers.getRBP() - 8 * savedRegistersOffset;
   for (int i = 0; i < 5; ++i) {
     switch (savedRegistersLocations & 0x7) {
@@ -430,6 +474,118 @@ int CompactUnwinder_x86_64<A>::stepWithCompactEncodingFrameless(
       }
     }
   }
+
+  // Note that the order of these registers is so that
+  // registersSaved[0] is the one that will be pushed onto the stack last.
+  // Thus, if we want to walk this from the top, we need to go in reverse.
+  assert(regCount <= 6);
+
+  // check whether we are still in the prologue
+  uint64_t curAddr = functionStart;
+  if (regCount > 0) {
+    for (int8_t i = (int8_t)(regCount) - 1; i >= 0; --i) {
+      if (registers.getIP() == curAddr) {
+        // None of the registers have been modified yet, so we don't need to reload them
+        framelessUnwind(addressSpace, registers.getSP() + 8 * (regCount - (uint64_t)(i + 1)), registers);
+        return UNW_STEP_SUCCESS;
+      } else {
+        assert(curAddr < registers.getIP());
+      }
+
+
+      // pushq %rbp and pushq %rbx is 1 byte. Everything else 2
+      if ((UNWIND_X86_64_REG_RBP == registersSaved[i]) ||
+          (UNWIND_X86_64_REG_RBX == registersSaved[i]))
+        curAddr += 1;
+      else
+        curAddr += 2;
+    }
+  }
+  if (registers.getIP() == curAddr) {
+    // None of the registers have been modified yet, so we don't need to reload them
+    framelessUnwind(addressSpace, registers.getSP() + 8*regCount, registers);
+    return UNW_STEP_SUCCESS;
+  } else {
+    assert(curAddr < registers.getIP());
+  }
+
+
+  // And now for the epilogue
+  {
+    uint8_t  i  = 0;
+    uint64_t p  = registers.getIP();
+    uint8_t  b  = 0;
+
+    while (true) {
+      b = addressSpace.get8(p++);
+      // This is a hack to detect VZEROUPPER but in between the popq's and ret
+      // It's not pretty but it works
+      if (b == 0xC5) {
+        if ((b = addressSpace.get8(p++)) == 0xF8 && (b = addressSpace.get8(p++)) == 0x77)
+          b = addressSpace.get8(p++);
+        else
+          break;
+      }
+      //  popq %rbx    popq %rbp
+      if (b == 0x5B || b == 0x5D) {
+        i++;
+      } else if (b == 0x41) {
+        b = addressSpace.get8(p++);
+        if (b == 0x5C || b == 0x5D || b == 0x5E || b == 0x5F)
+          i++;
+        else
+          break;
+      } else if (b == 0xC3 || b == 0xCB || b == 0xC2 || b == 0xCA) {
+        // i pop's haven't happened yet
+        uint64_t savedRegisters = registers.getSP() + 8 * i;
+        if (regCount > 0) {
+          for (int8_t j = (int8_t)(regCount) - 1; j >= (int8_t)(regCount) - i; --j) {
+            uint64_t addr = savedRegisters - 8 * (regCount - (uint64_t)(j));
+            switch (registersSaved[j]) {
+              case UNWIND_X86_64_REG_RBX:
+                registers.setRBX(addressSpace.get64(addr));
+                break;
+              case UNWIND_X86_64_REG_R12:
+                registers.setR12(addressSpace.get64(addr));
+                break;
+              case UNWIND_X86_64_REG_R13:
+                registers.setR13(addressSpace.get64(addr));
+                break;
+              case UNWIND_X86_64_REG_R14:
+                registers.setR14(addressSpace.get64(addr));
+                break;
+              case UNWIND_X86_64_REG_R15:
+                registers.setR15(addressSpace.get64(addr));
+                break;
+              case UNWIND_X86_64_REG_RBP:
+                registers.setRBP(addressSpace.get64(addr));
+                break;
+              default:
+                _LIBUNWIND_DEBUG_LOG("bad register for frameless, encoding=%08X for "
+                             "function starting at 0x%llX",
+                              encoding, functionStart);
+                _LIBUNWIND_ABORT("invalid compact unwind encoding");
+            }
+          }
+        }
+        framelessUnwind(addressSpace, savedRegisters, registers);
+        return UNW_STEP_SUCCESS;
+      } else {
+        break;
+      }
+    }
+  }
+
+  /*
+   0x10fe2733a:  5b                             popq   %rbx
+   0x10fe2733b:  41 5c                          popq   %r12
+   0x10fe2733d:  41 5d                          popq   %r13
+   0x10fe2733f:  41 5e                          popq   %r14
+   0x10fe27341:  41 5f                          popq   %r15
+   0x10fe27343:  5d                             popq   %rbp
+   */
+
+
   uint64_t savedRegisters = registers.getSP() + stackSize - 8 - 8 * regCount;
   for (uint32_t i = 0; i < regCount; ++i) {
     switch (registersSaved[i]) {

From 8482aa12a3fcbfd4a1ca69aba58b20a6af111497 Mon Sep 17 00:00:00 2001
From: Julian P Samaroo <jpsamaroo@jpsamaroo.me>
Date: Tue, 18 Jan 2022 13:32:28 -0600
Subject: [PATCH 64/84] [LLD] Respect LLVM_TOOLS_INSTALL_DIR

Co-authored-by: Valentin Churavy <v.churavy@gmail.com>
Co-authored-by: Julian P Samaroo <jpsamaroo@jpsamaroo.me>
(cherry picked from commit a0defe021cee2076dc161eceeaab70297b386b91)
---
 lld/cmake/modules/AddLLD.cmake | 4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/lld/cmake/modules/AddLLD.cmake b/lld/cmake/modules/AddLLD.cmake
index d3924f7243d403..01b4fe65a45ac2 100644
--- a/lld/cmake/modules/AddLLD.cmake
+++ b/lld/cmake/modules/AddLLD.cmake
@@ -20,7 +20,7 @@ macro(add_lld_library name)
       ${export_to_lldtargets}
       LIBRARY DESTINATION lib${LLVM_LIBDIR_SUFFIX}
       ARCHIVE DESTINATION lib${LLVM_LIBDIR_SUFFIX}
-      RUNTIME DESTINATION "${CMAKE_INSTALL_BINDIR}")
+      RUNTIME DESTINATION ${LLVM_TOOLS_INSTALL_DIR})
 
     if (${ARG_SHARED} AND NOT CMAKE_CONFIGURATION_TYPES)
       add_llvm_install_targets(install-${name}
@@ -47,7 +47,7 @@ macro(add_lld_tool name)
     get_target_export_arg(${name} LLD export_to_lldtargets)
     install(TARGETS ${name}
       ${export_to_lldtargets}
-      RUNTIME DESTINATION "${CMAKE_INSTALL_BINDIR}"
+      RUNTIME DESTINATION ${LLVM_TOOLS_INSTALL_DIR}
       COMPONENT ${name})
 
     if(NOT CMAKE_CONFIGURATION_TYPES)

From e74c41e9d2391523d0e4174c2fb096dbddb7622a Mon Sep 17 00:00:00 2001
From: Valentin Churavy <v.churavy@gmail.com>
Date: Mon, 2 May 2022 10:04:47 -0400
Subject: [PATCH 65/84] [Sanitizers] Guard FP_XSTATE_MAGIC1 usage by GLIBC
 version

Follow-up on https://reviews.llvm.org/D118970 FP_XSTATE_MAGIC1 is only available on glibc 2.27 and upwards

Differential Revision: https://reviews.llvm.org/D124770
---
 .../lib/sanitizer_common/sanitizer_platform_limits_posix.cpp    | 2 +-
 compiler-rt/test/msan/Linux/signal_mcontext.cpp                 | 2 +-
 2 files changed, 2 insertions(+), 2 deletions(-)

diff --git a/compiler-rt/lib/sanitizer_common/sanitizer_platform_limits_posix.cpp b/compiler-rt/lib/sanitizer_common/sanitizer_platform_limits_posix.cpp
index c85cf1626a75b1..e648b829a03724 100644
--- a/compiler-rt/lib/sanitizer_common/sanitizer_platform_limits_posix.cpp
+++ b/compiler-rt/lib/sanitizer_common/sanitizer_platform_limits_posix.cpp
@@ -223,7 +223,7 @@ namespace __sanitizer {
   unsigned struct_sockaddr_sz = sizeof(struct sockaddr);
 
   unsigned ucontext_t_sz(void *ctx) {
-#    if SANITIZER_GLIBC && SANITIZER_X64
+#    if SANITIZER_GLIBC && SANITIZER_X64 &&  __GLIBC_PREREQ (2, 27)
     // Added in Linux kernel 3.4.0, merged to glibc in 2.16
 #      ifndef FP_XSTATE_MAGIC1
 #        define FP_XSTATE_MAGIC1 0x46505853U
diff --git a/compiler-rt/test/msan/Linux/signal_mcontext.cpp b/compiler-rt/test/msan/Linux/signal_mcontext.cpp
index b49451fbb730b6..11ef74e7462bbe 100644
--- a/compiler-rt/test/msan/Linux/signal_mcontext.cpp
+++ b/compiler-rt/test/msan/Linux/signal_mcontext.cpp
@@ -10,7 +10,7 @@
 
 void handler(int sig, siginfo_t *info, void *uctx) {
   __msan_check_mem_is_initialized(uctx, sizeof(ucontext_t));
-#if defined(__GLIBC__) && defined(__x86_64__)
+#if defined(__GLIBC__) && defined(__x86_64__) && __GLIBC_PREREQ(2, 27)
   auto *mctx = &static_cast<ucontext_t *>(uctx)->uc_mcontext;
   if (auto *fpregs = mctx->fpregs) {
     // The member names differ across header versions, but the actual layout

From 425cad85181bc0fcc2e6ebf75f3a183445909953 Mon Sep 17 00:00:00 2001
From: Cody Tapscott <cody+github@tapscott.me>
Date: Mon, 24 May 2021 16:36:06 -0700
Subject: [PATCH 66/84] Force `.eh_frame` emission on AArch64

We need to force the emission of the EH Frame section (currently done via SupportsCompactUnwindWithoutEHFrame in the MCObjectFileInfo for the target), since libunwind doesn't yet support dynamically registering compact unwind information at run-time.

(cherry picked from commit 60e041894288848e37870c42749a1aabcc2c2274)
(cherry picked from commit 6275013da5e8cd5e552bd5bb7d85c7b0524ca69d)
---
 llvm/lib/MC/MCObjectFileInfo.cpp | 7 ++++---
 1 file changed, 4 insertions(+), 3 deletions(-)

diff --git a/llvm/lib/MC/MCObjectFileInfo.cpp b/llvm/lib/MC/MCObjectFileInfo.cpp
index d6fe952c0c1d87..6d422efc7fbcc8 100644
--- a/llvm/lib/MC/MCObjectFileInfo.cpp
+++ b/llvm/lib/MC/MCObjectFileInfo.cpp
@@ -61,9 +61,10 @@ void MCObjectFileInfo::initMachOMCObjectFileInfo(const Triple &T) {
           MachO::S_ATTR_STRIP_STATIC_SYMS | MachO::S_ATTR_LIVE_SUPPORT,
       SectionKind::getReadOnly());
 
-  if (T.isOSDarwin() &&
-      (T.getArch() == Triple::aarch64 || T.getArch() == Triple::aarch64_32))
-    SupportsCompactUnwindWithoutEHFrame = true;
+  // Disabled for now, since we need to emit EH Frames for stack unwinding in the JIT
+  // if (T.isOSDarwin() &&
+  //     (T.getArch() == Triple::aarch64 || T.getArch() == Triple::aarch64_32))
+  //   SupportsCompactUnwindWithoutEHFrame = true;
 
   switch (Ctx->emitDwarfUnwindInfo()) {
   case EmitDwarfUnwindType::Always:

From 2e0d8422b279c7d2363ff199e5fb1970d1c6950d Mon Sep 17 00:00:00 2001
From: Jameson Nash <vtjnash@gmail.com>
Date: Thu, 30 Jun 2022 17:25:48 -0400
Subject: [PATCH 67/84] [SimplifyCFG] teach simplifycfg not to introduce
 ptrtoint for NI pointers

SimplifyCFG expects to be able to cast both sides to an int, if either side can be case to an int, but this is not desirable or legal, in general, per D104547.

Spotted in https://github.com/JuliaLang/julia/issues/45702

Differential Revision: https://reviews.llvm.org/D128670

(cherry picked from commit b904e7e94c5cc9d86762b32211cd0e35670534cb)
---
 llvm/lib/Transforms/Utils/SimplifyCFG.cpp     |  3 +-
 .../Transforms/SimplifyCFG/nonintegral.ll     | 29 +++++++++++++++++++
 2 files changed, 31 insertions(+), 1 deletion(-)
 create mode 100644 llvm/test/Transforms/SimplifyCFG/nonintegral.ll

diff --git a/llvm/lib/Transforms/Utils/SimplifyCFG.cpp b/llvm/lib/Transforms/Utils/SimplifyCFG.cpp
index 1806081678a867..74eaf228c9417c 100644
--- a/llvm/lib/Transforms/Utils/SimplifyCFG.cpp
+++ b/llvm/lib/Transforms/Utils/SimplifyCFG.cpp
@@ -472,7 +472,8 @@ static bool dominatesMergePoint(Value *V, BasicBlock *BB,
 static ConstantInt *GetConstantInt(Value *V, const DataLayout &DL) {
   // Normal constant int.
   ConstantInt *CI = dyn_cast<ConstantInt>(V);
-  if (CI || !isa<Constant>(V) || !V->getType()->isPointerTy())
+  if (CI || !isa<Constant>(V) || !V->getType()->isPointerTy() ||
+      DL.isNonIntegralPointerType(V->getType()))
     return CI;
 
   // This is some kind of pointer constant. Turn it into a pointer-sized
diff --git a/llvm/test/Transforms/SimplifyCFG/nonintegral.ll b/llvm/test/Transforms/SimplifyCFG/nonintegral.ll
new file mode 100644
index 00000000000000..00c295ddc5c6d7
--- /dev/null
+++ b/llvm/test/Transforms/SimplifyCFG/nonintegral.ll
@@ -0,0 +1,29 @@
+; RUN: opt -simplifycfg -verify -S < %s | FileCheck %s
+; RUN: opt -passes=simplifycfg,verify -S < %s | FileCheck %s
+
+target datalayout = "ni:1"
+
+define void @test_01(i64 addrspace(1)* align 8 %ptr) local_unnamed_addr #0 {
+; CHECK-LABEL: @test_01(
+; CHECK-NOT:   ptrtoint
+; CHECK-NEXT:  icmp eq i64 addrspace(1)* %ptr, null
+; CHECK-NOT:   ptrtoint
+  %cond1 = icmp eq i64 addrspace(1)* %ptr, null
+  %cond2 = icmp eq i64 addrspace(1)* %ptr, null
+  br i1 %cond1, label %true1, label %false1
+
+true1:
+  br i1 %cond2, label %true2, label %false2
+
+false1:
+  store i64 1, i64 addrspace(1)* %ptr, align 8
+  br label %true1
+
+true2:
+  store i64 2, i64 addrspace(1)* %ptr, align 8
+  ret void
+
+false2:
+  store i64 3, i64 addrspace(1)* %ptr, align 8
+  ret void
+}

From 0deac677ceabe1b285a8a741ea6f319a2a0fbb06 Mon Sep 17 00:00:00 2001
From: Chen Zheng <czhengsz@cn.ibm.com>
Date: Tue, 19 Jul 2022 04:24:49 -0400
Subject: [PATCH 68/84] [NFC] add test cases for D123366

(cherry picked from commit 13016f1f1be5864dacdc8e15b920465dcec2b49a)
---
 llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll | 449 +++++++++++++++++++
 1 file changed, 449 insertions(+)
 create mode 100644 llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll

diff --git a/llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll b/llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll
new file mode 100644
index 00000000000000..39f33d9e849a01
--- /dev/null
+++ b/llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll
@@ -0,0 +1,449 @@
+; NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
+; RUN: llc -verify-machineinstrs -stop-after=finalize-isel -mtriple=powerpc64-ibm-aix-xcoff \
+; RUN:   -mcpu=pwr4 < %s | FileCheck -check-prefix=AIX64 %s
+; RUN: llc -verify-machineinstrs -stop-after=finalize-isel -mtriple=powerpc-ibm-aix-xcoff \
+; RUN:   -mcpu=pwr4 < %s | FileCheck -check-prefix=AIX32 %s
+; RUN: llc -verify-machineinstrs -stop-after=finalize-isel -mtriple=powerpc64le-unknown-linux-gnu \
+; RUN:   -mcpu=pwr8 < %s | FileCheck -check-prefix=LE64 %s
+
+;; This file is copied from test/CodeGen/PowerPC/ctrloops.ll.
+;; In this file, we are testing the CTR loops form after ISEL.
+
+@a = common global i32 0, align 4
+
+define void @test1(i32 %c) nounwind {
+  ; AIX64-LABEL: name: test1
+  ; AIX64: bb.0.entry:
+  ; AIX64-NEXT:   successors: %bb.1(0x80000000)
+  ; AIX64-NEXT:   liveins: $x3
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   [[COPY:%[0-9]+]]:g8rc = COPY $x3
+  ; AIX64-NEXT:   [[COPY1:%[0-9]+]]:gprc = COPY [[COPY]].sub_32
+  ; AIX64-NEXT:   [[LI8_:%[0-9]+]]:g8rc = LI8 2048
+  ; AIX64-NEXT:   MTCTR8loop killed [[LI8_]], implicit-def dead $ctr8
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.1.for.body:
+  ; AIX64-NEXT:   successors: %bb.1(0x7c000000), %bb.2(0x04000000)
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   [[LDtoc:%[0-9]+]]:g8rc_and_g8rc_nox0 = LDtoc @a, $x2 :: (load (s64) from got)
+  ; AIX64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtoc]] :: (volatile dereferenceable load (s32) from @a)
+  ; AIX64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY1]]
+  ; AIX64-NEXT:   STW killed [[ADD4_]], 0, [[LDtoc]] :: (volatile store (s32) into @a)
+  ; AIX64-NEXT:   BDNZ8 %bb.1, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   B %bb.2
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.2.for.end:
+  ; AIX64-NEXT:   BLR8 implicit $lr8, implicit $rm
+  ; AIX32-LABEL: name: test1
+  ; AIX32: bb.0.entry:
+  ; AIX32-NEXT:   successors: %bb.1(0x80000000)
+  ; AIX32-NEXT:   liveins: $r3
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   [[COPY:%[0-9]+]]:gprc = COPY $r3
+  ; AIX32-NEXT:   [[LI:%[0-9]+]]:gprc = LI 2048
+  ; AIX32-NEXT:   MTCTRloop killed [[LI]], implicit-def dead $ctr
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.1.for.body:
+  ; AIX32-NEXT:   successors: %bb.1(0x7c000000), %bb.2(0x04000000)
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   [[LWZtoc:%[0-9]+]]:gprc_and_gprc_nor0 = LWZtoc @a, $r2 :: (load (s32) from got)
+  ; AIX32-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LWZtoc]] :: (volatile dereferenceable load (s32) from @a)
+  ; AIX32-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY]]
+  ; AIX32-NEXT:   STW killed [[ADD4_]], 0, [[LWZtoc]] :: (volatile store (s32) into @a)
+  ; AIX32-NEXT:   BDNZ %bb.1, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   B %bb.2
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.2.for.end:
+  ; AIX32-NEXT:   BLR implicit $lr, implicit $rm
+  ; LE64-LABEL: name: test1
+  ; LE64: bb.0.entry:
+  ; LE64-NEXT:   successors: %bb.1(0x80000000)
+  ; LE64-NEXT:   liveins: $x3
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   [[COPY:%[0-9]+]]:g8rc = COPY $x3
+  ; LE64-NEXT:   [[COPY1:%[0-9]+]]:gprc = COPY [[COPY]].sub_32
+  ; LE64-NEXT:   [[LI8_:%[0-9]+]]:g8rc = LI8 2048
+  ; LE64-NEXT:   MTCTR8loop killed [[LI8_]], implicit-def dead $ctr8
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.1.for.body:
+  ; LE64-NEXT:   successors: %bb.1(0x7c000000), %bb.2(0x04000000)
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   [[ADDIStocHA8_:%[0-9]+]]:g8rc_and_g8rc_nox0 = ADDIStocHA8 $x2, @a
+  ; LE64-NEXT:   [[LDtocL:%[0-9]+]]:g8rc_and_g8rc_nox0 = LDtocL @a, killed [[ADDIStocHA8_]] :: (load (s64) from got)
+  ; LE64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtocL]] :: (volatile dereferenceable load (s32) from @a)
+  ; LE64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY1]]
+  ; LE64-NEXT:   STW killed [[ADD4_]], 0, [[LDtocL]] :: (volatile store (s32) into @a)
+  ; LE64-NEXT:   BDNZ8 %bb.1, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   B %bb.2
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.2.for.end:
+  ; LE64-NEXT:   BLR8 implicit $lr8, implicit $rm
+entry:
+  br label %for.body
+
+for.body:                                         ; preds = %for.body, %entry
+  %i.01 = phi i32 [ 0, %entry ], [ %inc, %for.body ]
+  %0 = load volatile i32, i32* @a, align 4
+  %add = add nsw i32 %0, %c
+  store volatile i32 %add, i32* @a, align 4
+  %inc = add nsw i32 %i.01, 1
+  %exitcond = icmp eq i32 %inc, 2048
+  br i1 %exitcond, label %for.end, label %for.body
+
+for.end:                                          ; preds = %for.body
+  ret void
+}
+
+define void @test2(i32 %c, i32 %d) nounwind {
+  ; AIX64-LABEL: name: test2
+  ; AIX64: bb.0.entry:
+  ; AIX64-NEXT:   successors: %bb.1(0x50000000), %bb.3(0x30000000)
+  ; AIX64-NEXT:   liveins: $x3, $x4
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   [[COPY:%[0-9]+]]:g8rc = COPY $x4
+  ; AIX64-NEXT:   [[COPY1:%[0-9]+]]:g8rc = COPY $x3
+  ; AIX64-NEXT:   [[COPY2:%[0-9]+]]:gprc = COPY [[COPY1]].sub_32
+  ; AIX64-NEXT:   [[COPY3:%[0-9]+]]:gprc_and_gprc_nor0 = COPY [[COPY]].sub_32
+  ; AIX64-NEXT:   [[CMPWI:%[0-9]+]]:crrc = CMPWI [[COPY3]], 1
+  ; AIX64-NEXT:   BCC 12, killed [[CMPWI]], %bb.3
+  ; AIX64-NEXT:   B %bb.1
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.1.for.body.preheader:
+  ; AIX64-NEXT:   successors: %bb.2(0x80000000)
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   [[ADDI:%[0-9]+]]:gprc = ADDI [[COPY3]], -1
+  ; AIX64-NEXT:   [[DEF:%[0-9]+]]:g8rc = IMPLICIT_DEF
+  ; AIX64-NEXT:   [[INSERT_SUBREG:%[0-9]+]]:g8rc = INSERT_SUBREG [[DEF]], killed [[ADDI]], %subreg.sub_32
+  ; AIX64-NEXT:   [[RLDICL:%[0-9]+]]:g8rc_and_g8rc_nox0 = RLDICL killed [[INSERT_SUBREG]], 0, 32
+  ; AIX64-NEXT:   [[ADDI8_:%[0-9]+]]:g8rc = nuw nsw ADDI8 killed [[RLDICL]], 1
+  ; AIX64-NEXT:   MTCTR8loop killed [[ADDI8_]], implicit-def dead $ctr8
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.2.for.body:
+  ; AIX64-NEXT:   successors: %bb.2(0x7c000000), %bb.3(0x04000000)
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   [[LDtoc:%[0-9]+]]:g8rc_and_g8rc_nox0 = LDtoc @a, $x2 :: (load (s64) from got)
+  ; AIX64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtoc]] :: (volatile dereferenceable load (s32) from @a)
+  ; AIX64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY2]]
+  ; AIX64-NEXT:   STW killed [[ADD4_]], 0, [[LDtoc]] :: (volatile store (s32) into @a)
+  ; AIX64-NEXT:   BDNZ8 %bb.2, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   B %bb.3
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.3.for.end:
+  ; AIX64-NEXT:   BLR8 implicit $lr8, implicit $rm
+  ; AIX32-LABEL: name: test2
+  ; AIX32: bb.0.entry:
+  ; AIX32-NEXT:   successors: %bb.1(0x50000000), %bb.3(0x30000000)
+  ; AIX32-NEXT:   liveins: $r3, $r4
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   [[COPY:%[0-9]+]]:gprc = COPY $r4
+  ; AIX32-NEXT:   [[COPY1:%[0-9]+]]:gprc = COPY $r3
+  ; AIX32-NEXT:   [[CMPWI:%[0-9]+]]:crrc = CMPWI [[COPY]], 1
+  ; AIX32-NEXT:   BCC 12, killed [[CMPWI]], %bb.3
+  ; AIX32-NEXT:   B %bb.1
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.1.for.body.preheader:
+  ; AIX32-NEXT:   successors: %bb.2(0x80000000)
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   MTCTRloop [[COPY]], implicit-def dead $ctr
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.2.for.body:
+  ; AIX32-NEXT:   successors: %bb.2(0x7c000000), %bb.3(0x04000000)
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   [[LWZtoc:%[0-9]+]]:gprc_and_gprc_nor0 = LWZtoc @a, $r2 :: (load (s32) from got)
+  ; AIX32-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LWZtoc]] :: (volatile dereferenceable load (s32) from @a)
+  ; AIX32-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY1]]
+  ; AIX32-NEXT:   STW killed [[ADD4_]], 0, [[LWZtoc]] :: (volatile store (s32) into @a)
+  ; AIX32-NEXT:   BDNZ %bb.2, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   B %bb.3
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.3.for.end:
+  ; AIX32-NEXT:   BLR implicit $lr, implicit $rm
+  ; LE64-LABEL: name: test2
+  ; LE64: bb.0.entry:
+  ; LE64-NEXT:   successors: %bb.1(0x50000000), %bb.3(0x30000000)
+  ; LE64-NEXT:   liveins: $x3, $x4
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   [[COPY:%[0-9]+]]:g8rc = COPY $x4
+  ; LE64-NEXT:   [[COPY1:%[0-9]+]]:g8rc = COPY $x3
+  ; LE64-NEXT:   [[COPY2:%[0-9]+]]:gprc = COPY [[COPY1]].sub_32
+  ; LE64-NEXT:   [[COPY3:%[0-9]+]]:gprc_and_gprc_nor0 = COPY [[COPY]].sub_32
+  ; LE64-NEXT:   [[CMPWI:%[0-9]+]]:crrc = CMPWI [[COPY3]], 1
+  ; LE64-NEXT:   BCC 12, killed [[CMPWI]], %bb.3
+  ; LE64-NEXT:   B %bb.1
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.1.for.body.preheader:
+  ; LE64-NEXT:   successors: %bb.2(0x80000000)
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   [[ADDI:%[0-9]+]]:gprc = ADDI [[COPY3]], -1
+  ; LE64-NEXT:   [[DEF:%[0-9]+]]:g8rc = IMPLICIT_DEF
+  ; LE64-NEXT:   [[INSERT_SUBREG:%[0-9]+]]:g8rc = INSERT_SUBREG [[DEF]], killed [[ADDI]], %subreg.sub_32
+  ; LE64-NEXT:   [[RLDICL:%[0-9]+]]:g8rc_and_g8rc_nox0 = RLDICL killed [[INSERT_SUBREG]], 0, 32
+  ; LE64-NEXT:   [[ADDI8_:%[0-9]+]]:g8rc = nuw nsw ADDI8 killed [[RLDICL]], 1
+  ; LE64-NEXT:   MTCTR8loop killed [[ADDI8_]], implicit-def dead $ctr8
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.2.for.body:
+  ; LE64-NEXT:   successors: %bb.2(0x7c000000), %bb.3(0x04000000)
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   [[ADDIStocHA8_:%[0-9]+]]:g8rc_and_g8rc_nox0 = ADDIStocHA8 $x2, @a
+  ; LE64-NEXT:   [[LDtocL:%[0-9]+]]:g8rc_and_g8rc_nox0 = LDtocL @a, killed [[ADDIStocHA8_]] :: (load (s64) from got)
+  ; LE64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtocL]] :: (volatile dereferenceable load (s32) from @a)
+  ; LE64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY2]]
+  ; LE64-NEXT:   STW killed [[ADD4_]], 0, [[LDtocL]] :: (volatile store (s32) into @a)
+  ; LE64-NEXT:   BDNZ8 %bb.2, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   B %bb.3
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.3.for.end:
+  ; LE64-NEXT:   BLR8 implicit $lr8, implicit $rm
+entry:
+  %cmp1 = icmp sgt i32 %d, 0
+  br i1 %cmp1, label %for.body, label %for.end
+
+for.body:                                         ; preds = %entry, %for.body
+  %i.02 = phi i32 [ %inc, %for.body ], [ 0, %entry ]
+  %0 = load volatile i32, i32* @a, align 4
+  %add = add nsw i32 %0, %c
+  store volatile i32 %add, i32* @a, align 4
+  %inc = add nsw i32 %i.02, 1
+  %exitcond = icmp eq i32 %inc, %d
+  br i1 %exitcond, label %for.end, label %for.body
+
+for.end:                                          ; preds = %for.body, %entry
+  ret void
+}
+
+define void @test3(i32 %c, i32 %d) nounwind {
+  ; AIX64-LABEL: name: test3
+  ; AIX64: bb.0.entry:
+  ; AIX64-NEXT:   successors: %bb.1(0x50000000), %bb.3(0x30000000)
+  ; AIX64-NEXT:   liveins: $x3, $x4
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   [[COPY:%[0-9]+]]:g8rc = COPY $x4
+  ; AIX64-NEXT:   [[COPY1:%[0-9]+]]:g8rc = COPY $x3
+  ; AIX64-NEXT:   [[COPY2:%[0-9]+]]:gprc = COPY [[COPY1]].sub_32
+  ; AIX64-NEXT:   [[COPY3:%[0-9]+]]:gprc_and_gprc_nor0 = COPY [[COPY]].sub_32
+  ; AIX64-NEXT:   [[CMPWI:%[0-9]+]]:crrc = CMPWI [[COPY3]], 1
+  ; AIX64-NEXT:   BCC 12, killed [[CMPWI]], %bb.3
+  ; AIX64-NEXT:   B %bb.1
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.1.for.body.preheader:
+  ; AIX64-NEXT:   successors: %bb.2(0x80000000)
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   [[ADDI:%[0-9]+]]:gprc = ADDI [[COPY3]], -1
+  ; AIX64-NEXT:   [[DEF:%[0-9]+]]:g8rc = IMPLICIT_DEF
+  ; AIX64-NEXT:   [[INSERT_SUBREG:%[0-9]+]]:g8rc = INSERT_SUBREG [[DEF]], killed [[ADDI]], %subreg.sub_32
+  ; AIX64-NEXT:   [[RLDICL:%[0-9]+]]:g8rc_and_g8rc_nox0 = RLDICL killed [[INSERT_SUBREG]], 0, 32
+  ; AIX64-NEXT:   [[ADDI8_:%[0-9]+]]:g8rc = nuw nsw ADDI8 killed [[RLDICL]], 1
+  ; AIX64-NEXT:   MTCTR8loop killed [[ADDI8_]], implicit-def dead $ctr8
+  ; AIX64-NEXT:   [[LI:%[0-9]+]]:gprc = LI 0
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.2.for.body:
+  ; AIX64-NEXT:   successors: %bb.2(0x7c000000), %bb.3(0x04000000)
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   [[PHI:%[0-9]+]]:gprc = PHI [[LI]], %bb.1, %1, %bb.2
+  ; AIX64-NEXT:   [[LDtoc:%[0-9]+]]:g8rc_and_g8rc_nox0 = LDtoc @a, $x2 :: (load (s64) from got)
+  ; AIX64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtoc]] :: (volatile dereferenceable load (s32) from @a)
+  ; AIX64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = ADD4 [[PHI]], killed [[LWZ]]
+  ; AIX64-NEXT:   STW killed [[ADD4_]], 0, [[LDtoc]] :: (volatile store (s32) into @a)
+  ; AIX64-NEXT:   [[ADD4_1:%[0-9]+]]:gprc = ADD4 [[PHI]], [[COPY2]]
+  ; AIX64-NEXT:   BDNZ8 %bb.2, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   B %bb.3
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.3.for.end:
+  ; AIX64-NEXT:   BLR8 implicit $lr8, implicit $rm
+  ; AIX32-LABEL: name: test3
+  ; AIX32: bb.0.entry:
+  ; AIX32-NEXT:   successors: %bb.1(0x50000000), %bb.3(0x30000000)
+  ; AIX32-NEXT:   liveins: $r3, $r4
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   [[COPY:%[0-9]+]]:gprc = COPY $r4
+  ; AIX32-NEXT:   [[COPY1:%[0-9]+]]:gprc = COPY $r3
+  ; AIX32-NEXT:   [[CMPWI:%[0-9]+]]:crrc = CMPWI [[COPY]], 1
+  ; AIX32-NEXT:   BCC 12, killed [[CMPWI]], %bb.3
+  ; AIX32-NEXT:   B %bb.1
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.1.for.body.preheader:
+  ; AIX32-NEXT:   successors: %bb.2(0x80000000)
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   MTCTRloop [[COPY]], implicit-def dead $ctr
+  ; AIX32-NEXT:   [[LI:%[0-9]+]]:gprc = LI 0
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.2.for.body:
+  ; AIX32-NEXT:   successors: %bb.2(0x7c000000), %bb.3(0x04000000)
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   [[PHI:%[0-9]+]]:gprc = PHI [[LI]], %bb.1, %1, %bb.2
+  ; AIX32-NEXT:   [[LWZtoc:%[0-9]+]]:gprc_and_gprc_nor0 = LWZtoc @a, $r2 :: (load (s32) from got)
+  ; AIX32-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LWZtoc]] :: (volatile dereferenceable load (s32) from @a)
+  ; AIX32-NEXT:   [[ADD4_:%[0-9]+]]:gprc = ADD4 [[PHI]], killed [[LWZ]]
+  ; AIX32-NEXT:   STW killed [[ADD4_]], 0, [[LWZtoc]] :: (volatile store (s32) into @a)
+  ; AIX32-NEXT:   [[ADD4_1:%[0-9]+]]:gprc = ADD4 [[PHI]], [[COPY1]]
+  ; AIX32-NEXT:   BDNZ %bb.2, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   B %bb.3
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.3.for.end:
+  ; AIX32-NEXT:   BLR implicit $lr, implicit $rm
+  ; LE64-LABEL: name: test3
+  ; LE64: bb.0.entry:
+  ; LE64-NEXT:   successors: %bb.1(0x50000000), %bb.3(0x30000000)
+  ; LE64-NEXT:   liveins: $x3, $x4
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   [[COPY:%[0-9]+]]:g8rc = COPY $x4
+  ; LE64-NEXT:   [[COPY1:%[0-9]+]]:g8rc = COPY $x3
+  ; LE64-NEXT:   [[COPY2:%[0-9]+]]:gprc = COPY [[COPY1]].sub_32
+  ; LE64-NEXT:   [[COPY3:%[0-9]+]]:gprc_and_gprc_nor0 = COPY [[COPY]].sub_32
+  ; LE64-NEXT:   [[CMPWI:%[0-9]+]]:crrc = CMPWI [[COPY3]], 1
+  ; LE64-NEXT:   BCC 12, killed [[CMPWI]], %bb.3
+  ; LE64-NEXT:   B %bb.1
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.1.for.body.preheader:
+  ; LE64-NEXT:   successors: %bb.2(0x80000000)
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   [[ADDI:%[0-9]+]]:gprc = ADDI [[COPY3]], -1
+  ; LE64-NEXT:   [[DEF:%[0-9]+]]:g8rc = IMPLICIT_DEF
+  ; LE64-NEXT:   [[INSERT_SUBREG:%[0-9]+]]:g8rc = INSERT_SUBREG [[DEF]], killed [[ADDI]], %subreg.sub_32
+  ; LE64-NEXT:   [[RLDICL:%[0-9]+]]:g8rc_and_g8rc_nox0 = RLDICL killed [[INSERT_SUBREG]], 0, 32
+  ; LE64-NEXT:   [[ADDI8_:%[0-9]+]]:g8rc = nuw nsw ADDI8 killed [[RLDICL]], 1
+  ; LE64-NEXT:   MTCTR8loop killed [[ADDI8_]], implicit-def dead $ctr8
+  ; LE64-NEXT:   [[LI:%[0-9]+]]:gprc = LI 0
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.2.for.body:
+  ; LE64-NEXT:   successors: %bb.2(0x7c000000), %bb.3(0x04000000)
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   [[PHI:%[0-9]+]]:gprc = PHI [[LI]], %bb.1, %1, %bb.2
+  ; LE64-NEXT:   [[ADDIStocHA8_:%[0-9]+]]:g8rc_and_g8rc_nox0 = ADDIStocHA8 $x2, @a
+  ; LE64-NEXT:   [[LDtocL:%[0-9]+]]:g8rc_and_g8rc_nox0 = LDtocL @a, killed [[ADDIStocHA8_]] :: (load (s64) from got)
+  ; LE64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtocL]] :: (volatile dereferenceable load (s32) from @a)
+  ; LE64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = ADD4 [[PHI]], killed [[LWZ]]
+  ; LE64-NEXT:   STW killed [[ADD4_]], 0, [[LDtocL]] :: (volatile store (s32) into @a)
+  ; LE64-NEXT:   [[ADD4_1:%[0-9]+]]:gprc = ADD4 [[PHI]], [[COPY2]]
+  ; LE64-NEXT:   BDNZ8 %bb.2, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   B %bb.3
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.3.for.end:
+  ; LE64-NEXT:   BLR8 implicit $lr8, implicit $rm
+entry:
+  %cmp1 = icmp sgt i32 %d, 0
+  br i1 %cmp1, label %for.body, label %for.end
+
+for.body:                                         ; preds = %entry, %for.body
+  %i.02 = phi i32 [ %inc, %for.body ], [ 0, %entry ]
+  %mul = mul nsw i32 %i.02, %c
+  %0 = load volatile i32, i32* @a, align 4
+  %add = add nsw i32 %0, %mul
+  store volatile i32 %add, i32* @a, align 4
+  %inc = add nsw i32 %i.02, 1
+  %exitcond = icmp eq i32 %inc, %d
+  br i1 %exitcond, label %for.end, label %for.body
+
+for.end:                                          ; preds = %for.body, %entry
+  ret void
+}
+
+@tls_var = external thread_local global i8
+
+define i32 @test4(i32 %inp) {
+  ; AIX64-LABEL: name: test4
+  ; AIX64: bb.0.entry:
+  ; AIX64-NEXT:   successors: %bb.1(0x80000000)
+  ; AIX64-NEXT:   liveins: $x3
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   [[COPY:%[0-9]+]]:g8rc = COPY $x3
+  ; AIX64-NEXT:   [[COPY1:%[0-9]+]]:gprc_and_gprc_nor0 = COPY [[COPY]].sub_32
+  ; AIX64-NEXT:   [[CMPWI:%[0-9]+]]:crrc = CMPWI [[COPY1]], 1
+  ; AIX64-NEXT:   [[LI:%[0-9]+]]:gprc_and_gprc_nor0 = LI 1
+  ; AIX64-NEXT:   [[ISEL:%[0-9]+]]:gprc = ISEL [[COPY1]], [[LI]], [[CMPWI]].sub_lt
+  ; AIX64-NEXT:   [[SUBF:%[0-9]+]]:gprc = SUBF [[ISEL]], [[COPY1]]
+  ; AIX64-NEXT:   [[DEF:%[0-9]+]]:g8rc = IMPLICIT_DEF
+  ; AIX64-NEXT:   [[INSERT_SUBREG:%[0-9]+]]:g8rc = INSERT_SUBREG [[DEF]], killed [[SUBF]], %subreg.sub_32
+  ; AIX64-NEXT:   [[RLDICL:%[0-9]+]]:g8rc_and_g8rc_nox0 = RLDICL killed [[INSERT_SUBREG]], 0, 32
+  ; AIX64-NEXT:   [[ADDI8_:%[0-9]+]]:g8rc = nuw nsw ADDI8 killed [[RLDICL]], 1
+  ; AIX64-NEXT:   MTCTR8loop killed [[ADDI8_]], implicit-def dead $ctr8
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.1.for.body:
+  ; AIX64-NEXT:   successors: %bb.1(0x7c000000), %bb.2(0x04000000)
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT:   BDNZ8 %bb.1, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   B %bb.2
+  ; AIX64-NEXT: {{  $}}
+  ; AIX64-NEXT: bb.2.return:
+  ; AIX64-NEXT:   [[LDtoc:%[0-9]+]]:g8rc = LDtoc target-flags(ppc-lo) @tls_var, $x2 :: (load (s64) from got)
+  ; AIX64-NEXT:   [[LDtoc1:%[0-9]+]]:g8rc = LDtoc target-flags(ppc-tlsgd) @tls_var, $x2 :: (load (s64) from got)
+  ; AIX64-NEXT:   [[TLSGDAIX8_:%[0-9]+]]:g8rc = TLSGDAIX8 killed [[LDtoc1]], killed [[LDtoc]]
+  ; AIX64-NEXT:   [[COPY2:%[0-9]+]]:gprc = COPY [[TLSGDAIX8_]].sub_32
+  ; AIX64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = ADD4 killed [[COPY2]], [[ISEL]]
+  ; AIX64-NEXT:   [[DEF1:%[0-9]+]]:g8rc = IMPLICIT_DEF
+  ; AIX64-NEXT:   [[INSERT_SUBREG1:%[0-9]+]]:g8rc = INSERT_SUBREG [[DEF1]], killed [[ADD4_]], %subreg.sub_32
+  ; AIX64-NEXT:   $x3 = COPY [[INSERT_SUBREG1]]
+  ; AIX64-NEXT:   BLR8 implicit $lr8, implicit $rm, implicit $x3
+  ; AIX32-LABEL: name: test4
+  ; AIX32: bb.0.entry:
+  ; AIX32-NEXT:   successors: %bb.1(0x80000000)
+  ; AIX32-NEXT:   liveins: $r3
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   [[COPY:%[0-9]+]]:gprc_and_gprc_nor0 = COPY $r3
+  ; AIX32-NEXT:   [[CMPWI:%[0-9]+]]:crrc = CMPWI [[COPY]], 1
+  ; AIX32-NEXT:   [[LI:%[0-9]+]]:gprc_and_gprc_nor0 = LI 1
+  ; AIX32-NEXT:   [[ISEL:%[0-9]+]]:gprc = ISEL [[COPY]], [[LI]], [[CMPWI]].sub_lt
+  ; AIX32-NEXT:   [[SUBF:%[0-9]+]]:gprc_and_gprc_nor0 = SUBF [[ISEL]], [[COPY]]
+  ; AIX32-NEXT:   [[ADDI:%[0-9]+]]:gprc = ADDI killed [[SUBF]], 1
+  ; AIX32-NEXT:   MTCTRloop killed [[ADDI]], implicit-def dead $ctr
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.1.for.body:
+  ; AIX32-NEXT:   successors: %bb.1(0x7c000000), %bb.2(0x04000000)
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT:   BDNZ %bb.1, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   B %bb.2
+  ; AIX32-NEXT: {{  $}}
+  ; AIX32-NEXT: bb.2.return:
+  ; AIX32-NEXT:   [[LWZtoc:%[0-9]+]]:gprc = LWZtoc target-flags(ppc-lo) @tls_var, $r2 :: (load (s32) from got)
+  ; AIX32-NEXT:   [[LWZtoc1:%[0-9]+]]:gprc = LWZtoc target-flags(ppc-tlsgd) @tls_var, $r2 :: (load (s32) from got)
+  ; AIX32-NEXT:   [[TLSGDAIX:%[0-9]+]]:gprc = TLSGDAIX killed [[LWZtoc1]], killed [[LWZtoc]]
+  ; AIX32-NEXT:   [[ADD4_:%[0-9]+]]:gprc = ADD4 killed [[TLSGDAIX]], [[ISEL]]
+  ; AIX32-NEXT:   $r3 = COPY [[ADD4_]]
+  ; AIX32-NEXT:   BLR implicit $lr, implicit $rm, implicit $r3
+  ; LE64-LABEL: name: test4
+  ; LE64: bb.0.entry:
+  ; LE64-NEXT:   successors: %bb.1(0x80000000)
+  ; LE64-NEXT:   liveins: $x3
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   [[COPY:%[0-9]+]]:g8rc = COPY $x3
+  ; LE64-NEXT:   [[COPY1:%[0-9]+]]:gprc_and_gprc_nor0 = COPY [[COPY]].sub_32
+  ; LE64-NEXT:   [[CMPWI:%[0-9]+]]:crrc = CMPWI [[COPY1]], 1
+  ; LE64-NEXT:   [[LI:%[0-9]+]]:gprc_and_gprc_nor0 = LI 1
+  ; LE64-NEXT:   [[ISEL:%[0-9]+]]:gprc = ISEL [[COPY1]], [[LI]], [[CMPWI]].sub_lt
+  ; LE64-NEXT:   [[SUBF:%[0-9]+]]:gprc = SUBF [[ISEL]], [[COPY1]]
+  ; LE64-NEXT:   [[DEF:%[0-9]+]]:g8rc = IMPLICIT_DEF
+  ; LE64-NEXT:   [[INSERT_SUBREG:%[0-9]+]]:g8rc = INSERT_SUBREG [[DEF]], killed [[SUBF]], %subreg.sub_32
+  ; LE64-NEXT:   [[RLDICL:%[0-9]+]]:g8rc_and_g8rc_nox0 = RLDICL killed [[INSERT_SUBREG]], 0, 32
+  ; LE64-NEXT:   [[ADDI8_:%[0-9]+]]:g8rc = nuw nsw ADDI8 killed [[RLDICL]], 1
+  ; LE64-NEXT:   MTCTR8loop killed [[ADDI8_]], implicit-def dead $ctr8
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.1.for.body:
+  ; LE64-NEXT:   successors: %bb.1(0x7c000000), %bb.2(0x04000000)
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT:   BDNZ8 %bb.1, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   B %bb.2
+  ; LE64-NEXT: {{  $}}
+  ; LE64-NEXT: bb.2.return:
+  ; LE64-NEXT:   [[ADDISgotTprelHA:%[0-9]+]]:g8rc_and_g8rc_nox0 = ADDISgotTprelHA $x2, @tls_var
+  ; LE64-NEXT:   [[LDgotTprelL:%[0-9]+]]:g8rc_and_g8rc_nox0 = LDgotTprelL @tls_var, killed [[ADDISgotTprelHA]]
+  ; LE64-NEXT:   [[ADD8TLS:%[0-9]+]]:g8rc = ADD8TLS killed [[LDgotTprelL]], target-flags(ppc-tls) @tls_var
+  ; LE64-NEXT:   [[COPY2:%[0-9]+]]:gprc = COPY [[ADD8TLS]].sub_32
+  ; LE64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = ADD4 killed [[COPY2]], [[ISEL]]
+  ; LE64-NEXT:   [[DEF1:%[0-9]+]]:g8rc = IMPLICIT_DEF
+  ; LE64-NEXT:   [[INSERT_SUBREG1:%[0-9]+]]:g8rc = INSERT_SUBREG [[DEF1]], killed [[ADD4_]], %subreg.sub_32
+  ; LE64-NEXT:   $x3 = COPY [[INSERT_SUBREG1]]
+  ; LE64-NEXT:   BLR8 implicit $lr8, implicit $rm, implicit $x3
+entry:
+  br label %for.body
+
+for.body:                                         ; preds = %for.body, %entry
+  %phi = phi i32 [ %dec, %for.body ], [ %inp, %entry ]
+  %load = ptrtoint i8* @tls_var to i32
+  %val = add i32 %load, %phi
+  %dec = add i32 %phi, -1
+  %cmp = icmp sgt i32 %phi, 1
+  br i1 %cmp, label %for.body, label %return
+
+return:                                           ; preds = %for.body
+  ret i32 %val
+}

From e31bbef2536cc110e073a91f7829f506c77670f2 Mon Sep 17 00:00:00 2001
From: Chen Zheng <czhengsz@cn.ibm.com>
Date: Fri, 8 Apr 2022 03:24:46 -0400
Subject: [PATCH 69/84] [PowerPC] mapping hardward loop intrinsics to powerpc
 pseudo

Map hardware loop intrinsics loop_decrement and set_loop_iteration
to the new PowerPC pseudo instructions, so that the hardware loop
intrinsics will be expanded to normal cmp+branch form or ctrloop
form based on the CTR register usage on MIR level.

Reviewed By: lkail

Differential Revision: https://reviews.llvm.org/D123366

(cherry picked from commit d9004dfbabc62887f09775297436792077ce4496)
---
 llvm/lib/Target/PowerPC/PPCCTRLoops.cpp      | 31 ++++-----
 llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp  | 56 ++++++++++++++++
 llvm/lib/Target/PowerPC/PPCISelLowering.cpp  | 50 --------------
 llvm/lib/Target/PowerPC/PPCInstr64Bit.td     | 10 +--
 llvm/lib/Target/PowerPC/PPCInstrInfo.td      |  9 +--
 llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll | 36 ++++++----
 llvm/test/CodeGen/PowerPC/ctrloops32.mir     | 70 ++++++++++----------
 llvm/test/CodeGen/PowerPC/ctrloops64.mir     | 70 ++++++++++----------
 llvm/test/CodeGen/PowerPC/sms-phi.ll         |  8 +--
 9 files changed, 172 insertions(+), 168 deletions(-)

diff --git a/llvm/lib/Target/PowerPC/PPCCTRLoops.cpp b/llvm/lib/Target/PowerPC/PPCCTRLoops.cpp
index 48167c3dc9ca87..cb0519c8fe7bb9 100644
--- a/llvm/lib/Target/PowerPC/PPCCTRLoops.cpp
+++ b/llvm/lib/Target/PowerPC/PPCCTRLoops.cpp
@@ -7,21 +7,21 @@
 //===----------------------------------------------------------------------===//
 //
 // This pass generates machine instructions for the CTR loops related pseudos:
-// 1: MTCTRPseudo/DecreaseCTRPseudo
-// 2: MTCTR8Pseudo/DecreaseCTR8Pseudo
+// 1: MTCTRloop/DecreaseCTRloop
+// 2: MTCTR8loop/DecreaseCTR8loop
 //
 // If a CTR loop can be generated:
-// 1: MTCTRPseudo/MTCTR8Pseudo will be converted to "mtctr"
-// 2: DecreaseCTRPseudo/DecreaseCTR8Pseudo will be converted to "bdnz/bdz" and
+// 1: MTCTRloop/MTCTR8loop will be converted to "mtctr"
+// 2: DecreaseCTRloop/DecreaseCTR8loop will be converted to "bdnz/bdz" and
 //    its user branch instruction can be deleted.
 //
 // If a CTR loop can not be generated due to clobber of CTR:
-// 1: MTCTRPseudo/MTCTR8Pseudo can be deleted.
-// 2: DecreaseCTRPseudo/DecreaseCTR8Pseudo will be converted to "addi -1" and
+// 1: MTCTRloop/MTCTR8loop can be deleted.
+// 2: DecreaseCTRloop/DecreaseCTR8loop will be converted to "addi -1" and
 //    a "cmplwi/cmpldi".
 //
 // This pass runs just before register allocation, because we don't want
-// register allocator to allocate register for DecreaseCTRPseudo if a CTR can be
+// register allocator to allocate register for DecreaseCTRloop if a CTR can be
 // generated or if a CTR loop can not be generated, we don't have any condition
 // register for the new added "cmplwi/cmpldi".
 //
@@ -148,8 +148,8 @@ bool PPCCTRLoops::processLoop(MachineLoop *ML) {
     return true;
 
   auto IsLoopStart = [](MachineInstr &MI) {
-    return MI.getOpcode() == PPC::MTCTRPseudo ||
-           MI.getOpcode() == PPC::MTCTR8Pseudo;
+    return MI.getOpcode() == PPC::MTCTRloop ||
+           MI.getOpcode() == PPC::MTCTR8loop;
   };
 
   auto SearchForStart =
@@ -166,7 +166,7 @@ bool PPCCTRLoops::processLoop(MachineLoop *ML) {
   bool InvalidCTRLoop = false;
 
   MachineBasicBlock *Preheader = ML->getLoopPreheader();
-  // If there is no preheader for this loop, there must be no MTCTRPseudo
+  // If there is no preheader for this loop, there must be no MTCTRloop
   // either.
   if (!Preheader)
     return false;
@@ -205,8 +205,8 @@ bool PPCCTRLoops::processLoop(MachineLoop *ML) {
   // normal loop.
   for (auto *MBB : reverse(ML->getBlocks())) {
     for (auto &MI : *MBB) {
-      if (MI.getOpcode() == PPC::DecreaseCTRPseudo ||
-          MI.getOpcode() == PPC::DecreaseCTR8Pseudo)
+      if (MI.getOpcode() == PPC::DecreaseCTRloop ||
+          MI.getOpcode() == PPC::DecreaseCTR8loop)
         Dec = &MI;
       else if (!InvalidCTRLoop)
         // If any instruction clobber CTR, then we can not generate a CTR loop.
@@ -341,18 +341,11 @@ void PPCCTRLoops::expandCTRLoops(MachineLoop *ML, MachineInstr *Start,
     llvm_unreachable("Unhandled branch user for DecreaseCTRloop.");
   }
 
-  unsigned MTCTROpcode = Is64Bit ? PPC::MTCTR8 : PPC::MTCTR;
-
-  // Generate "mtctr" in the loop preheader.
-  BuildMI(*Preheader, Start, Start->getDebugLoc(), TII->get(MTCTROpcode))
-      .addReg(Start->getOperand(0).getReg());
-
   // Generate "bdnz/bdz" in the exiting block just before the terminator.
   BuildMI(*Exiting, &*BrInstr, BrInstr->getDebugLoc(), TII->get(Opcode))
       .addMBB(BrInstr->getOperand(1).getMBB());
 
   // Remove the pseudo instructions.
-  Start->eraseFromParent();
   BrInstr->eraseFromParent();
   Dec->eraseFromParent();
 }
diff --git a/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp b/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp
index 14c4fd3a9ffadb..cdab2184b33c95 100644
--- a/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp
+++ b/llvm/lib/Target/PowerPC/PPCISelDAGToDAG.cpp
@@ -417,6 +417,7 @@ namespace {
 private:
     bool trySETCC(SDNode *N);
     bool tryFoldSWTestBRCC(SDNode *N);
+    bool trySelectLoopCountIntrinsic(SDNode *N);
     bool tryAsSingleRLDICL(SDNode *N);
     bool tryAsSingleRLDICR(SDNode *N);
     bool tryAsSingleRLWINM(SDNode *N);
@@ -4718,6 +4719,59 @@ bool PPCDAGToDAGISel::tryFoldSWTestBRCC(SDNode *N) {
   return false;
 }
 
+bool PPCDAGToDAGISel::trySelectLoopCountIntrinsic(SDNode *N) {
+  // Sometimes the promoted value of the intrinsic is ANDed by some non-zero
+  // value, for example when crbits is disabled. If so, select the
+  // loop_decrement intrinsics now.
+  ISD::CondCode CC = cast<CondCodeSDNode>(N->getOperand(1))->get();
+  SDValue LHS = N->getOperand(2), RHS = N->getOperand(3);
+
+  if (LHS.getOpcode() != ISD::AND || !isa<ConstantSDNode>(LHS.getOperand(1)) ||
+      isNullConstant(LHS.getOperand(1)))
+    return false;
+
+  if (LHS.getOperand(0).getOpcode() != ISD::INTRINSIC_W_CHAIN ||
+      cast<ConstantSDNode>(LHS.getOperand(0).getOperand(1))->getZExtValue() !=
+          Intrinsic::loop_decrement)
+    return false;
+
+  if (!isa<ConstantSDNode>(RHS))
+    return false;
+
+  assert((CC == ISD::SETEQ || CC == ISD::SETNE) &&
+         "Counter decrement comparison is not EQ or NE");
+
+  SDValue OldDecrement = LHS.getOperand(0);
+  assert(OldDecrement.hasOneUse() && "loop decrement has more than one use!");
+
+  SDLoc DecrementLoc(OldDecrement);
+  SDValue ChainInput = OldDecrement.getOperand(0);
+  SDValue DecrementOps[] = {Subtarget->isPPC64() ? getI64Imm(1, DecrementLoc)
+                                                 : getI32Imm(1, DecrementLoc)};
+  unsigned DecrementOpcode =
+      Subtarget->isPPC64() ? PPC::DecreaseCTR8loop : PPC::DecreaseCTRloop;
+  SDNode *NewDecrement = CurDAG->getMachineNode(DecrementOpcode, DecrementLoc,
+                                                MVT::i1, DecrementOps);
+
+  unsigned Val = cast<ConstantSDNode>(RHS)->getZExtValue();
+  bool IsBranchOnTrue = (CC == ISD::SETEQ && Val) || (CC == ISD::SETNE && !Val);
+  unsigned Opcode = IsBranchOnTrue ? PPC::BC : PPC::BCn;
+
+  ReplaceUses(LHS.getValue(0), LHS.getOperand(1));
+  CurDAG->RemoveDeadNode(LHS.getNode());
+
+  // Mark the old loop_decrement intrinsic as dead.
+  ReplaceUses(OldDecrement.getValue(1), ChainInput);
+  CurDAG->RemoveDeadNode(OldDecrement.getNode());
+
+  SDValue Chain = CurDAG->getNode(ISD::TokenFactor, SDLoc(N), MVT::Other,
+                                  ChainInput, N->getOperand(0));
+
+  CurDAG->SelectNodeTo(N, Opcode, MVT::Other, SDValue(NewDecrement, 0),
+                       N->getOperand(4), Chain);
+  return true;
+}
+
 bool PPCDAGToDAGISel::tryAsSingleRLWINM(SDNode *N) {
   assert(N->getOpcode() == ISD::AND && "ISD::AND SDNode expected");
   unsigned Imm;
@@ -5739,6 +5793,8 @@ void PPCDAGToDAGISel::Select(SDNode *N) {
   case ISD::BR_CC: {
     if (tryFoldSWTestBRCC(N))
       return;
+    if (trySelectLoopCountIntrinsic(N))
+      return;
     ISD::CondCode CC = cast<CondCodeSDNode>(N->getOperand(1))->get();
     unsigned PCC =
         getPredicateForSetCC(CC, N->getOperand(2).getValueType(), Subtarget);
diff --git a/llvm/lib/Target/PowerPC/PPCISelLowering.cpp b/llvm/lib/Target/PowerPC/PPCISelLowering.cpp
index 3c461a627d61c2..086fbbe82ed3ef 100644
--- a/llvm/lib/Target/PowerPC/PPCISelLowering.cpp
+++ b/llvm/lib/Target/PowerPC/PPCISelLowering.cpp
@@ -15719,25 +15719,6 @@ SDValue PPCTargetLowering::PerformDAGCombine(SDNode *N,
         return SDValue(VCMPrecNode, 0);
     }
     break;
-  case ISD::BRCOND: {
-    SDValue Cond = N->getOperand(1);
-    SDValue Target = N->getOperand(2);
-
-    if (Cond.getOpcode() == ISD::INTRINSIC_W_CHAIN &&
-        cast<ConstantSDNode>(Cond.getOperand(1))->getZExtValue() ==
-          Intrinsic::loop_decrement) {
-
-      // We now need to make the intrinsic dead (it cannot be instruction
-      // selected).
-      DAG.ReplaceAllUsesOfValueWith(Cond.getValue(1), Cond.getOperand(0));
-      assert(Cond.getNode()->hasOneUse() &&
-             "Counter decrement has more than one use");
-
-      return DAG.getNode(PPCISD::BDNZ, dl, MVT::Other,
-                         N->getOperand(0), Target);
-    }
-  }
-  break;
   case ISD::BR_CC: {
     // If this is a branch on an altivec predicate comparison, lower this so
     // that we don't have to do a MFOCRF: instead, branch directly on CR6.  This
@@ -15746,37 +15727,6 @@ SDValue PPCTargetLowering::PerformDAGCombine(SDNode *N,
     ISD::CondCode CC = cast<CondCodeSDNode>(N->getOperand(1))->get();
     SDValue LHS = N->getOperand(2), RHS = N->getOperand(3);
 
-    // Sometimes the promoted value of the intrinsic is ANDed by some non-zero
-    // value. If so, pass-through the AND to get to the intrinsic.
-    if (LHS.getOpcode() == ISD::AND &&
-        LHS.getOperand(0).getOpcode() == ISD::INTRINSIC_W_CHAIN &&
-        cast<ConstantSDNode>(LHS.getOperand(0).getOperand(1))->getZExtValue() ==
-          Intrinsic::loop_decrement &&
-        isa<ConstantSDNode>(LHS.getOperand(1)) &&
-        !isNullConstant(LHS.getOperand(1)))
-      LHS = LHS.getOperand(0);
-
-    if (LHS.getOpcode() == ISD::INTRINSIC_W_CHAIN &&
-        cast<ConstantSDNode>(LHS.getOperand(1))->getZExtValue() ==
-          Intrinsic::loop_decrement &&
-        isa<ConstantSDNode>(RHS)) {
-      assert((CC == ISD::SETEQ || CC == ISD::SETNE) &&
-             "Counter decrement comparison is not EQ or NE");
-
-      unsigned Val = cast<ConstantSDNode>(RHS)->getZExtValue();
-      bool isBDNZ = (CC == ISD::SETEQ && Val) ||
-                    (CC == ISD::SETNE && !Val);
-
-      // We now need to make the intrinsic dead (it cannot be instruction
-      // selected).
-      DAG.ReplaceAllUsesOfValueWith(LHS.getValue(1), LHS.getOperand(0));
-      assert(LHS.getNode()->hasOneUse() &&
-             "Counter decrement has more than one use");
-
-      return DAG.getNode(isBDNZ ? PPCISD::BDNZ : PPCISD::BDZ, dl, MVT::Other,
-                         N->getOperand(0), N->getOperand(4));
-    }
-
     int CompareOpc;
     bool isDot;
 
diff --git a/llvm/lib/Target/PowerPC/PPCInstr64Bit.td b/llvm/lib/Target/PowerPC/PPCInstr64Bit.td
index dbe7a7805c617e..7d648b1429beeb 100644
--- a/llvm/lib/Target/PowerPC/PPCInstr64Bit.td
+++ b/llvm/lib/Target/PowerPC/PPCInstr64Bit.td
@@ -580,13 +580,9 @@ def MTCTR8loop : XFXForm_7_ext<31, 467, 9, (outs), (ins g8rc:$rS),
                  PPC970_DGroup_First, PPC970_Unit_FXU;
 }
 
-
-let hasSideEffects = 1, Defs = [CTR8] in
-def MTCTR8Pseudo : PPCEmitTimePseudo<(outs), (ins g8rc:$rS), "#MTCTR8Pseudo", []>;
-
-let hasSideEffects = 1, Uses = [CTR8], Defs = [CTR8] in
-def DecreaseCTR8Pseudo : PPCEmitTimePseudo<(outs crbitrc:$rT), (ins i64imm:$stride),
-                                          "#DecreaseCTR8Pseudo", []>;
+let hasSideEffects = 1, hasNoSchedulingInfo = 1, Uses = [CTR8], Defs = [CTR8] in
+def DecreaseCTR8loop : PPCEmitTimePseudo<(outs crbitrc:$rT), (ins i64imm:$stride),
+                                        "#DecreaseCTR8loop", [(set i1:$rT, (int_loop_decrement (i64 imm:$stride)))]>;
 
 let Pattern = [(set i64:$rT, readcyclecounter)] in
 def MFTB8 : XFXForm_1_ext<31, 339, 268, (outs g8rc:$rT), (ins),
diff --git a/llvm/lib/Target/PowerPC/PPCInstrInfo.td b/llvm/lib/Target/PowerPC/PPCInstrInfo.td
index f651b51d26845f..046d3b24541cb8 100644
--- a/llvm/lib/Target/PowerPC/PPCInstrInfo.td
+++ b/llvm/lib/Target/PowerPC/PPCInstrInfo.td
@@ -2549,12 +2549,9 @@ def MTCTRloop : XFXForm_7_ext<31, 467, 9, (outs), (ins gprc:$rS),
                 PPC970_DGroup_First, PPC970_Unit_FXU;
 }
 
-let hasSideEffects = 1, Defs = [CTR] in
-def MTCTRPseudo : PPCEmitTimePseudo<(outs), (ins gprc:$rS), "#MTCTRPseudo", []>;
-
-let hasSideEffects = 1, Uses = [CTR], Defs = [CTR] in
-def DecreaseCTRPseudo : PPCEmitTimePseudo<(outs crbitrc:$rT), (ins i32imm:$stride),
-                                          "#DecreaseCTRPseudo", []>;
+let hasSideEffects = 1, hasNoSchedulingInfo = 1, Uses = [CTR], Defs = [CTR] in
+def DecreaseCTRloop : PPCEmitTimePseudo<(outs crbitrc:$rT), (ins i32imm:$stride),
+                                       "#DecreaseCTRloop", [(set i1:$rT, (int_loop_decrement (i32 imm:$stride)))]>;
 
 let hasSideEffects = 0 in {
 let Defs = [LR] in {
diff --git a/llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll b/llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll
index 39f33d9e849a01..9890830194e220 100644
--- a/llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll
+++ b/llvm/test/CodeGen/PowerPC/ctrloops-pseudo.ll
@@ -29,7 +29,8 @@ define void @test1(i32 %c) nounwind {
   ; AIX64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtoc]] :: (volatile dereferenceable load (s32) from @a)
   ; AIX64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY1]]
   ; AIX64-NEXT:   STW killed [[ADD4_]], 0, [[LDtoc]] :: (volatile store (s32) into @a)
-  ; AIX64-NEXT:   BDNZ8 %bb.1, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   [[DecreaseCTR8loop:%[0-9]+]]:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   BC killed [[DecreaseCTR8loop]], %bb.1
   ; AIX64-NEXT:   B %bb.2
   ; AIX64-NEXT: {{  $}}
   ; AIX64-NEXT: bb.2.for.end:
@@ -50,7 +51,8 @@ define void @test1(i32 %c) nounwind {
   ; AIX32-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LWZtoc]] :: (volatile dereferenceable load (s32) from @a)
   ; AIX32-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY]]
   ; AIX32-NEXT:   STW killed [[ADD4_]], 0, [[LWZtoc]] :: (volatile store (s32) into @a)
-  ; AIX32-NEXT:   BDNZ %bb.1, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   [[DecreaseCTRloop:%[0-9]+]]:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   BC killed [[DecreaseCTRloop]], %bb.1
   ; AIX32-NEXT:   B %bb.2
   ; AIX32-NEXT: {{  $}}
   ; AIX32-NEXT: bb.2.for.end:
@@ -73,7 +75,8 @@ define void @test1(i32 %c) nounwind {
   ; LE64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtocL]] :: (volatile dereferenceable load (s32) from @a)
   ; LE64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY1]]
   ; LE64-NEXT:   STW killed [[ADD4_]], 0, [[LDtocL]] :: (volatile store (s32) into @a)
-  ; LE64-NEXT:   BDNZ8 %bb.1, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   [[DecreaseCTR8loop:%[0-9]+]]:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   BC killed [[DecreaseCTR8loop]], %bb.1
   ; LE64-NEXT:   B %bb.2
   ; LE64-NEXT: {{  $}}
   ; LE64-NEXT: bb.2.for.end:
@@ -125,7 +128,8 @@ define void @test2(i32 %c, i32 %d) nounwind {
   ; AIX64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtoc]] :: (volatile dereferenceable load (s32) from @a)
   ; AIX64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY2]]
   ; AIX64-NEXT:   STW killed [[ADD4_]], 0, [[LDtoc]] :: (volatile store (s32) into @a)
-  ; AIX64-NEXT:   BDNZ8 %bb.2, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   [[DecreaseCTR8loop:%[0-9]+]]:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   BC killed [[DecreaseCTR8loop]], %bb.2
   ; AIX64-NEXT:   B %bb.3
   ; AIX64-NEXT: {{  $}}
   ; AIX64-NEXT: bb.3.for.end:
@@ -153,7 +157,8 @@ define void @test2(i32 %c, i32 %d) nounwind {
   ; AIX32-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LWZtoc]] :: (volatile dereferenceable load (s32) from @a)
   ; AIX32-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY1]]
   ; AIX32-NEXT:   STW killed [[ADD4_]], 0, [[LWZtoc]] :: (volatile store (s32) into @a)
-  ; AIX32-NEXT:   BDNZ %bb.2, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   [[DecreaseCTRloop:%[0-9]+]]:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   BC killed [[DecreaseCTRloop]], %bb.2
   ; AIX32-NEXT:   B %bb.3
   ; AIX32-NEXT: {{  $}}
   ; AIX32-NEXT: bb.3.for.end:
@@ -189,7 +194,8 @@ define void @test2(i32 %c, i32 %d) nounwind {
   ; LE64-NEXT:   [[LWZ:%[0-9]+]]:gprc = LWZ 0, [[LDtocL]] :: (volatile dereferenceable load (s32) from @a)
   ; LE64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = nsw ADD4 killed [[LWZ]], [[COPY2]]
   ; LE64-NEXT:   STW killed [[ADD4_]], 0, [[LDtocL]] :: (volatile store (s32) into @a)
-  ; LE64-NEXT:   BDNZ8 %bb.2, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   [[DecreaseCTR8loop:%[0-9]+]]:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   BC killed [[DecreaseCTR8loop]], %bb.2
   ; LE64-NEXT:   B %bb.3
   ; LE64-NEXT: {{  $}}
   ; LE64-NEXT: bb.3.for.end:
@@ -245,7 +251,8 @@ define void @test3(i32 %c, i32 %d) nounwind {
   ; AIX64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = ADD4 [[PHI]], killed [[LWZ]]
   ; AIX64-NEXT:   STW killed [[ADD4_]], 0, [[LDtoc]] :: (volatile store (s32) into @a)
   ; AIX64-NEXT:   [[ADD4_1:%[0-9]+]]:gprc = ADD4 [[PHI]], [[COPY2]]
-  ; AIX64-NEXT:   BDNZ8 %bb.2, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   [[DecreaseCTR8loop:%[0-9]+]]:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   BC killed [[DecreaseCTR8loop]], %bb.2
   ; AIX64-NEXT:   B %bb.3
   ; AIX64-NEXT: {{  $}}
   ; AIX64-NEXT: bb.3.for.end:
@@ -276,7 +283,8 @@ define void @test3(i32 %c, i32 %d) nounwind {
   ; AIX32-NEXT:   [[ADD4_:%[0-9]+]]:gprc = ADD4 [[PHI]], killed [[LWZ]]
   ; AIX32-NEXT:   STW killed [[ADD4_]], 0, [[LWZtoc]] :: (volatile store (s32) into @a)
   ; AIX32-NEXT:   [[ADD4_1:%[0-9]+]]:gprc = ADD4 [[PHI]], [[COPY1]]
-  ; AIX32-NEXT:   BDNZ %bb.2, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   [[DecreaseCTRloop:%[0-9]+]]:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   BC killed [[DecreaseCTRloop]], %bb.2
   ; AIX32-NEXT:   B %bb.3
   ; AIX32-NEXT: {{  $}}
   ; AIX32-NEXT: bb.3.for.end:
@@ -315,7 +323,8 @@ define void @test3(i32 %c, i32 %d) nounwind {
   ; LE64-NEXT:   [[ADD4_:%[0-9]+]]:gprc = ADD4 [[PHI]], killed [[LWZ]]
   ; LE64-NEXT:   STW killed [[ADD4_]], 0, [[LDtocL]] :: (volatile store (s32) into @a)
   ; LE64-NEXT:   [[ADD4_1:%[0-9]+]]:gprc = ADD4 [[PHI]], [[COPY2]]
-  ; LE64-NEXT:   BDNZ8 %bb.2, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   [[DecreaseCTR8loop:%[0-9]+]]:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   BC killed [[DecreaseCTR8loop]], %bb.2
   ; LE64-NEXT:   B %bb.3
   ; LE64-NEXT: {{  $}}
   ; LE64-NEXT: bb.3.for.end:
@@ -361,7 +370,8 @@ define i32 @test4(i32 %inp) {
   ; AIX64-NEXT: bb.1.for.body:
   ; AIX64-NEXT:   successors: %bb.1(0x7c000000), %bb.2(0x04000000)
   ; AIX64-NEXT: {{  $}}
-  ; AIX64-NEXT:   BDNZ8 %bb.1, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   [[DecreaseCTR8loop:%[0-9]+]]:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
+  ; AIX64-NEXT:   BC killed [[DecreaseCTR8loop]], %bb.1
   ; AIX64-NEXT:   B %bb.2
   ; AIX64-NEXT: {{  $}}
   ; AIX64-NEXT: bb.2.return:
@@ -390,7 +400,8 @@ define i32 @test4(i32 %inp) {
   ; AIX32-NEXT: bb.1.for.body:
   ; AIX32-NEXT:   successors: %bb.1(0x7c000000), %bb.2(0x04000000)
   ; AIX32-NEXT: {{  $}}
-  ; AIX32-NEXT:   BDNZ %bb.1, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   [[DecreaseCTRloop:%[0-9]+]]:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
+  ; AIX32-NEXT:   BC killed [[DecreaseCTRloop]], %bb.1
   ; AIX32-NEXT:   B %bb.2
   ; AIX32-NEXT: {{  $}}
   ; AIX32-NEXT: bb.2.return:
@@ -420,7 +431,8 @@ define i32 @test4(i32 %inp) {
   ; LE64-NEXT: bb.1.for.body:
   ; LE64-NEXT:   successors: %bb.1(0x7c000000), %bb.2(0x04000000)
   ; LE64-NEXT: {{  $}}
-  ; LE64-NEXT:   BDNZ8 %bb.1, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   [[DecreaseCTR8loop:%[0-9]+]]:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
+  ; LE64-NEXT:   BC killed [[DecreaseCTR8loop]], %bb.1
   ; LE64-NEXT:   B %bb.2
   ; LE64-NEXT: {{  $}}
   ; LE64-NEXT: bb.2.return:
diff --git a/llvm/test/CodeGen/PowerPC/ctrloops32.mir b/llvm/test/CodeGen/PowerPC/ctrloops32.mir
index 90ee800042c3ed..ffe62cf6a2f758 100644
--- a/llvm/test/CodeGen/PowerPC/ctrloops32.mir
+++ b/llvm/test/CodeGen/PowerPC/ctrloops32.mir
@@ -10,16 +10,16 @@ body:             |
   bb.0.entry:
 
     %0:gprc = LI 2048
-    ; CHECK: MTCTR
+    ; CHECK: MTCTRloop
     ; CHECK: BDNZ
     ; CHECK-NOT: ADDI
     ; CHECK-NOT: CMPLWI
     ; CHECK-NOT: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %1:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -35,17 +35,17 @@ body:             |
   bb.0.entry:
 
     %0:gprc = LI 2048
-    ; CHECK-NOT: MTCTR
+    ; CHECK-NOT: MTCTRloop
     ; CHECK-NOT: BDNZ
     ; CHECK: ADDI
     ; CHECK: CMPLWI
     ; CHECK: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
 
   bb.1:
 
     INLINEASM &"", 1 /* sideeffect attdialect */, 12 /* clobber */, implicit-def early-clobber $ctr
-    %1:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %1:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -61,17 +61,17 @@ body:             |
   bb.0.entry:
 
     %0:gprc = LI 2048
-    ; CHECK-NOT: MTCTR
+    ; CHECK-NOT: MTCTRloop
     ; CHECK-NOT: BDNZ
     ; CHECK: ADDI
     ; CHECK: CMPLWI
     ; CHECK: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
 
   bb.1:
 
     %1:gprc = MFCTR implicit $ctr
-    %2:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %2:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
@@ -92,12 +92,12 @@ body:             |
     ; CHECK: ADDI
     ; CHECK: CMPLWI
     ; CHECK: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
     BL @test_fail_use_in_loop, csr_aix32, implicit-def dead $lr, implicit $rm
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %1:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -119,11 +119,11 @@ body:             |
     ; CHECK-NOT: ADDI
     ; CHECK-NOT: CMPLWI
     ; CHECK-NOT: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %1:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -144,12 +144,12 @@ body:             |
     ; CHECK: ADDI
     ; CHECK: CMPLWI
     ; CHECK: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
 
   bb.1:
 
     BL @test_fail_use_in_loop, csr_aix32, implicit-def dead $lr, implicit $rm
-    %1:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %1:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -174,12 +174,12 @@ body:             |
     renamable %1:crrc = CMPLW killed renamable $r3, killed renamable $r4
     renamable %2:crbitrc = COPY %1.sub_gt
     MTLR %0:gprc, implicit-def $lr
-    MTCTRPseudo %0:gprc, implicit-def dead $ctr
+    MTCTRloop %0:gprc, implicit-def dead $ctr
 
   bb.1:
 
     BCLRL renamable %2, implicit $lr, implicit $rm
-    %3:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %3:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %3:crbitrc, %bb.1
     B %bb.2
 
@@ -196,16 +196,16 @@ body:             |
     liveins: $ctr
 
     %0:gprc = LI 2048
-    ; CHECK-NOT: MTCTR
+    ; CHECK-NOT: MTCTRloop
     ; CHECK-NOT: BDNZ
     ; CHECK: ADDI
     ; CHECK: CMPLWI
     ; CHECK: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %1:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -222,16 +222,16 @@ body:             |
 
     INLINEASM &"", 1 /* sideeffect attdialect */, 12 /* clobber */, implicit-def early-clobber $ctr
     %0:gprc = LI 2048
-    ; CHECK2-NOT: MTCTR
+    ; CHECK-NOT: MTCTRloop
     ; CHECK-NOT: BDNZ
     ; CHECK: ADDI
     ; CHECK: CMPLWI
     ; CHECK: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %1:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -248,16 +248,16 @@ body:             |
 
     %0:gprc = MFCTR implicit $ctr
     %1:gprc = LI 2048
-    ; CHECK: MTCTR
+    ; CHECK: MTCTRloop
     ; CHECK: BDNZ
     ; CHECK-NOT: ADDI
     ; CHECK-NOT: CMPLWI
     ; CHECK-NOT: BC
-    MTCTRPseudo killed %1:gprc, implicit-def dead $ctr
+    MTCTRloop killed %1:gprc, implicit-def dead $ctr
 
   bb.1:
 
-    %2:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %2:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
@@ -273,17 +273,17 @@ body:             |
   bb.0.entry:
 
     %0:gprc = LI 2048
-    ; CHECK-NOT: MTCTR
+    ; CHECK-NOT: MTCTRloop
     ; CHECK-NOT: BDNZ
     ; CHECK: ADDI
     ; CHECK: CMPLWI
     ; CHECK: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
     %1:gprc = MFCTR implicit $ctr
 
   bb.1:
 
-    %2:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %2:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
@@ -299,17 +299,17 @@ body:             |
   bb.0.entry:
 
     %0:gprc = LI 2048
-    ; CHECK-NOT: MTCTR
+    ; CHECK-NOT: MTCTRloop
     ; CHECK-NOT: BDNZ
     ; CHECK: ADDI
     ; CHECK: CMPLWI
     ; CHECK: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
     INLINEASM &"", 1 /* sideeffect attdialect */, 12 /* clobber */, implicit-def early-clobber $ctr
 
   bb.1:
 
-    %2:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %2:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
@@ -325,16 +325,16 @@ body:             |
   bb.0.entry:
 
     %0:gprc = LI 2048
-    ; CHECK: MTCTR
+    ; CHECK: MTCTRloop
     ; CHECK: BDNZ
     ; CHECK-NOT: ADDI
     ; CHECK-NOT: CMPLWI
     ; CHECK-NOT: BC
-    MTCTRPseudo killed %0:gprc, implicit-def dead $ctr
+    MTCTRloop killed %0:gprc, implicit-def dead $ctr
 
   bb.1:
 
-    %2:crbitrc = DecreaseCTRPseudo 1, implicit-def dead $ctr, implicit $ctr
+    %2:crbitrc = DecreaseCTRloop 1, implicit-def dead $ctr, implicit $ctr
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
diff --git a/llvm/test/CodeGen/PowerPC/ctrloops64.mir b/llvm/test/CodeGen/PowerPC/ctrloops64.mir
index 1d4ed84cdd6b58..8e50c555195b18 100644
--- a/llvm/test/CodeGen/PowerPC/ctrloops64.mir
+++ b/llvm/test/CodeGen/PowerPC/ctrloops64.mir
@@ -12,16 +12,16 @@ body:             |
   bb.0.entry:
 
     %0:g8rc = LI8 2048
-    ; CHECK: MTCTR8
+    ; CHECK: MTCTR8loop
     ; CHECK: BDNZ8
     ; CHECK-NOT: ADDI8
     ; CHECK-NOT: CMPLDI
     ; CHECK-NOT: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %1:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -37,17 +37,17 @@ body:             |
   bb.0.entry:
 
     %0:g8rc = LI8 2048
-    ; CHECK-NOT: MTCTR8
+    ; CHECK-NOT: MTCTR8loop
     ; CHECK-NOT: BDNZ8
     ; CHECK: ADDI8
     ; CHECK: CMPLDI
     ; CHECK: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
     INLINEASM &"", 1 /* sideeffect attdialect */, 12 /* clobber */, implicit-def early-clobber $ctr8
-    %1:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %1:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -63,17 +63,17 @@ body:             |
   bb.0.entry:
 
     %0:g8rc = LI8 2048
-    ; CHECK-NOT: MTCTR8
+    ; CHECK-NOT: MTCTR8loop
     ; CHECK-NOT: BDNZ8
     ; CHECK: ADDI8
     ; CHECK: CMPLDI
     ; CHECK: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
     %1:g8rc = MFCTR8 implicit $ctr8
-    %2:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %2:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
@@ -94,12 +94,12 @@ body:             |
     ; CHECK: ADDI8
     ; CHECK: CMPLDI
     ; CHECK: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
     BL8 @test_fail_use_in_loop, csr_ppc64, implicit-def dead $lr8, implicit $rm
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %1:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -121,11 +121,11 @@ body:             |
     ; CHECK-NOT: ADDI8
     ; CHECK-NOT: CMPLDI
     ; CHECK-NOT: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %1:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -146,12 +146,12 @@ body:             |
     ; CHECK: ADDI8
     ; CHECK: CMPLDI
     ; CHECK: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
     BL8 @test_fail_use_in_loop, csr_ppc64, implicit-def dead $lr8, implicit $rm
-    %1:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %1:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -176,12 +176,12 @@ body:             |
     renamable %1:crrc = CMPLD killed renamable $x3, killed renamable $x4
     renamable %2:crbitrc = COPY %1.sub_gt
     MTLR8 %0:g8rc, implicit-def $lr8
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
     BCLRL renamable %2, implicit $lr, implicit $rm
-    %3:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %3:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %3:crbitrc, %bb.1
     B %bb.2
 
@@ -198,16 +198,16 @@ body:             |
     liveins: $ctr8
 
     %0:g8rc = LI8 2048
-    ; CHECK-NOT: MTCTR8
+    ; CHECK-NOT: MTCTR8loop
     ; CHECK-NOT: BDNZ8
     ; CHECK: ADDI8
     ; CHECK: CMPLDI
     ; CHECK: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %1:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -224,16 +224,16 @@ body:             |
 
     INLINEASM &"", 1 /* sideeffect attdialect */, 12 /* clobber */, implicit-def early-clobber $ctr8
     %0:g8rc = LI8 2048
-    ; CHECK-NOT: MTCTR8
+    ; CHECK-NOT: MTCTR8loop
     ; CHECK-NOT: BDNZ8
     ; CHECK: ADDI8
     ; CHECK: CMPLDI
     ; CHECK: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
-    %1:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %1:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %1:crbitrc, %bb.1
     B %bb.2
 
@@ -250,16 +250,16 @@ body:             |
 
     %0:g8rc = MFCTR8 implicit $ctr8
     %1:g8rc = LI8 2048
-    ; CHECK: MTCTR8
+    ; CHECK: MTCTR8loop
     ; CHECK: BDNZ8
     ; CHECK-NOT: ADDI8
     ; CHECK-NOT: CMPLDI
     ; CHECK-NOT: BC
-    MTCTR8Pseudo killed %1:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %1:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
-    %2:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %2:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
@@ -275,17 +275,17 @@ body:             |
   bb.0.entry:
 
     %0:g8rc = LI8 2048
-    ; CHECK-NOT: MTCTR8
+    ; CHECK-NOT: MTCTR8loop
     ; CHECK-NOT: BDNZ8
     ; CHECK: ADDI8
     ; CHECK: CMPLDI
     ; CHECK: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
     %1:g8rc = MFCTR8 implicit $ctr8
 
   bb.1:
 
-    %2:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %2:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
@@ -301,17 +301,17 @@ body:             |
   bb.0.entry:
 
     %0:g8rc = LI8 2048
-    ; CHECK-NOT: MTCTR8
+    ; CHECK-NOT: MTCTR8loop
     ; CHECK-NOT: BDNZ8
     ; CHECK: ADDI8
     ; CHECK: CMPLDI
     ; CHECK: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
     INLINEASM &"", 1 /* sideeffect attdialect */, 12 /* clobber */, implicit-def early-clobber $ctr8
 
   bb.1:
 
-    %2:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %2:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
@@ -327,16 +327,16 @@ body:             |
   bb.0.entry:
 
     %0:g8rc = LI8 2048
-    ; CHECK: MTCTR8
+    ; CHECK: MTCTR8loop
     ; CHECK: BDNZ8
     ; CHECK-NOT: ADDI8
     ; CHECK-NOT: CMPLDI
     ; CHECK-NOT: BC
-    MTCTR8Pseudo killed %0:g8rc, implicit-def dead $ctr8
+    MTCTR8loop killed %0:g8rc, implicit-def dead $ctr8
 
   bb.1:
 
-    %2:crbitrc = DecreaseCTR8Pseudo 1, implicit-def dead $ctr8, implicit $ctr8
+    %2:crbitrc = DecreaseCTR8loop 1, implicit-def dead $ctr8, implicit $ctr8
     BC killed %2:crbitrc, %bb.1
     B %bb.2
 
diff --git a/llvm/test/CodeGen/PowerPC/sms-phi.ll b/llvm/test/CodeGen/PowerPC/sms-phi.ll
index 3ddf78157d7162..4e9031bced6f42 100644
--- a/llvm/test/CodeGen/PowerPC/sms-phi.ll
+++ b/llvm/test/CodeGen/PowerPC/sms-phi.ll
@@ -4,11 +4,11 @@
 ; RUN:       >/dev/null | FileCheck %s
 define dso_local void @sha512() #0 {
 ;CHECK: prolog:
-;CHECK:        %18:g8rc = ADD8 %24:g8rc, %23:g8rc
+;CHECK:        %{{[0-9]+}}:g8rc = ADD8 %{{[0-9]+}}:g8rc, %{{[0-9]+}}:g8rc
 ;CHECK: epilog:
-;CHECK:        %28:g8rc_and_g8rc_nox0 = PHI %6:g8rc_and_g8rc_nox0, %bb.3, %22:g8rc_and_g8rc_nox0, %bb.4
-;CHECK-NEXT:   %29:g8rc = PHI %12:g8rc, %bb.3, %16:g8rc, %bb.4
-;CHECK-NEXT:   %30:g8rc = PHI %15:g8rc, %bb.3, %19:g8rc, %bb.4
+;CHECK:        %{{[0-9]+}}:g8rc_and_g8rc_nox0 = PHI %{{[0-9]+}}:g8rc_and_g8rc_nox0, %bb.3, %{{[0-9]+}}:g8rc_and_g8rc_nox0, %bb.4
+;CHECK-NEXT:   %{{[0-9]+}}:g8rc = PHI %{{[0-9]+}}:g8rc, %bb.3, %{{[0-9]+}}:g8rc, %bb.4
+;CHECK-NEXT:   %{{[0-9]+}}:g8rc = PHI %{{[0-9]+}}:g8rc, %bb.3, %{{[0-9]+}}:g8rc, %bb.4
   br label %1
 
 1:                                                ; preds = %1, %0

From aee61d4601a8f09afd9d851aeb7952aea0fe3986 Mon Sep 17 00:00:00 2001
From: Gabriel Baraldi <baraldigabriel@gmail.com>
Date: Mon, 22 Aug 2022 13:17:12 -0300
Subject: [PATCH 70/84] Add patches for msan

---
 .../Instrumentation/MemorySanitizer.cpp       |  5 ++--
 .../Instrumentation/MemorySanitizer/alloca.ll | 30 +++++++++++++++++++
 .../MemorySanitizer/atomics.ll                | 14 +++++++++
 3 files changed, 47 insertions(+), 2 deletions(-)

diff --git a/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp b/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp
index 4606bd5de6c307..6a4397967f0105 100644
--- a/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp
+++ b/llvm/lib/Transforms/Instrumentation/MemorySanitizer.cpp
@@ -1940,7 +1940,7 @@ struct MemorySanitizerVisitor : public InstVisitor<MemorySanitizerVisitor> {
     IRBuilder<> IRB(&I);
     Value *Addr = I.getOperand(0);
     Value *Val = I.getOperand(1);
-    Value *ShadowPtr = getShadowOriginPtr(Addr, IRB, Val->getType(), Align(1),
+    Value *ShadowPtr = getShadowOriginPtr(Addr, IRB, getShadowTy(Val), Align(1),
                                           /*isStore*/ true)
                            .first;
 
@@ -3922,7 +3922,8 @@ struct MemorySanitizerVisitor : public InstVisitor<MemorySanitizerVisitor> {
     uint64_t TypeSize = DL.getTypeAllocSize(I.getAllocatedType());
     Value *Len = ConstantInt::get(MS.IntptrTy, TypeSize);
     if (I.isArrayAllocation())
-      Len = IRB.CreateMul(Len, I.getArraySize());
+      Len = IRB.CreateMul(Len,
+                          IRB.CreateZExtOrTrunc(I.getArraySize(), MS.IntptrTy));
 
     if (MS.CompileKernel)
       poisonAllocaKmsan(I, IRB, Len);
diff --git a/llvm/test/Instrumentation/MemorySanitizer/alloca.ll b/llvm/test/Instrumentation/MemorySanitizer/alloca.ll
index 10c1796ac60472..53f8879a944c1f 100644
--- a/llvm/test/Instrumentation/MemorySanitizer/alloca.ll
+++ b/llvm/test/Instrumentation/MemorySanitizer/alloca.ll
@@ -56,6 +56,20 @@ entry:
 ; KMSAN: call void @__msan_poison_alloca(i8* {{.*}}, i64 20,
 ; CHECK: ret void
 
+define void @array32() sanitize_memory {
+entry:
+  %x = alloca i32, i32 5, align 4
+  ret void
+}
+
+; CHECK-LABEL: define void @array32(
+; INLINE: call void @llvm.memset.p0i8.i64(i8* align 4 {{.*}}, i8 -1, i64 20, i1 false)
+; CALL: call void @__msan_poison_stack(i8* {{.*}}, i64 20)
+; ORIGIN: call void @__msan_set_alloca_origin_with_descr(i8* {{.*}}, i64 20,
+; ORIGIN-LEAN: call void @__msan_set_alloca_origin_no_descr(i8* {{.*}}, i64 20,
+; KMSAN: call void @__msan_poison_alloca(i8* {{.*}}, i64 20,
+; CHECK: ret void
+
 define void @array_non_const(i64 %cnt) sanitize_memory {
 entry:
   %x = alloca i32, i64 %cnt, align 4
@@ -70,6 +84,22 @@ entry:
 ; KMSAN: call void @__msan_poison_alloca(i8* {{.*}}, i64 %[[A]],
 ; CHECK: ret void
 
+define void @array_non_const32(i32 %cnt) sanitize_memory {
+entry:
+  %x = alloca i32, i32 %cnt, align 4
+  ret void
+}
+
+; CHECK-LABEL: define void @array_non_const32(
+; CHECK: %[[Z:.*]] = zext i32 %cnt to i64
+; CHECK: %[[A:.*]] = mul i64 4, %[[Z]]
+; INLINE: call void @llvm.memset.p0i8.i64(i8* align 4 {{.*}}, i8 -1, i64 %[[A]], i1 false)
+; CALL: call void @__msan_poison_stack(i8* {{.*}}, i64 %[[A]])
+; ORIGIN: call void @__msan_set_alloca_origin_with_descr(i8* {{.*}}, i64 %[[A]],
+; ORIGIN-LEAN: call void @__msan_set_alloca_origin_no_descr(i8* {{.*}}, i64 %[[A]],
+; KMSAN: call void @__msan_poison_alloca(i8* {{.*}}, i64 %[[A]],
+; CHECK: ret void
+
 ; Check that the local is unpoisoned in the absence of sanitize_memory
 define void @unpoison_local() {
 entry:
diff --git a/llvm/test/Instrumentation/MemorySanitizer/atomics.ll b/llvm/test/Instrumentation/MemorySanitizer/atomics.ll
index 4fff90ea788b99..196f67f03fad49 100644
--- a/llvm/test/Instrumentation/MemorySanitizer/atomics.ll
+++ b/llvm/test/Instrumentation/MemorySanitizer/atomics.ll
@@ -22,6 +22,20 @@ entry:
 ; CHECK: store i32 0, {{.*}} @__msan_retval_tls
 ; CHECK: ret i32
 
+; atomicrmw xchg ptr: exactly the same as above
+
+define i32* @AtomicRmwXchgPtr(i32** %p, i32* %x) sanitize_memory {
+entry:
+  %0 = atomicrmw xchg i32** %p, i32* %x seq_cst
+  ret i32* %0
+}
+
+; CHECK-LABEL: @AtomicRmwXchgPtr
+; CHECK: store i64 0,
+; CHECK: atomicrmw xchg {{.*}} seq_cst
+; CHECK: store i64 0, {{.*}} @__msan_retval_tls
+; CHECK: ret i32*
+
 
 ; atomicrmw max: exactly the same as above
 

From 6f13c5b9c31e50ad2a8742a8108836d587897f6c Mon Sep 17 00:00:00 2001
From: Gabriel Baraldi <baraldigabriel@gmail.com>
Date: Mon, 22 Aug 2022 13:18:19 -0300
Subject: [PATCH 71/84] Try keno's tentative TLS fix

---
 compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp | 4 ++++
 1 file changed, 4 insertions(+)

diff --git a/compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp b/compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp
index b13e2dc9e33278..e4bbba74cd7fcf 100644
--- a/compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp
+++ b/compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp
@@ -16,6 +16,8 @@
 #include "sanitizer_flags.h"
 #include "sanitizer_platform_interceptors.h"
 
+#include <malloc.h>
+
 namespace __sanitizer {
 #if SANITIZER_INTERCEPT_TLS_GET_ADDR
 
@@ -139,6 +141,8 @@ DTLS::DTV *DTLS_on_tls_get_addr(void *arg_void, void *res,
     tls_beg = header->start;
     VReport(2, "__tls_get_addr: glibc >=2.19 suspected; tls={0x%zx 0x%zx}\n",
             tls_beg, tls_size);
+  } else if (uptr size = malloc_usable_size((void *)tls_beg)) {
+    tls_size = size;
   } else {
     VReport(2, "__tls_get_addr: Can't guess glibc version\n");
     // This may happen inside the DTOR of main thread, so just ignore it.

From 15b2b0317ee63b470d6c44712fc3f17f9922bf3f Mon Sep 17 00:00:00 2001
From: Gabriel Baraldi <baraldigabriel@gmail.com>
Date: Wed, 31 Aug 2022 20:06:40 -0300
Subject: [PATCH 72/84] Make include conditional to macos

---
 compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp | 2 ++
 1 file changed, 2 insertions(+)

diff --git a/compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp b/compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp
index e4bbba74cd7fcf..45c52763cebfed 100644
--- a/compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp
+++ b/compiler-rt/lib/sanitizer_common/sanitizer_tls_get_addr.cpp
@@ -16,7 +16,9 @@
 #include "sanitizer_flags.h"
 #include "sanitizer_platform_interceptors.h"
 
+#if !defined(__APPLE__)
 #include <malloc.h>
+#endif
 
 namespace __sanitizer {
 #if SANITIZER_INTERCEPT_TLS_GET_ADDR

From 90e1c629f21fe3a8d66d06ebdc5dde62aa6203be Mon Sep 17 00:00:00 2001
From: Keno Fischer <keno@juliacomputing.com>
Date: Wed, 4 Jan 2023 01:49:17 +0000
Subject: [PATCH 73/84] [LVI] Look through negations when evaluating conditions

This teaches LVI (and thus CVP) to extract range information
from branches whose condition is negated using (`xor %c, true`).
On the implementation side, we switch the cache to additionally
track whether we're looking for the inverted value or not and
otherwise using the existing support for computing inverted
conditions.

I think the biggest question here is why this negation shows up
here at all. After all, it should always be possible for some
other pass to fold such a negation into a branch, comparison or
some other logical operation. Indeed, instcombine does just that.
However, these negations can be otherwise fairly persistent, e.g.
instsimplify is not able to exchange branch conditions from
negations. In addition, jumpthreading, which sits at the same
point in default pass pipeline also handles this pattern, which
adds further evidence that we might expect these negations to
not have been canonicalized away yet at this point in the pass
pipeline.

In the particular case I was looking at there was a bit of a
circular dependency where flags computed by cvp were needed
by instcombine, and incstombine's folding of the negation was
needed for cvp. Adding a second instombine pass would have
worked of course, but instcombine can be somewhat expensive,
so it appeared desirable to not require it to have run
before cvp (as is the case in the default pass pipeline).

Reviewed By: nikic

Differential Revision: https://reviews.llvm.org/D140933

(cherry picked from commit 1436a9232b10487a097f62bf85025fc6b6b66fde)
---
 llvm/lib/Analysis/LazyValueInfo.cpp           | 50 ++++++++++------
 .../CorrelatedValuePropagation/basic.ll       | 57 +++++++++++++++++++
 2 files changed, 91 insertions(+), 16 deletions(-)

diff --git a/llvm/lib/Analysis/LazyValueInfo.cpp b/llvm/lib/Analysis/LazyValueInfo.cpp
index 2fae260e0d8fef..7b7f7c6bb64b0a 100644
--- a/llvm/lib/Analysis/LazyValueInfo.cpp
+++ b/llvm/lib/Analysis/LazyValueInfo.cpp
@@ -1161,11 +1161,17 @@ static ValueLatticeElement getValueFromOverflowCondition(
   return ValueLatticeElement::getRange(NWR);
 }
 
+// Tracks a Value * condition and whether we're interested in it or its inverse
+typedef PointerIntPair<Value *, 1, bool> CondValue;
+
 static Optional<ValueLatticeElement>
-getValueFromConditionImpl(Value *Val, Value *Cond, bool isTrueDest,
-                          bool isRevisit,
-                          SmallDenseMap<Value *, ValueLatticeElement> &Visited,
-                          SmallVectorImpl<Value *> &Worklist) {
+getValueFromConditionImpl(
+    Value *Val, CondValue CondVal, bool isRevisit,
+    SmallDenseMap<CondValue, ValueLatticeElement> &Visited,
+    SmallVectorImpl<CondValue> &Worklist) {
+
+  Value *Cond = CondVal.getPointer();
+  bool isTrueDest = CondVal.getInt();
   if (!isRevisit) {
     if (ICmpInst *ICI = dyn_cast<ICmpInst>(Cond))
       return getValueFromICmpCondition(Val, ICI, isTrueDest);
@@ -1176,6 +1182,17 @@ getValueFromConditionImpl(Value *Val, Value *Cond, bool isTrueDest,
           return getValueFromOverflowCondition(Val, WO, isTrueDest);
   }
 
+  Value *N;
+  if (match(Cond, m_Not(m_Value(N)))) {
+    CondValue NKey(N, !isTrueDest);
+    auto NV = Visited.find(NKey);
+    if (NV == Visited.end()) {
+      Worklist.push_back(NKey);
+      return None;
+    }
+    return NV->second;
+  }
+
   Value *L, *R;
   bool IsAnd;
   if (match(Cond, m_LogicalAnd(m_Value(L), m_Value(R))))
@@ -1185,13 +1202,13 @@ getValueFromConditionImpl(Value *Val, Value *Cond, bool isTrueDest,
   else
     return ValueLatticeElement::getOverdefined();
 
-  auto LV = Visited.find(L);
-  auto RV = Visited.find(R);
+  auto LV = Visited.find(CondValue(L, isTrueDest));
+  auto RV = Visited.find(CondValue(R, isTrueDest));
 
   // if (L && R) -> intersect L and R
-  // if (!(L || R)) -> intersect L and R
+  // if (!(L || R)) -> intersect !L and !R
   // if (L || R) -> union L and R
-  // if (!(L && R)) -> union L and R
+  // if (!(L && R)) -> union !L and !R
   if ((isTrueDest ^ IsAnd) && (LV != Visited.end())) {
     ValueLatticeElement V = LV->second;
     if (V.isOverdefined())
@@ -1205,9 +1222,9 @@ getValueFromConditionImpl(Value *Val, Value *Cond, bool isTrueDest,
   if (LV == Visited.end() || RV == Visited.end()) {
     assert(!isRevisit);
     if (LV == Visited.end())
-      Worklist.push_back(L);
+      Worklist.push_back(CondValue(L, isTrueDest));
     if (RV == Visited.end())
-      Worklist.push_back(R);
+      Worklist.push_back(CondValue(R, isTrueDest));
     return None;
   }
 
@@ -1217,12 +1234,13 @@ getValueFromConditionImpl(Value *Val, Value *Cond, bool isTrueDest,
 ValueLatticeElement getValueFromCondition(Value *Val, Value *Cond,
                                           bool isTrueDest) {
   assert(Cond && "precondition");
-  SmallDenseMap<Value*, ValueLatticeElement> Visited;
-  SmallVector<Value *> Worklist;
+  SmallDenseMap<CondValue, ValueLatticeElement> Visited;
+  SmallVector<CondValue> Worklist;
 
-  Worklist.push_back(Cond);
+  CondValue CondKey(Cond, isTrueDest);
+  Worklist.push_back(CondKey);
   do {
-    Value *CurrentCond = Worklist.back();
+    CondValue CurrentCond = Worklist.back();
     // Insert an Overdefined placeholder into the set to prevent
     // infinite recursion if there exists IRs that use not
     // dominated by its def as in this example:
@@ -1232,14 +1250,14 @@ ValueLatticeElement getValueFromCondition(Value *Val, Value *Cond,
         Visited.try_emplace(CurrentCond, ValueLatticeElement::getOverdefined());
     bool isRevisit = !Iter.second;
     Optional<ValueLatticeElement> Result = getValueFromConditionImpl(
-        Val, CurrentCond, isTrueDest, isRevisit, Visited, Worklist);
+        Val, CurrentCond, isRevisit, Visited, Worklist);
     if (Result) {
       Visited[CurrentCond] = *Result;
       Worklist.pop_back();
     }
   } while (!Worklist.empty());
 
-  auto Result = Visited.find(Cond);
+  auto Result = Visited.find(CondKey);
   assert(Result != Visited.end());
   return Result->second;
 }
diff --git a/llvm/test/Transforms/CorrelatedValuePropagation/basic.ll b/llvm/test/Transforms/CorrelatedValuePropagation/basic.ll
index 7a08f4d2bd2701..b39dae7b28e893 100644
--- a/llvm/test/Transforms/CorrelatedValuePropagation/basic.ll
+++ b/llvm/test/Transforms/CorrelatedValuePropagation/basic.ll
@@ -1853,6 +1853,63 @@ define void @xor(i8 %a, i1* %p) {
   ret void
 }
 
+define i1 @xor_neg_cond(i32 %a) {
+; CHECK-LABEL: @xor_neg_cond(
+; CHECK-NEXT:    [[CMP1:%.*]] = icmp eq i32 [[A:%.*]], 10
+; CHECK-NEXT:    [[XOR:%.*]] = xor i1 [[CMP1]], true
+; CHECK-NEXT:    br i1 [[XOR]], label [[EXIT:%.*]], label [[GUARD:%.*]]
+; CHECK:       guard:
+; CHECK-NEXT:    ret i1 true
+; CHECK:       exit:
+; CHECK-NEXT:    ret i1 false
+;
+  %cmp1 = icmp eq i32 %a, 10
+  %xor = xor i1 %cmp1, true
+  br i1 %xor, label %exit, label %guard
+
+guard:
+  %cmp2 = icmp eq i32 %a, 10
+  ret i1 %cmp2
+
+exit:
+  ret i1 false
+}
+
+define i1 @xor_approx(i32 %a) {
+; CHECK-LABEL: @xor_approx(
+; CHECK-NEXT:    [[CMP1:%.*]] = icmp ugt i32 [[A:%.*]], 2
+; CHECK-NEXT:    [[CMP2:%.*]] = icmp ult i32 [[A]], 5
+; CHECK-NEXT:    [[CMP3:%.*]] = icmp ugt i32 [[A]], 7
+; CHECK-NEXT:    [[CMP4:%.*]] = icmp ult i32 [[A]], 9
+; CHECK-NEXT:    [[AND1:%.*]] = and i1 [[CMP1]], [[CMP2]]
+; CHECK-NEXT:    [[AND2:%.*]] = and i1 [[CMP3]], [[CMP4]]
+; CHECK-NEXT:    [[OR:%.*]] = or i1 [[AND1]], [[AND2]]
+; CHECK-NEXT:    [[XOR:%.*]] = xor i1 [[OR]], true
+; CHECK-NEXT:    br i1 [[XOR]], label [[EXIT:%.*]], label [[GUARD:%.*]]
+; CHECK:       guard:
+; CHECK-NEXT:    [[CMP5:%.*]] = icmp eq i32 [[A]], 6
+; CHECK-NEXT:    ret i1 [[CMP5]]
+; CHECK:       exit:
+; CHECK-NEXT:    ret i1 false
+;
+  %cmp1 = icmp ugt i32 %a, 2
+  %cmp2 = icmp ult i32 %a, 5
+  %cmp3 = icmp ugt i32 %a, 7
+  %cmp4 = icmp ult i32 %a, 9
+  %and1 = and i1 %cmp1, %cmp2
+  %and2 = and i1 %cmp3, %cmp4
+  %or = or i1 %and1, %and2
+  %xor = xor i1 %or, true
+  br i1 %xor, label %exit, label %guard
+
+guard:
+  %cmp5 = icmp eq i32 %a, 6
+  ret i1 %cmp5
+
+exit:
+  ret i1 false
+}
+
 declare i32 @llvm.uadd.sat.i32(i32, i32)
 declare i32 @llvm.usub.sat.i32(i32, i32)
 declare i32 @llvm.sadd.sat.i32(i32, i32)

From bf7ed7ade77424108f5de7c02b8a1febe4751cee Mon Sep 17 00:00:00 2001
From: Prem Chintalapudi <prem.chintalapudi@gmail.com>
Date: Fri, 14 Apr 2023 17:35:07 -0700
Subject: [PATCH 74/84] [NewPM] Use PassID instead of pass name

PrintIRInstrumentation::shouldPrintAfterPass accepts a pass ID instead of a pass name

Reviewed By: aeubanks

Differential Revision: https://reviews.llvm.org/D147394

(cherry picked from commit d4de7c2e1e7954ea03545f1551fda9f6bb9387cf)
---
 llvm/lib/Passes/StandardInstrumentations.cpp  |  3 +--
 .../loop-print-after-pass-invalidated.ll      | 21 +++++++++++++++++++
 2 files changed, 22 insertions(+), 2 deletions(-)
 create mode 100644 llvm/test/Other/loop-print-after-pass-invalidated.ll

diff --git a/llvm/lib/Passes/StandardInstrumentations.cpp b/llvm/lib/Passes/StandardInstrumentations.cpp
index a0c63fb33369ec..60ab3314259e09 100644
--- a/llvm/lib/Passes/StandardInstrumentations.cpp
+++ b/llvm/lib/Passes/StandardInstrumentations.cpp
@@ -758,8 +758,7 @@ void PrintIRInstrumentation::printAfterPass(StringRef PassID, Any IR) {
 }
 
 void PrintIRInstrumentation::printAfterPassInvalidated(StringRef PassID) {
-  StringRef PassName = PIC->getPassNameForClassName(PassID);
-  if (!shouldPrintAfterPass(PassName))
+  if (!shouldPrintAfterPass(PassID))
     return;
 
   if (isIgnored(PassID))
diff --git a/llvm/test/Other/loop-print-after-pass-invalidated.ll b/llvm/test/Other/loop-print-after-pass-invalidated.ll
new file mode 100644
index 00000000000000..63106f62ae1328
--- /dev/null
+++ b/llvm/test/Other/loop-print-after-pass-invalidated.ll
@@ -0,0 +1,21 @@
+; RUN: opt < %s 2>&1 -disable-output \
+; RUN: 	   -passes='simple-loop-unswitch<nontrivial>' \
+; RUN:     -print-after=simple-loop-unswitch \
+; RUN:	   | FileCheck %s
+
+; CHECK: *** IR Dump After SimpleLoopUnswitchPass on for.cond ***
+; CHECK: *** IR Dump After SimpleLoopUnswitchPass on for.cond.us ***
+
+define void @loop(i1 %w)  {
+entry:
+  br label %for.cond
+; Loop:
+for.cond:                                         ; preds = %for.inc, %entry
+  br i1 %w, label %for.inc, label %if.then
+
+if.then:                                          ; preds = %for.cond
+  br label %for.inc
+
+for.inc:                                          ; preds = %if.then, %for.cond
+  br label %for.cond
+}

From 6783826bf945837ac95d93546644d2723dedef73 Mon Sep 17 00:00:00 2001
From: Elliot Saba <staticfloat@gmail.com>
Date: Mon, 27 Mar 2023 17:43:54 -0700
Subject: [PATCH 75/84] Disable pathologically expensive `SimplifySelectOps`
 optimization

`SimplifySelectOps` is a late optimization in LLVM that attempts to
translate `select(C, load(A), load(B))` into `load(select(C, A, B))`.
However, in order for it to do this optimization, it needs to check that
`C` does not depend on the result of `load(A)` or `load(B)`.
Unfortunately (unlikely Julia and LLVM at the IR level), LLVM does not
have a topological order of statements computed at this stage of the
compiler, so LLVM needs to iterate through all statements in the
function in order to perform this legality check. For large functions,
this is extremely expensive, accounting for the majority of all
compilation time for such functions. On the other hand, the optimization
itself is minor, allowing at most the elision of one additional load
(and doesn't fire particularly often, because the middle end can perform
similar optimizations). Until there is a proper solution in LLVM, simply
disable this optimizations, making LLVM several orders of magnitude
faster on real world benchmarks.

X-ref: https://github.com/llvm/llvm-project/issues/60132
---
 llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp | 1 +
 1 file changed, 1 insertion(+)

diff --git a/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp b/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp
index a7f9382478d47b..2607179c20aa89 100644
--- a/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp
+++ b/llvm/lib/CodeGen/SelectionDAG/DAGCombiner.cpp
@@ -23772,6 +23772,7 @@ bool DAGCombiner::SimplifySelectOps(SDNode *TheSelect, SDValue LHS,
         !TLI.isOperationLegalOrCustom(TheSelect->getOpcode(),
                                       LLD->getBasePtr().getValueType()))
       return false;
+    return false;
 
     // The loads must not depend on one another.
     if (LLD->isPredecessorOf(RLD) || RLD->isPredecessorOf(LLD))

From 5354b0a21acb90f128273b2653bf0005d8ae58b7 Mon Sep 17 00:00:00 2001
From: Joshua Cao <cao.joshua@yahoo.com>
Date: Mon, 17 Apr 2023 14:28:48 -0400
Subject: [PATCH 76/84] [SimpleLoopUnswitch] unswitch selects

The old LoopUnswitch pass unswitched selects, but the changes were never
ported to the new SimpleLoopUnswitch.

We unswitch by turning:

```
S = select %cond, %a, %b
```

into:

```
head:
br %cond, label %then, label %tail

then:
br label %tail

tail:
S = phi [ %a, %then ], [ %b, %head ]
```

Unswitch selects are always nontrivial, since the successors do not exit
the loop and the loop body always needs to be cloned.

Differential Revision: https://reviews.llvm.org/D138526
---
 .../Transforms/Scalar/SimpleLoopUnswitch.cpp  | 96 ++++++++++++++++---
 .../nontrivial-unswitch-freeze.ll             | 19 ++--
 .../nontrivial-unswitch-trivial-select.ll     | 28 ++++--
 3 files changed, 115 insertions(+), 28 deletions(-)

diff --git a/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp b/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp
index 0535608244cc23..e5037955363019 100644
--- a/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp
+++ b/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp
@@ -70,6 +70,7 @@ using namespace llvm::PatternMatch;
 
 STATISTIC(NumBranches, "Number of branches unswitched");
 STATISTIC(NumSwitches, "Number of switches unswitched");
+STATISTIC(NumSelects, "Number of selects turned into branches for unswitching");
 STATISTIC(NumGuards, "Number of guards turned into branches for unswitching");
 STATISTIC(NumTrivial, "Number of unswitches that are trivial");
 STATISTIC(
@@ -2552,6 +2553,59 @@ static InstructionCost computeDomSubtreeCost(
   return Cost;
 }
 
+/// Turns a select instruction into implicit control flow branch,
+/// making the following replacement:
+///
+/// head:
+///   --code before select--
+///   select %cond, %trueval, %falseval
+///   --code after select--
+///
+/// into
+///
+/// head:
+///   --code before select--
+///   br i1 %cond, label %then, label %tail
+///
+/// then:
+///   br %tail
+///
+/// tail:
+///   phi [ %trueval, %then ], [ %falseval, %head]
+///   unreachable
+///
+/// It also makes all relevant DT and LI updates, so that all structures are in
+/// valid state after this transform.
+static BranchInst *turnSelectIntoBranch(SelectInst *SI, DominatorTree &DT,
+                                        LoopInfo &LI, MemorySSAUpdater *MSSAU,
+                                        AssumptionCache *AC) {
+  LLVM_DEBUG(dbgs() << "Turning " << *SI << " into a branch.\n");
+  BasicBlock *HeadBB = SI->getParent();
+
+  Value *Cond = SI->getCondition();
+  if (!isGuaranteedNotToBeUndefOrPoison(Cond, AC, SI, &DT))
+    Cond = new FreezeInst(Cond, Cond->getName() + ".fr", SI);
+  SplitBlockAndInsertIfThen(SI->getCondition(), SI, false,
+                            SI->getMetadata(LLVMContext::MD_prof), &DT, &LI);
+  auto *CondBr = cast<BranchInst>(HeadBB->getTerminator());
+  BasicBlock *ThenBB = CondBr->getSuccessor(0),
+             *TailBB = CondBr->getSuccessor(1);
+  if (MSSAU)
+    MSSAU->moveAllAfterSpliceBlocks(HeadBB, TailBB, SI);
+
+  PHINode *Phi = PHINode::Create(SI->getType(), 2, "unswitched.select", SI);
+  Phi->addIncoming(SI->getTrueValue(), ThenBB);
+  Phi->addIncoming(SI->getFalseValue(), HeadBB);
+  SI->replaceAllUsesWith(Phi);
+  SI->eraseFromParent();
+
+  if (MSSAU && VerifyMemorySSA)
+    MSSAU->getMemorySSA()->verifyMemorySSA();
+
+  ++NumSelects;
+  return CondBr;
+}
+
 /// Turns a llvm.experimental.guard intrinsic into implicit control flow branch,
 /// making the following replacement:
 ///
@@ -2663,9 +2717,10 @@ static int CalculateUnswitchCostMultiplier(
   BasicBlock *CondBlock = TI.getParent();
   if (DT.dominates(CondBlock, Latch) &&
       (isGuard(&TI) ||
-       llvm::count_if(successors(&TI), [&L](BasicBlock *SuccBB) {
-         return L.contains(SuccBB);
-       }) <= 1)) {
+       (TI.isTerminator() &&
+        llvm::count_if(successors(&TI), [&L](BasicBlock *SuccBB) {
+          return L.contains(SuccBB);
+        }) <= 1))) {
     NumCostMultiplierSkipped++;
     return 1;
   }
@@ -2674,12 +2729,17 @@ static int CalculateUnswitchCostMultiplier(
   int SiblingsCount = (ParentL ? ParentL->getSubLoopsVector().size()
                                : std::distance(LI.begin(), LI.end()));
   // Count amount of clones that all the candidates might cause during
-  // unswitching. Branch/guard counts as 1, switch counts as log2 of its cases.
+  // unswitching. Branch/guard/select counts as 1, switch counts as log2 of its
+  // cases.
   int UnswitchedClones = 0;
   for (auto Candidate : UnswitchCandidates) {
     Instruction *CI = Candidate.first;
     BasicBlock *CondBlock = CI->getParent();
     bool SkipExitingSuccessors = DT.dominates(CondBlock, Latch);
+    if (isa<SelectInst>(CI)) {
+      UnswitchedClones++;
+      continue;
+    }
     if (isGuard(CI)) {
       if (!SkipExitingSuccessors)
         UnswitchedClones++;
@@ -2747,14 +2807,19 @@ static bool unswitchBestCondition(
     if (LI.getLoopFor(BB) != &L)
       continue;
 
-    if (CollectGuards)
-      for (auto &I : *BB)
-        if (isGuard(&I)) {
-          auto *Cond = cast<IntrinsicInst>(&I)->getArgOperand(0);
-          // TODO: Support AND, OR conditions and partial unswitching.
-          if (!isa<Constant>(Cond) && L.isLoopInvariant(Cond))
-            UnswitchCandidates.push_back({&I, {Cond}});
-        }
+    for (auto &I : *BB) {
+      if (auto *SI = dyn_cast<SelectInst>(&I)) {
+        auto *Cond = SI->getCondition();
+        if (!isa<Constant>(Cond) && L.isLoopInvariant(Cond))
+          UnswitchCandidates.push_back({&I, {Cond}});
+      } else if (CollectGuards && isGuard(&I)) {
+        auto *Cond =
+            skipTrivialSelect(cast<IntrinsicInst>(&I)->getArgOperand(0));
+        // TODO: Support AND, OR conditions and partial unswitching.
+        if (!isa<Constant>(Cond) && L.isLoopInvariant(Cond))
+          UnswitchCandidates.push_back({&I, {Cond}});
+      }
+    }
 
     if (auto *SI = dyn_cast<SwitchInst>(BB->getTerminator())) {
       // We can only consider fully loop-invariant switch conditions as we need
@@ -2953,7 +3018,8 @@ static bool unswitchBestCondition(
     // loop. This is computing the new cost of unswitching a condition.
     // Note that guards always have 2 unique successors that are implicit and
     // will be materialized if we decide to unswitch it.
-    int SuccessorsCount = isGuard(&TI) ? 2 : Visited.size();
+    int SuccessorsCount =
+        isGuard(&TI) || isa<SelectInst>(TI) ? 2 : Visited.size();
     assert(SuccessorsCount > 1 &&
            "Cannot unswitch a condition without multiple distinct successors!");
     return (LoopCost - Cost) * (SuccessorsCount - 1);
@@ -3004,7 +3070,9 @@ static bool unswitchBestCondition(
     PartialIVInfo.InstToDuplicate.clear();
 
   // If the best candidate is a guard, turn it into a branch.
-  if (isGuard(BestUnswitchTI))
+  if (auto *SI = dyn_cast<SelectInst>(BestUnswitchTI))
+    BestUnswitchTI = turnSelectIntoBranch(SI, DT, LI, MSSAU, &AC);
+  else if (isGuard(BestUnswitchTI))
     BestUnswitchTI = turnGuardIntoBranch(cast<IntrinsicInst>(BestUnswitchTI), L,
                                          ExitBlocks, DT, LI, MSSAU);
 
diff --git a/llvm/test/Transforms/SimpleLoopUnswitch/nontrivial-unswitch-freeze.ll b/llvm/test/Transforms/SimpleLoopUnswitch/nontrivial-unswitch-freeze.ll
index ff9feab4a74c02..d253205576d171 100644
--- a/llvm/test/Transforms/SimpleLoopUnswitch/nontrivial-unswitch-freeze.ll
+++ b/llvm/test/Transforms/SimpleLoopUnswitch/nontrivial-unswitch-freeze.ll
@@ -2332,21 +2332,26 @@ exit:
 define i32 @test_partial_unswitch_all_conds_guaranteed_non_poison(i1 noundef %c.1, i1 noundef %c.2) {
 ; CHECK-LABEL: @test_partial_unswitch_all_conds_guaranteed_non_poison(
 ; CHECK-NEXT:  entry:
-; CHECK-NEXT:    [[TMP0:%.*]] = and i1 [[C_1:%.*]], [[C_2:%.*]]
-; CHECK-NEXT:    br i1 [[TMP0]], label [[ENTRY_SPLIT:%.*]], label [[ENTRY_SPLIT_US:%.*]]
+; CHECK-NEXT:    br i1 [[C_1:%.*]], label [[ENTRY_SPLIT_US:%.*]], label [[ENTRY_SPLIT:%.*]]
 ; CHECK:       entry.split.us:
 ; CHECK-NEXT:    br label [[LOOP_US:%.*]]
 ; CHECK:       loop.us:
-; CHECK-NEXT:    [[TMP1:%.*]] = call i32 @a()
-; CHECK-NEXT:    br label [[EXIT_SPLIT_US:%.*]]
+; CHECK-NEXT:    [[TMP0:%.*]] = call i32 @a()
+; CHECK-NEXT:    br label [[TMP1:%.*]]
+; CHECK:       1:
+; CHECK-NEXT:    br label [[TMP2:%.*]]
+; CHECK:       2:
+; CHECK-NEXT:    [[UNSWITCHED_SELECT_US:%.*]] = phi i1 [ [[C_2:%.*]], [[TMP1]] ]
+; CHECK-NEXT:    br i1 [[UNSWITCHED_SELECT_US]], label [[LOOP_US]], label [[EXIT_SPLIT_US:%.*]]
 ; CHECK:       exit.split.us:
 ; CHECK-NEXT:    br label [[EXIT:%.*]]
 ; CHECK:       entry.split:
 ; CHECK-NEXT:    br label [[LOOP:%.*]]
 ; CHECK:       loop:
-; CHECK-NEXT:    [[TMP2:%.*]] = call i32 @a()
-; CHECK-NEXT:    [[SEL:%.*]] = select i1 true, i1 true, i1 false
-; CHECK-NEXT:    br i1 [[SEL]], label [[LOOP]], label [[EXIT_SPLIT:%.*]]
+; CHECK-NEXT:    [[TMP3:%.*]] = call i32 @a()
+; CHECK-NEXT:    br label [[TMP4:%.*]]
+; CHECK:       4:
+; CHECK-NEXT:    br i1 false, label [[LOOP]], label [[EXIT_SPLIT:%.*]]
 ; CHECK:       exit.split:
 ; CHECK-NEXT:    br label [[EXIT]]
 ; CHECK:       exit:
diff --git a/llvm/test/Transforms/SimpleLoopUnswitch/nontrivial-unswitch-trivial-select.ll b/llvm/test/Transforms/SimpleLoopUnswitch/nontrivial-unswitch-trivial-select.ll
index 5280aa7d3e2847..654b9efb2a275a 100644
--- a/llvm/test/Transforms/SimpleLoopUnswitch/nontrivial-unswitch-trivial-select.ll
+++ b/llvm/test/Transforms/SimpleLoopUnswitch/nontrivial-unswitch-trivial-select.ll
@@ -92,17 +92,31 @@ define i32 @unswitch_trivial_select_cmp_outside(i32 %x) {
 ; CHECK:       entry.split.us:
 ; CHECK-NEXT:    br label [[LOOP_US:%.*]]
 ; CHECK:       loop.us:
-; CHECK-NEXT:    [[P_US:%.*]] = phi i32 [ 0, [[ENTRY_SPLIT_US]] ], [ 35, [[LOOP_US]] ]
-; CHECK-NEXT:    br label [[LOOP_US]]
+; CHECK-NEXT:    [[P_US:%.*]] = phi i32 [ 0, [[ENTRY_SPLIT_US]] ], [ 35, [[TMP1:%.*]] ]
+; CHECK-NEXT:    [[C_FR_US:%.*]] = freeze i1 true
+; CHECK-NEXT:    br label [[TMP0:%.*]]
+; CHECK:       0:
+; CHECK-NEXT:    br label [[TMP1]]
+; CHECK:       1:
+; CHECK-NEXT:    [[UNSWITCHED_SELECT_US:%.*]] = phi i1 [ true, [[TMP0]] ]
+; CHECK-NEXT:    br i1 [[UNSWITCHED_SELECT_US]], label [[LOOP_US]], label [[EXIT_SPLIT_US:%.*]]
+; CHECK:       exit.split.us:
+; CHECK-NEXT:    [[LCSSA_US:%.*]] = phi i32 [ [[P_US]], [[TMP1]] ]
+; CHECK-NEXT:    br label [[EXIT:%.*]]
 ; CHECK:       entry.split:
 ; CHECK-NEXT:    br label [[LOOP:%.*]]
 ; CHECK:       loop:
-; CHECK-NEXT:    [[P:%.*]] = phi i32 [ 0, [[ENTRY_SPLIT]] ]
-; CHECK-NEXT:    [[SPEC_SELECT:%.*]] = select i1 false, i1 true, i1 false
-; CHECK-NEXT:    br label [[EXIT:%.*]]
+; CHECK-NEXT:    [[P:%.*]] = phi i32 [ 0, [[ENTRY_SPLIT]] ], [ 35, [[TMP2:%.*]] ]
+; CHECK-NEXT:    [[C_FR:%.*]] = freeze i1 false
+; CHECK-NEXT:    br label [[TMP2]]
+; CHECK:       2:
+; CHECK-NEXT:    br i1 false, label [[LOOP]], label [[EXIT_SPLIT:%.*]]
+; CHECK:       exit.split:
+; CHECK-NEXT:    [[LCSSA:%.*]] = phi i32 [ [[P]], [[TMP2]] ]
+; CHECK-NEXT:    br label [[EXIT]]
 ; CHECK:       exit:
-; CHECK-NEXT:    [[LCSSA:%.*]] = phi i32 [ [[P]], [[LOOP]] ]
-; CHECK-NEXT:    ret i32 [[LCSSA]]
+; CHECK-NEXT:    [[DOTUS_PHI:%.*]] = phi i32 [ [[LCSSA]], [[EXIT_SPLIT]] ], [ [[LCSSA_US]], [[EXIT_SPLIT_US]] ]
+; CHECK-NEXT:    ret i32 [[DOTUS_PHI]]
 ;
 entry:
   %c = icmp ult i32 %x, 100

From 6f51ecd2842de0ea4b72bc9807b4294d6bab227c Mon Sep 17 00:00:00 2001
From: Prem Chintalapudi <prem.chintalapudi@gmail.com>
Date: Sun, 2 Apr 2023 10:29:52 -0700
Subject: [PATCH 77/84] [MCJIT] Set VMA to code address in
 PerfJITEventListener.

VMA should default to CodeAddr, not 0, as specified here:
https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/tree/tools/perf/Documentation/jitdump-specification.txt

Reviewed By: lhames

Differential Revision: https://reviews.llvm.org/D146496

(cherry picked from commit e5bdf0f6d2552541ebab1d2a865f9c4e10ca6724)
---
 llvm/lib/ExecutionEngine/PerfJITEvents/PerfJITEventListener.cpp | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/llvm/lib/ExecutionEngine/PerfJITEvents/PerfJITEventListener.cpp b/llvm/lib/ExecutionEngine/PerfJITEvents/PerfJITEventListener.cpp
index bb41bac3253489..730805a056ceba 100644
--- a/llvm/lib/ExecutionEngine/PerfJITEvents/PerfJITEventListener.cpp
+++ b/llvm/lib/ExecutionEngine/PerfJITEvents/PerfJITEventListener.cpp
@@ -417,7 +417,7 @@ void PerfJITEventListener::NotifyCode(Expected<llvm::StringRef> &Symbol,
   rec.Prefix.Timestamp = perf_get_timestamp();
 
   rec.CodeSize = CodeSize;
-  rec.Vma = 0;
+  rec.Vma = CodeAddr;
   rec.CodeAddr = CodeAddr;
   rec.Pid = Pid;
   rec.Tid = get_threadid();

From fcc8566589dd38181281316a65a96ea1e8b6b599 Mon Sep 17 00:00:00 2001
From: Prem Chintalapudi <prem.chintalapudi@gmail.com>
Date: Mon, 17 Apr 2023 17:14:30 -0700
Subject: [PATCH 78/84] Expose PassBuilder extension point callbacks

This patch allows access to callbacks registered by TargetMachines to allow custom pipelines to run those callbacks.

Reviewed By: aeubanks

Differential Revision: https://reviews.llvm.org/D148561

(cherry picked from commit 33817296c6003f6b3bb7eed5fbcd64a2385fe425)
---
 llvm/include/llvm/Passes/PassBuilder.h   |  29 ++++-
 llvm/lib/Passes/PassBuilderPipelines.cpp | 136 ++++++++++++++---------
 2 files changed, 110 insertions(+), 55 deletions(-)

diff --git a/llvm/include/llvm/Passes/PassBuilder.h b/llvm/include/llvm/Passes/PassBuilder.h
index 0cbbdf7f3ce805..88c6382f14b1b3 100644
--- a/llvm/include/llvm/Passes/PassBuilder.h
+++ b/llvm/include/llvm/Passes/PassBuilder.h
@@ -579,6 +579,34 @@ class PassBuilder {
     return PIC;
   }
 
+  // Invoke the callbacks registered for the various extension points.
+  // Custom pipelines should use these to invoke the callbacks registered
+  // by TargetMachines and other clients.
+  void invokePeepholeEPCallbacks(FunctionPassManager &FPM,
+                                 OptimizationLevel Level);
+  void invokeLateLoopOptimizationsEPCallbacks(LoopPassManager &LPM,
+                                              OptimizationLevel Level);
+  void invokeLoopOptimizerEndEPCallbacks(LoopPassManager &LPM,
+                                         OptimizationLevel Level);
+  void invokeScalarOptimizerLateEPCallbacks(FunctionPassManager &FPM,
+                                            OptimizationLevel Level);
+  void invokeCGSCCOptimizerLateEPCallbacks(CGSCCPassManager &CGPM,
+                                           OptimizationLevel Level);
+  void invokeVectorizerStartEPCallbacks(FunctionPassManager &FPM,
+                                        OptimizationLevel Level);
+  void invokeOptimizerEarlyEPCallbacks(ModulePassManager &MPM,
+                                       OptimizationLevel Level);
+  void invokeOptimizerLastEPCallbacks(ModulePassManager &MPM,
+                                      OptimizationLevel Level);
+  void invokeFullLinkTimeOptimizationEarlyEPCallbacks(ModulePassManager &MPM,
+                                                      OptimizationLevel Level);
+  void invokeFullLinkTimeOptimizationLastEPCallbacks(ModulePassManager &MPM,
+                                                     OptimizationLevel Level);
+  void invokePipelineStartEPCallbacks(ModulePassManager &MPM,
+                                      OptimizationLevel Level);
+  void invokePipelineEarlySimplificationEPCallbacks(ModulePassManager &MPM,
+                                                    OptimizationLevel Level);
+
 private:
   // O1 pass pipeline
   FunctionPassManager
@@ -612,7 +640,6 @@ class PassBuilder {
                          bool RunProfileGen, bool IsCS, std::string ProfileFile,
                          std::string ProfileRemappingFile,
                          ThinOrFullLTOPhase LTOPhase);
-  void invokePeepholeEPCallbacks(FunctionPassManager &, OptimizationLevel);
 
   // Extension Point callbacks
   SmallVector<std::function<void(FunctionPassManager &, OptimizationLevel)>, 2>
diff --git a/llvm/lib/Passes/PassBuilderPipelines.cpp b/llvm/lib/Passes/PassBuilderPipelines.cpp
index 945ef512391b02..b77c351e16a430 100644
--- a/llvm/lib/Passes/PassBuilderPipelines.cpp
+++ b/llvm/lib/Passes/PassBuilderPipelines.cpp
@@ -230,6 +230,61 @@ void PassBuilder::invokePeepholeEPCallbacks(FunctionPassManager &FPM,
   for (auto &C : PeepholeEPCallbacks)
     C(FPM, Level);
 }
+void PassBuilder::invokeLateLoopOptimizationsEPCallbacks(
+    LoopPassManager &LPM, OptimizationLevel Level) {
+  for (auto &C : LateLoopOptimizationsEPCallbacks)
+    C(LPM, Level);
+}
+void PassBuilder::invokeLoopOptimizerEndEPCallbacks(LoopPassManager &LPM,
+                                                    OptimizationLevel Level) {
+  for (auto &C : LoopOptimizerEndEPCallbacks)
+    C(LPM, Level);
+}
+void PassBuilder::invokeScalarOptimizerLateEPCallbacks(
+    FunctionPassManager &FPM, OptimizationLevel Level) {
+  for (auto &C : ScalarOptimizerLateEPCallbacks)
+    C(FPM, Level);
+}
+void PassBuilder::invokeCGSCCOptimizerLateEPCallbacks(CGSCCPassManager &CGPM,
+                                                      OptimizationLevel Level) {
+  for (auto &C : CGSCCOptimizerLateEPCallbacks)
+    C(CGPM, Level);
+}
+void PassBuilder::invokeVectorizerStartEPCallbacks(FunctionPassManager &FPM,
+                                                   OptimizationLevel Level) {
+  for (auto &C : VectorizerStartEPCallbacks)
+    C(FPM, Level);
+}
+void PassBuilder::invokeOptimizerEarlyEPCallbacks(ModulePassManager &MPM,
+                                                  OptimizationLevel Level) {
+  for (auto &C : OptimizerEarlyEPCallbacks)
+    C(MPM, Level);
+}
+void PassBuilder::invokeOptimizerLastEPCallbacks(ModulePassManager &MPM,
+                                                 OptimizationLevel Level) {
+  for (auto &C : OptimizerLastEPCallbacks)
+    C(MPM, Level);
+}
+void PassBuilder::invokeFullLinkTimeOptimizationEarlyEPCallbacks(
+    ModulePassManager &MPM, OptimizationLevel Level) {
+  for (auto &C : FullLinkTimeOptimizationEarlyEPCallbacks)
+    C(MPM, Level);
+}
+void PassBuilder::invokeFullLinkTimeOptimizationLastEPCallbacks(
+    ModulePassManager &MPM, OptimizationLevel Level) {
+  for (auto &C : FullLinkTimeOptimizationLastEPCallbacks)
+    C(MPM, Level);
+}
+void PassBuilder::invokePipelineStartEPCallbacks(ModulePassManager &MPM,
+                                                 OptimizationLevel Level) {
+  for (auto &C : PipelineStartEPCallbacks)
+    C(MPM, Level);
+}
+void PassBuilder::invokePipelineEarlySimplificationEPCallbacks(
+    ModulePassManager &MPM, OptimizationLevel Level) {
+  for (auto &C : PipelineEarlySimplificationEPCallbacks)
+    C(MPM, Level);
+}
 
 // Helper to add AnnotationRemarksPass.
 static void addAnnotationRemarksPass(ModulePassManager &MPM) {
@@ -311,8 +366,7 @@ PassBuilder::buildO1FunctionSimplificationPipeline(OptimizationLevel Level,
   LPM2.addPass(LoopIdiomRecognizePass());
   LPM2.addPass(IndVarSimplifyPass());
 
-  for (auto &C : LateLoopOptimizationsEPCallbacks)
-    C(LPM2, Level);
+  invokeLateLoopOptimizationsEPCallbacks(LPM2, Level);
 
   LPM2.addPass(LoopDeletionPass());
 
@@ -330,8 +384,7 @@ PassBuilder::buildO1FunctionSimplificationPipeline(OptimizationLevel Level,
                                     /* OnlyWhenForced= */ !PTO.LoopUnrolling,
                                     PTO.ForgetAllSCEVInLoopUnroll));
 
-  for (auto &C : LoopOptimizerEndEPCallbacks)
-    C(LPM2, Level);
+  invokeLoopOptimizerEndEPCallbacks(LPM2, Level);
 
   // We provide the opt remark emitter pass for LICM to use. We only need to do
   // this once as it is immutable.
@@ -372,8 +425,7 @@ PassBuilder::buildO1FunctionSimplificationPipeline(OptimizationLevel Level,
 
   FPM.addPass(CoroElidePass());
 
-  for (auto &C : ScalarOptimizerLateEPCallbacks)
-    C(FPM, Level);
+  invokeScalarOptimizerLateEPCallbacks(FPM, Level);
 
   // Finally, do an expensive DCE pass to catch all the dead code exposed by
   // the simplifications and basic cleanup after all the simplifications.
@@ -496,8 +548,7 @@ PassBuilder::buildFunctionSimplificationPipeline(OptimizationLevel Level,
   LPM2.addPass(LoopIdiomRecognizePass());
   LPM2.addPass(IndVarSimplifyPass());
 
-  for (auto &C : LateLoopOptimizationsEPCallbacks)
-    C(LPM2, Level);
+  invokeLateLoopOptimizationsEPCallbacks(LPM2, Level);
 
   LPM2.addPass(LoopDeletionPass());
 
@@ -515,8 +566,7 @@ PassBuilder::buildFunctionSimplificationPipeline(OptimizationLevel Level,
                                     /* OnlyWhenForced= */ !PTO.LoopUnrolling,
                                     PTO.ForgetAllSCEVInLoopUnroll));
 
-  for (auto &C : LoopOptimizerEndEPCallbacks)
-    C(LPM2, Level);
+  invokeLoopOptimizerEndEPCallbacks(LPM2, Level);
 
   // We provide the opt remark emitter pass for LICM to use. We only need to do
   // this once as it is immutable.
@@ -589,8 +639,7 @@ PassBuilder::buildFunctionSimplificationPipeline(OptimizationLevel Level,
 
   FPM.addPass(CoroElidePass());
 
-  for (auto &C : ScalarOptimizerLateEPCallbacks)
-    C(FPM, Level);
+  invokeScalarOptimizerLateEPCallbacks(FPM, Level);
 
   FPM.addPass(SimplifyCFGPass(SimplifyCFGOptions()
                                   .convertSwitchRangeToICmp(true)
@@ -772,8 +821,7 @@ PassBuilder::buildInlinerPipeline(OptimizationLevel Level,
   if (Level == OptimizationLevel::O2 || Level == OptimizationLevel::O3)
     MainCGPipeline.addPass(OpenMPOptCGSCCPass());
 
-  for (auto &C : CGSCCOptimizerLateEPCallbacks)
-    C(MainCGPipeline, Level);
+  invokeCGSCCOptimizerLateEPCallbacks(MainCGPipeline, Level);
 
   // Lastly, add the core function simplification pipeline nested inside the
   // CGSCC walk.
@@ -928,8 +976,7 @@ PassBuilder::buildModuleSimplificationPipeline(OptimizationLevel Level,
   if (Phase == ThinOrFullLTOPhase::ThinLTOPostLink)
     MPM.addPass(LowerTypeTestsPass(nullptr, nullptr, true));
 
-  for (auto &C : PipelineEarlySimplificationEPCallbacks)
-    C(MPM, Level);
+  invokePipelineEarlySimplificationEPCallbacks(MPM, Level);
 
   // Specialize functions with IPSCCP.
   if (EnableFunctionSpecialization && Level == OptimizationLevel::O3)
@@ -1189,8 +1236,7 @@ PassBuilder::buildModuleOptimizationPipeline(OptimizationLevel Level,
   // memory operations.
   MPM.addPass(RecomputeGlobalsAAPass());
 
-  for (auto &C : OptimizerEarlyEPCallbacks)
-    C(MPM, Level);
+  invokeOptimizerEarlyEPCallbacks(MPM, Level);
 
   FunctionPassManager OptimizePM;
   OptimizePM.addPass(Float2IntPass());
@@ -1208,8 +1254,7 @@ PassBuilder::buildModuleOptimizationPipeline(OptimizationLevel Level,
   // rather than on each loop in an inside-out manner, and so they are actually
   // function passes.
 
-  for (auto &C : VectorizerStartEPCallbacks)
-    C(OptimizePM, Level);
+  invokeVectorizerStartEPCallbacks(OptimizePM, Level);
 
   LoopPassManager LPM;
   // First rotate loops that may have been un-rotated by prior passes.
@@ -1261,8 +1306,7 @@ PassBuilder::buildModuleOptimizationPipeline(OptimizationLevel Level,
   MPM.addPass(createModuleToFunctionPassAdaptor(std::move(OptimizePM),
                                                 PTO.EagerlyInvalidateAnalyses));
 
-  for (auto &C : OptimizerLastEPCallbacks)
-    C(MPM, Level);
+  invokeOptimizerLastEPCallbacks(MPM, Level);
 
   // Split out cold code. Splitting is done late to avoid hiding context from
   // other optimizations and inadvertently regressing performance. The tradeoff
@@ -1315,8 +1359,7 @@ PassBuilder::buildPerModuleDefaultPipeline(OptimizationLevel Level,
   MPM.addPass(ForceFunctionAttrsPass());
 
   // Apply module pipeline start EP callback.
-  for (auto &C : PipelineStartEPCallbacks)
-    C(MPM, Level);
+  invokePipelineStartEPCallbacks(MPM, Level);
 
   if (PGOOpt && PGOOpt->DebugInfoForProfiling)
     MPM.addPass(createModuleToFunctionPassAdaptor(AddDiscriminatorsPass()));
@@ -1360,8 +1403,7 @@ PassBuilder::buildThinLTOPreLinkDefaultPipeline(OptimizationLevel Level) {
     MPM.addPass(createModuleToFunctionPassAdaptor(AddDiscriminatorsPass()));
 
   // Apply module pipeline start EP callback.
-  for (auto &C : PipelineStartEPCallbacks)
-    C(MPM, Level);
+  invokePipelineStartEPCallbacks(MPM, Level);
 
   // If we are planning to perform ThinLTO later, we don't bloat the code with
   // unrolling/vectorization/... now. Just simplify the module as much as we
@@ -1389,8 +1431,7 @@ PassBuilder::buildThinLTOPreLinkDefaultPipeline(OptimizationLevel Level) {
   // Handle OptimizerLastEPCallbacks added by clang on PreLink. Actual
   // optimization is going to be done in PostLink stage, but clang can't
   // add callbacks there in case of in-process ThinLTO called by linker.
-  for (auto &C : OptimizerLastEPCallbacks)
-    C(MPM, Level);
+  invokeOptimizerLastEPCallbacks(MPM, Level);
 
   // Emit annotation remarks.
   addAnnotationRemarksPass(MPM);
@@ -1473,8 +1514,7 @@ PassBuilder::buildLTODefaultPipeline(OptimizationLevel Level,
   // Convert @llvm.global.annotations to !annotation metadata.
   MPM.addPass(Annotation2MetadataPass());
 
-  for (auto &C : FullLinkTimeOptimizationEarlyEPCallbacks)
-    C(MPM, Level);
+  invokeFullLinkTimeOptimizationEarlyEPCallbacks(MPM, Level);
 
   // Create a function that performs CFI checks for cross-DSO calls with targets
   // in the current module.
@@ -1489,8 +1529,7 @@ PassBuilder::buildLTODefaultPipeline(OptimizationLevel Level,
     // in ICP.
     MPM.addPass(LowerTypeTestsPass(nullptr, nullptr, true));
 
-    for (auto &C : FullLinkTimeOptimizationLastEPCallbacks)
-      C(MPM, Level);
+    invokeFullLinkTimeOptimizationLastEPCallbacks(MPM, Level);
 
     // Emit annotation remarks.
     addAnnotationRemarksPass(MPM);
@@ -1571,8 +1610,7 @@ PassBuilder::buildLTODefaultPipeline(OptimizationLevel Level,
     // pipeline).
     MPM.addPass(LowerTypeTestsPass(nullptr, nullptr, true));
 
-    for (auto &C : FullLinkTimeOptimizationLastEPCallbacks)
-      C(MPM, Level);
+    invokeFullLinkTimeOptimizationLastEPCallbacks(MPM, Level);
 
     // Emit annotation remarks.
     addAnnotationRemarksPass(MPM);
@@ -1753,8 +1791,7 @@ PassBuilder::buildLTODefaultPipeline(OptimizationLevel Level,
   if (PTO.CallGraphProfile)
     MPM.addPass(CGProfilePass());
 
-  for (auto &C : FullLinkTimeOptimizationLastEPCallbacks)
-    C(MPM, Level);
+  invokeFullLinkTimeOptimizationLastEPCallbacks(MPM, Level);
 
   // Emit annotation remarks.
   addAnnotationRemarksPass(MPM);
@@ -1783,14 +1820,12 @@ ModulePassManager PassBuilder::buildO0DefaultPipeline(OptimizationLevel Level,
         /* RunProfileGen */ (PGOOpt->Action == PGOOptions::IRInstr),
         /* IsCS */ false, PGOOpt->ProfileFile, PGOOpt->ProfileRemappingFile);
 
-  for (auto &C : PipelineStartEPCallbacks)
-    C(MPM, Level);
+  invokePipelineStartEPCallbacks(MPM, Level);
 
   if (PGOOpt && PGOOpt->DebugInfoForProfiling)
     MPM.addPass(createModuleToFunctionPassAdaptor(AddDiscriminatorsPass()));
 
-  for (auto &C : PipelineEarlySimplificationEPCallbacks)
-    C(MPM, Level);
+  invokePipelineEarlySimplificationEPCallbacks(MPM, Level);
 
   // Build a minimal pipeline based on the semantics required by LLVM,
   // which is just that always inlining occurs. Further, disable generating
@@ -1808,15 +1843,13 @@ ModulePassManager PassBuilder::buildO0DefaultPipeline(OptimizationLevel Level,
 
   if (!CGSCCOptimizerLateEPCallbacks.empty()) {
     CGSCCPassManager CGPM;
-    for (auto &C : CGSCCOptimizerLateEPCallbacks)
-      C(CGPM, Level);
+    invokeCGSCCOptimizerLateEPCallbacks(CGPM, Level);
     if (!CGPM.isEmpty())
       MPM.addPass(createModuleToPostOrderCGSCCPassAdaptor(std::move(CGPM)));
   }
   if (!LateLoopOptimizationsEPCallbacks.empty()) {
     LoopPassManager LPM;
-    for (auto &C : LateLoopOptimizationsEPCallbacks)
-      C(LPM, Level);
+    invokeLateLoopOptimizationsEPCallbacks(LPM, Level);
     if (!LPM.isEmpty()) {
       MPM.addPass(createModuleToFunctionPassAdaptor(
           createFunctionToLoopPassAdaptor(std::move(LPM))));
@@ -1824,8 +1857,7 @@ ModulePassManager PassBuilder::buildO0DefaultPipeline(OptimizationLevel Level,
   }
   if (!LoopOptimizerEndEPCallbacks.empty()) {
     LoopPassManager LPM;
-    for (auto &C : LoopOptimizerEndEPCallbacks)
-      C(LPM, Level);
+    invokeLoopOptimizerEndEPCallbacks(LPM, Level);
     if (!LPM.isEmpty()) {
       MPM.addPass(createModuleToFunctionPassAdaptor(
           createFunctionToLoopPassAdaptor(std::move(LPM))));
@@ -1833,19 +1865,16 @@ ModulePassManager PassBuilder::buildO0DefaultPipeline(OptimizationLevel Level,
   }
   if (!ScalarOptimizerLateEPCallbacks.empty()) {
     FunctionPassManager FPM;
-    for (auto &C : ScalarOptimizerLateEPCallbacks)
-      C(FPM, Level);
+    invokeScalarOptimizerLateEPCallbacks(FPM, Level);
     if (!FPM.isEmpty())
       MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));
   }
 
-  for (auto &C : OptimizerEarlyEPCallbacks)
-    C(MPM, Level);
+  invokeOptimizerEarlyEPCallbacks(MPM, Level);
 
   if (!VectorizerStartEPCallbacks.empty()) {
     FunctionPassManager FPM;
-    for (auto &C : VectorizerStartEPCallbacks)
-      C(FPM, Level);
+    invokeVectorizerStartEPCallbacks(FPM, Level);
     if (!FPM.isEmpty())
       MPM.addPass(createModuleToFunctionPassAdaptor(std::move(FPM)));
   }
@@ -1859,8 +1888,7 @@ ModulePassManager PassBuilder::buildO0DefaultPipeline(OptimizationLevel Level,
   CoroPM.addPass(GlobalDCEPass());
   MPM.addPass(CoroConditionalWrapper(std::move(CoroPM)));
 
-  for (auto &C : OptimizerLastEPCallbacks)
-    C(MPM, Level);
+  invokeOptimizerLastEPCallbacks(MPM, Level);
 
   if (LTOPreLink)
     addRequiredLTOPreLinkPasses(MPM);

From 3089b0b526eed060bc1c0ed582dabe2a06801226 Mon Sep 17 00:00:00 2001
From: Valentin Churavy <v.churavy@gmail.com>
Date: Sun, 30 Apr 2023 17:35:09 -0400
Subject: [PATCH 79/84] Don't loop unswitch vector selects

Otherwise we could produce `br <2x i1>` which are of course not legal.

```
Branch condition is not 'i1' type!
  br <2 x i1> %cond.fr1, label %entry.split.us, label %entry.split
  %cond.fr1 = freeze <2 x i1> %cond
LLVM ERROR: Broken module found, compilation aborted!
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/vchuravy/builds/llvm/bin/opt -passes=simple-loop-unswitch<nontrivial> -S
```

Fixes https://reviews.llvm.org/D138526

Differential Revision: https://reviews.llvm.org/D149560
---
 llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp b/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp
index e5037955363019..bf53dfd456e0d3 100644
--- a/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp
+++ b/llvm/lib/Transforms/Scalar/SimpleLoopUnswitch.cpp
@@ -2810,7 +2810,8 @@ static bool unswitchBestCondition(
     for (auto &I : *BB) {
       if (auto *SI = dyn_cast<SelectInst>(&I)) {
         auto *Cond = SI->getCondition();
-        if (!isa<Constant>(Cond) && L.isLoopInvariant(Cond))
+        // restrict to simple boolean selects
+        if (!isa<Constant>(Cond) && L.isLoopInvariant(Cond) && Cond->getType()->isIntegerTy(1))
           UnswitchCandidates.push_back({&I, {Cond}});
       } else if (CollectGuards && isGuard(&I)) {
         auto *Cond =

From e9683c03b0e034f0ac1ab5f2b1f22465aad73385 Mon Sep 17 00:00:00 2001
From: Nikita Popov <npopov@redhat.com>
Date: Wed, 13 Jul 2022 16:53:11 +0200
Subject: [PATCH 80/84] [IR] Add Instruction::getInsertionPointAfterDef()

Transforms occasionally want to insert an instruction directly
after the definition point of a value. This involves quite a few
different edge cases, e.g. for phi nodes the next insertion point
is not the next instruction, and for invokes and callbrs its not
even in the same block. Additionally, the insertion point may not
exist at all if catchswitch is involved.

This adds a general Instruction::getInsertionPointAfterDef() API to
implement the necessary logic. For now it is used in two places
where this should be mostly NFC. I will follow up with additional
uses where this fixes specific bugs in the existing implementations.

Differential Revision: https://reviews.llvm.org/D129660
---
 llvm/include/llvm/IR/Instruction.h            |  7 +++++
 llvm/lib/IR/Instruction.cpp                   | 26 +++++++++++++++++++
 llvm/lib/Transforms/Coroutines/CoroFrame.cpp  | 17 +++++-------
 .../InstCombine/InstCombineCalls.cpp          | 15 +++--------
 4 files changed, 43 insertions(+), 22 deletions(-)

diff --git a/llvm/include/llvm/IR/Instruction.h b/llvm/include/llvm/IR/Instruction.h
index 15b0bdf557fb1e..dd9cd519fc4b78 100644
--- a/llvm/include/llvm/IR/Instruction.h
+++ b/llvm/include/llvm/IR/Instruction.h
@@ -149,6 +149,13 @@ class Instruction : public User,
   /// it takes constant time.
   bool comesBefore(const Instruction *Other) const;
 
+  /// Get the first insertion point at which the result of this instruction
+  /// is defined. This is *not* the directly following instruction in a number
+  /// of cases, e.g. phi nodes or terminators that return values. This function
+  /// may return null if the insertion after the definition is not possible,
+  /// e.g. due to a catchswitch terminator.
+  Instruction *getInsertionPointAfterDef();
+
   //===--------------------------------------------------------------------===//
   // Subclass classification.
   //===--------------------------------------------------------------------===//
diff --git a/llvm/lib/IR/Instruction.cpp b/llvm/lib/IR/Instruction.cpp
index bf76c89f26ca89..007e518a1a8179 100644
--- a/llvm/lib/IR/Instruction.cpp
+++ b/llvm/lib/IR/Instruction.cpp
@@ -116,6 +116,32 @@ bool Instruction::comesBefore(const Instruction *Other) const {
   return Order < Other->Order;
 }
 
+Instruction *Instruction::getInsertionPointAfterDef() {
+  assert(!getType()->isVoidTy() && "Instruction must define result");
+  BasicBlock *InsertBB;
+  BasicBlock::iterator InsertPt;
+  if (auto *PN = dyn_cast<PHINode>(this)) {
+    InsertBB = PN->getParent();
+    InsertPt = InsertBB->getFirstInsertionPt();
+  } else if (auto *II = dyn_cast<InvokeInst>(this)) {
+    InsertBB = II->getNormalDest();
+    InsertPt = InsertBB->getFirstInsertionPt();
+  } else if (auto *CB = dyn_cast<CallBrInst>(this)) {
+    InsertBB = CB->getDefaultDest();
+    InsertPt = InsertBB->getFirstInsertionPt();
+  } else {
+    assert(!isTerminator() && "Only invoke/callbr terminators return value");
+    InsertBB = getParent();
+    InsertPt = std::next(getIterator());
+  }
+
+  // catchswitch blocks don't have any legal insertion point (because they
+  // are both an exception pad and a terminator).
+  if (InsertPt == InsertBB->end())
+    return nullptr;
+  return &*InsertPt;
+}
+
 bool Instruction::isOnlyUserOfAnyOperand() {
   return any_of(operands(), [](Value *V) { return V->hasOneUser(); });
 }
diff --git a/llvm/lib/Transforms/Coroutines/CoroFrame.cpp b/llvm/lib/Transforms/Coroutines/CoroFrame.cpp
index 51eb8ebf03691d..dcff14b8638543 100644
--- a/llvm/lib/Transforms/Coroutines/CoroFrame.cpp
+++ b/llvm/lib/Transforms/Coroutines/CoroFrame.cpp
@@ -2633,16 +2633,13 @@ void coro::salvageDebugInfo(
   // dbg.value or dbg.addr since they do not have the same function wide
   // guarantees that dbg.declare does.
   if (!isa<DbgValueInst>(DVI) && !isa<DbgAddrIntrinsic>(DVI)) {
-    if (auto *II = dyn_cast<InvokeInst>(Storage))
-      DVI->moveBefore(II->getNormalDest()->getFirstNonPHI());
-    else if (auto *CBI = dyn_cast<CallBrInst>(Storage))
-      DVI->moveBefore(CBI->getDefaultDest()->getFirstNonPHI());
-    else if (auto *InsertPt = dyn_cast<Instruction>(Storage)) {
-      assert(!InsertPt->isTerminator() &&
-             "Unimaged terminator that could return a storage.");
-      DVI->moveAfter(InsertPt);
-    } else if (isa<Argument>(Storage))
-      DVI->moveAfter(F->getEntryBlock().getFirstNonPHI());
+    Instruction *InsertPt = nullptr;
+    if (auto *I = dyn_cast<Instruction>(Storage))
+      InsertPt = I->getInsertionPointAfterDef();
+    else if (isa<Argument>(Storage))
+      InsertPt = &*F->getEntryBlock().begin();
+    if (InsertPt)
+      DVI->moveBefore(InsertPt);
   }
 }
 
diff --git a/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp b/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp
index 52596b30494fa3..9e3dec1cf92b41 100644
--- a/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp
+++ b/llvm/lib/Transforms/InstCombine/InstCombineCalls.cpp
@@ -3451,18 +3451,9 @@ bool InstCombinerImpl::transformConstExprCastCall(CallBase &Call) {
       NV = NC = CastInst::CreateBitOrPointerCast(NC, OldRetTy);
       NC->setDebugLoc(Caller->getDebugLoc());
 
-      // If this is an invoke/callbr instruction, we should insert it after the
-      // first non-phi instruction in the normal successor block.
-      if (InvokeInst *II = dyn_cast<InvokeInst>(Caller)) {
-        BasicBlock::iterator I = II->getNormalDest()->getFirstInsertionPt();
-        InsertNewInstBefore(NC, *I);
-      } else if (CallBrInst *CBI = dyn_cast<CallBrInst>(Caller)) {
-        BasicBlock::iterator I = CBI->getDefaultDest()->getFirstInsertionPt();
-        InsertNewInstBefore(NC, *I);
-      } else {
-        // Otherwise, it's a call, just insert cast right after the call.
-        InsertNewInstBefore(NC, *Caller);
-      }
+      Instruction *InsertPt = NewCall->getInsertionPointAfterDef();
+      assert(InsertPt && "No place to insert cast");
+      InsertNewInstBefore(NC, *InsertPt);
       Worklist.pushUsersToWorkList(*Caller);
     } else {
       NV = UndefValue::get(Caller->getType());

From e42aaf192bf5a8a2b55ac520cad9a70f5aab3348 Mon Sep 17 00:00:00 2001
From: Sanjay Patel <spatel@rotateright.com>
Date: Fri, 10 Feb 2023 10:53:22 -0500
Subject: [PATCH 81/84] [VectorCombine] fix insertion point of shuffles

As shown in issue #60649, the new shuffles were
being inserted before a phi, and that is invalid.

It seems like most test coverage for this fold
(foldSelectShuffle) lives in the AArch64 dir,
but this doesn't repro there for a base target.
---
 .../Transforms/Vectorize/VectorCombine.cpp    |  8 ++--
 .../VectorCombine/X86/select-shuffle.ll       | 38 +++++++++++++++++++
 2 files changed, 42 insertions(+), 4 deletions(-)
 create mode 100644 llvm/test/Transforms/VectorCombine/X86/select-shuffle.ll

diff --git a/llvm/lib/Transforms/Vectorize/VectorCombine.cpp b/llvm/lib/Transforms/Vectorize/VectorCombine.cpp
index a38936644bd306..0c0976ab969796 100644
--- a/llvm/lib/Transforms/Vectorize/VectorCombine.cpp
+++ b/llvm/lib/Transforms/Vectorize/VectorCombine.cpp
@@ -1518,16 +1518,16 @@ bool VectorCombine::foldSelectShuffle(Instruction &I, bool FromReduction) {
           return SSV->getOperand(Op);
     return SV->getOperand(Op);
   };
-  Builder.SetInsertPoint(SVI0A->getNextNode());
+  Builder.SetInsertPoint(SVI0A->getInsertionPointAfterDef());
   Value *NSV0A = Builder.CreateShuffleVector(GetShuffleOperand(SVI0A, 0),
                                              GetShuffleOperand(SVI0A, 1), V1A);
-  Builder.SetInsertPoint(SVI0B->getNextNode());
+  Builder.SetInsertPoint(SVI0B->getInsertionPointAfterDef());
   Value *NSV0B = Builder.CreateShuffleVector(GetShuffleOperand(SVI0B, 0),
                                              GetShuffleOperand(SVI0B, 1), V1B);
-  Builder.SetInsertPoint(SVI1A->getNextNode());
+  Builder.SetInsertPoint(SVI1A->getInsertionPointAfterDef());
   Value *NSV1A = Builder.CreateShuffleVector(GetShuffleOperand(SVI1A, 0),
                                              GetShuffleOperand(SVI1A, 1), V2A);
-  Builder.SetInsertPoint(SVI1B->getNextNode());
+  Builder.SetInsertPoint(SVI1B->getInsertionPointAfterDef());
   Value *NSV1B = Builder.CreateShuffleVector(GetShuffleOperand(SVI1B, 0),
                                              GetShuffleOperand(SVI1B, 1), V2B);
   Builder.SetInsertPoint(Op0);
diff --git a/llvm/test/Transforms/VectorCombine/X86/select-shuffle.ll b/llvm/test/Transforms/VectorCombine/X86/select-shuffle.ll
new file mode 100644
index 00000000000000..d51ac6a33911d4
--- /dev/null
+++ b/llvm/test/Transforms/VectorCombine/X86/select-shuffle.ll
@@ -0,0 +1,38 @@
+; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
+; RUN: opt < %s -passes=vector-combine -S -mtriple=x86_64-- | FileCheck %s
+
+target datalayout = "e-p:64:64-i64:64-f80:128-n8:16:32:64-S128"
+
+; This would insert before a phi instruction which is invalid IR.
+
+define <4 x double> @PR60649() {
+; CHECK-LABEL: @PR60649(
+; CHECK-NEXT:  entry:
+; CHECK-NEXT:    br label [[END:%.*]]
+; CHECK:       unreachable:
+; CHECK-NEXT:    br label [[END]]
+; CHECK:       end:
+; CHECK-NEXT:    [[T0:%.*]] = phi <4 x double> [ zeroinitializer, [[ENTRY:%.*]] ], [ zeroinitializer, [[UNREACHABLE:%.*]] ]
+; CHECK-NEXT:    [[T1:%.*]] = phi <4 x double> [ zeroinitializer, [[ENTRY]] ], [ zeroinitializer, [[UNREACHABLE]] ]
+; CHECK-NEXT:    [[TMP0:%.*]] = shufflevector <4 x double> [[T0]], <4 x double> [[T0]], <4 x i32> <i32 2, i32 3, i32 undef, i32 undef>
+; CHECK-NEXT:    [[TMP1:%.*]] = shufflevector <4 x double> [[T0]], <4 x double> [[T0]], <4 x i32> <i32 0, i32 1, i32 undef, i32 undef>
+; CHECK-NEXT:    [[TMP2:%.*]] = fdiv <4 x double> [[TMP1]], <double 0.000000e+00, double 0.000000e+00, double undef, double undef>
+; CHECK-NEXT:    [[TMP3:%.*]] = fmul <4 x double> [[TMP0]], <double 0.000000e+00, double 0.000000e+00, double undef, double undef>
+; CHECK-NEXT:    [[T5:%.*]] = shufflevector <4 x double> [[TMP2]], <4 x double> [[TMP3]], <4 x i32> <i32 0, i32 1, i32 4, i32 5>
+; CHECK-NEXT:    ret <4 x double> [[T5]]
+;
+entry:
+  br label %end
+
+unreachable:
+  br label %end
+
+end:
+  %t0 = phi <4 x double> [ zeroinitializer, %entry ], [ zeroinitializer, %unreachable ]
+  %t1 = phi <4 x double> [ zeroinitializer, %entry ], [ zeroinitializer, %unreachable ]
+  %t2 = shufflevector <4 x double> zeroinitializer, <4 x double> zeroinitializer, <4 x i32> <i32 0, i32 0, i32 1, i32 1>
+  %t3 = fdiv <4 x double> %t0, %t2
+  %t4 = fmul <4 x double> %t0, %t2
+  %t5 = shufflevector <4 x double> %t3, <4 x double> %t4, <4 x i32> <i32 0, i32 1, i32 6, i32 7>
+  ret <4 x double> %t5
+}

From e010657e399d312a9440732a8a67125ecd0e2298 Mon Sep 17 00:00:00 2001
From: Phoebe Wang <phoebe.wang@intel.com>
Date: Thu, 1 Dec 2022 22:31:51 +0800
Subject: [PATCH 82/84] [X86][FP16] Do not combine fminnum/fmaxnum for FP16
 emulation

Under the emulation situation, we lack native fmin/fmax instruction support.

Fixes #59258

Reviewed By: skan, spatel

Differential Revision: https://reviews.llvm.org/D139078
---
 llvm/lib/Target/X86/X86ISelLowering.cpp |   4 +-
 llvm/test/CodeGen/X86/pr59258.ll        | 169 ++++++++++++++++++++++++
 2 files changed, 171 insertions(+), 2 deletions(-)
 create mode 100644 llvm/test/CodeGen/X86/pr59258.ll

diff --git a/llvm/lib/Target/X86/X86ISelLowering.cpp b/llvm/lib/Target/X86/X86ISelLowering.cpp
index cd45c48259bbfa..a53192bce8fd18 100644
--- a/llvm/lib/Target/X86/X86ISelLowering.cpp
+++ b/llvm/lib/Target/X86/X86ISelLowering.cpp
@@ -51111,12 +51111,12 @@ static SDValue combineFMinFMax(SDNode *N, SelectionDAG &DAG) {
 
 static SDValue combineFMinNumFMaxNum(SDNode *N, SelectionDAG &DAG,
                                      const X86Subtarget &Subtarget) {
-  if (Subtarget.useSoftFloat())
+  EVT VT = N->getValueType(0);
+  if (Subtarget.useSoftFloat() || isSoftFP16(VT, Subtarget))
     return SDValue();
 
   const TargetLowering &TLI = DAG.getTargetLoweringInfo();
 
-  EVT VT = N->getValueType(0);
   if (!((Subtarget.hasSSE1() && VT == MVT::f32) ||
         (Subtarget.hasSSE2() && VT == MVT::f64) ||
         (Subtarget.hasFP16() && VT == MVT::f16) ||
diff --git a/llvm/test/CodeGen/X86/pr59258.ll b/llvm/test/CodeGen/X86/pr59258.ll
new file mode 100644
index 00000000000000..fb2d219556632f
--- /dev/null
+++ b/llvm/test/CodeGen/X86/pr59258.ll
@@ -0,0 +1,169 @@
+; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
+; RUN: llc < %s -mtriple=x86_64-unknown-unknown | FileCheck %s
+
+define <8 x half> @cvt_and_clamp2(<8 x float>) nounwind {
+; CHECK-LABEL: cvt_and_clamp2:
+; CHECK:       # %bb.0:
+; CHECK-NEXT:    subq $120, %rsp
+; CHECK-NEXT:    movaps %xmm1, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
+; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
+; CHECK-NEXT:    movaps %xmm1, %xmm0
+; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3],xmm1[3,3]
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
+; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
+; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
+; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[3,3,3,3]
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
+; CHECK-NEXT:    movhlps {{.*#+}} xmm0 = xmm0[1,1]
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movaps {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Reload
+; CHECK-NEXT:    shufps {{.*#+}} xmm0 = xmm0[1,1,1,1]
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    xorps %xmm1, %xmm1
+; CHECK-NEXT:    callq fmaxf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    xorps %xmm1, %xmm1
+; CHECK-NEXT:    callq fmaxf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    xorps %xmm1, %xmm1
+; CHECK-NEXT:    callq fmaxf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    xorps %xmm1, %xmm1
+; CHECK-NEXT:    callq fmaxf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    xorps %xmm1, %xmm1
+; CHECK-NEXT:    callq fmaxf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    xorps %xmm1, %xmm1
+; CHECK-NEXT:    callq fmaxf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    xorps %xmm1, %xmm1
+; CHECK-NEXT:    callq fmaxf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movss %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 4-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    xorps %xmm1, %xmm1
+; CHECK-NEXT:    callq fmaxf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq fminf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
+; CHECK-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq fminf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
+; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
+; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq fminf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
+; CHECK-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq fminf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
+; CHECK-NEXT:    punpcklwd {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1],xmm1[2],xmm0[2],xmm1[3],xmm0[3]
+; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Folded Reload
+; CHECK-NEXT:    # xmm1 = xmm1[0],mem[0],xmm1[1],mem[1]
+; CHECK-NEXT:    movdqa %xmm1, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq fminf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
+; CHECK-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq fminf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    punpcklwd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 16-byte Folded Reload
+; CHECK-NEXT:    # xmm0 = xmm0[0],mem[0],xmm0[1],mem[1],xmm0[2],mem[2],xmm0[3],mem[3]
+; CHECK-NEXT:    movdqa %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
+; CHECK-NEXT:    movss {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq fminf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movaps %xmm0, {{[-0-9]+}}(%r{{[sb]}}p) # 16-byte Spill
+; CHECK-NEXT:    movd {{[-0-9]+}}(%r{{[sb]}}p), %xmm0 # 4-byte Folded Reload
+; CHECK-NEXT:    # xmm0 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq __extendhfsf2@PLT
+; CHECK-NEXT:    movss {{.*#+}} xmm1 = mem[0],zero,zero,zero
+; CHECK-NEXT:    callq fminf@PLT
+; CHECK-NEXT:    callq __truncsfhf2@PLT
+; CHECK-NEXT:    movdqa {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Reload
+; CHECK-NEXT:    punpcklwd {{.*#+}} xmm1 = xmm1[0],xmm0[0],xmm1[1],xmm0[1],xmm1[2],xmm0[2],xmm1[3],xmm0[3]
+; CHECK-NEXT:    punpckldq {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Folded Reload
+; CHECK-NEXT:    # xmm1 = xmm1[0],mem[0],xmm1[1],mem[1]
+; CHECK-NEXT:    punpcklqdq {{[-0-9]+}}(%r{{[sb]}}p), %xmm1 # 16-byte Folded Reload
+; CHECK-NEXT:    # xmm1 = xmm1[0],mem[0]
+; CHECK-NEXT:    movdqa %xmm1, %xmm0
+; CHECK-NEXT:    addq $120, %rsp
+; CHECK-NEXT:    retq
+    %2 = fptrunc <8 x float> %0 to <8 x half>
+    %3 = call <8 x half> @llvm.maxnum.v8f16(<8 x half> zeroinitializer, <8 x half> %2)
+    %4 = call <8 x half> @llvm.minnum.v8f16(<8 x half> %3, <8 x half> <half 1.0, half 1.0, half 1.0, half 1.0, half 1.0, half 1.0, half 1.0, half 1.0>)
+    ret <8 x half> %4
+}
+
+declare <8 x half> @llvm.maxnum.v8f16(<8 x half>, <8 x half>)
+declare <8 x half> @llvm.minnum.v8f16(<8 x half>, <8 x half>)

From 084cd0fc414425be2d22f23552b79432dcbb01f0 Mon Sep 17 00:00:00 2001
From: Anton Smirnov <tonysmn97@gmail.com>
Date: Tue, 17 Oct 2023 18:48:14 +0300
Subject: [PATCH 83/84] [AMDGPU][Backend] Fix user-after-free in
 AMDGPUReleaseVGPRs::isLastVGPRUseVMEMStore (#21)
MIME-Version: 1.0
Content-Type: text/plain; charset=UTF-8
Content-Transfer-Encoding: 8bit

Reviewed By: jpages, arsenm

Differential Revision: https://reviews.llvm.org/D134641

(cherry picked from commit bb24b2c610b4fea76a3682b108847f69e230714c)

Co-authored-by: Juan Manuel MARTINEZ CAAMAO <juamarti@amd.com>
---
 llvm/lib/Target/AMDGPU/AMDGPUReleaseVGPRs.cpp | 106 ++++++++++--------
 1 file changed, 60 insertions(+), 46 deletions(-)

diff --git a/llvm/lib/Target/AMDGPU/AMDGPUReleaseVGPRs.cpp b/llvm/lib/Target/AMDGPU/AMDGPUReleaseVGPRs.cpp
index a86871a4a653f6..c53e262d23dfb4 100644
--- a/llvm/lib/Target/AMDGPU/AMDGPUReleaseVGPRs.cpp
+++ b/llvm/lib/Target/AMDGPU/AMDGPUReleaseVGPRs.cpp
@@ -16,7 +16,7 @@
 #include "GCNSubtarget.h"
 #include "MCTargetDesc/AMDGPUMCTargetDesc.h"
 #include "SIDefines.h"
-#include "llvm/ADT/STLExtras.h"
+#include "llvm/ADT/DepthFirstIterator.h"
 #include "llvm/CodeGen/MachineBasicBlock.h"
 #include "llvm/CodeGen/MachineOperand.h"
 using namespace llvm;
@@ -29,9 +29,6 @@ class AMDGPUReleaseVGPRs : public MachineFunctionPass {
 public:
   static char ID;
 
-  const SIInstrInfo *SII;
-  const SIRegisterInfo *TRI;
-
   AMDGPUReleaseVGPRs() : MachineFunctionPass(ID) {}
 
   void getAnalysisUsage(AnalysisUsage &AU) const override {
@@ -39,50 +36,69 @@ class AMDGPUReleaseVGPRs : public MachineFunctionPass {
     MachineFunctionPass::getAnalysisUsage(AU);
   }
 
-  // Used to cache the result of isLastInstructionVMEMStore for each block
-  using BlockVMEMStoreType = DenseMap<MachineBasicBlock *, bool>;
-  BlockVMEMStoreType BlockVMEMStore;
-
-  // Return true if the last instruction referencing a vgpr in this MBB
-  // is a VMEM store, otherwise return false.
-  // Visit previous basic blocks to find this last instruction if needed.
-  // Because this pass is late in the pipeline, it is expected that the
+  // Track if the last instruction referencing a vgpr in a MBB is a VMEM
+  // store. Because this pass is late in the pipeline, it is expected that the
   // last vgpr use will likely be one of vmem store, ds, exp.
   // Loads and others vgpr operations would have been
   // deleted by this point, except for complex control flow involving loops.
   // This is why we are just testing the type of instructions rather
   // than the operands.
-  bool isLastVGPRUseVMEMStore(MachineBasicBlock &MBB) {
-    // Use the cache to break infinite loop and save some time. Initialize to
-    // false in case we have a cycle.
-    BlockVMEMStoreType::iterator It;
-    bool Inserted;
-    std::tie(It, Inserted) = BlockVMEMStore.insert({&MBB, false});
-    bool &CacheEntry = It->second;
-    if (!Inserted)
-      return CacheEntry;
-
-    for (auto &MI : reverse(MBB.instrs())) {
-      // If it's a VMEM store, a vgpr will be used, return true.
-      if ((SIInstrInfo::isVMEM(MI) || SIInstrInfo::isFLAT(MI)) && MI.mayStore())
-        return CacheEntry = true;
-
-      // If it's referencing a VGPR but is not a VMEM store, return false.
-      if (SIInstrInfo::isDS(MI) || SIInstrInfo::isEXP(MI) ||
-          SIInstrInfo::isVMEM(MI) || SIInstrInfo::isFLAT(MI) ||
-          SIInstrInfo::isVALU(MI))
-        return CacheEntry = false;
+  class LastVGPRUseIsVMEMStore {
+    BitVector BlockVMEMStore;
+
+    static Optional<bool> lastVGPRUseIsStore(const MachineBasicBlock &MBB) {
+      for (auto &MI : reverse(MBB.instrs())) {
+        // If it's a VMEM store, a VGPR will be used, return true.
+        if ((SIInstrInfo::isVMEM(MI) || SIInstrInfo::isFLAT(MI)) &&
+            MI.mayStore())
+          return true;
+
+        // If it's referencing a VGPR but is not a VMEM store, return false.
+        if (SIInstrInfo::isDS(MI) || SIInstrInfo::isEXP(MI) ||
+            SIInstrInfo::isVMEM(MI) || SIInstrInfo::isFLAT(MI) ||
+            SIInstrInfo::isVALU(MI))
+          return false;
+      }
+      // Wait until the values are propagated from the predecessors
+      return None;
     }
 
-    // Recursive call into parent blocks. Look into predecessors if there is no
-    // vgpr used in this block.
-    return CacheEntry = llvm::any_of(MBB.predecessors(),
-                                     [this](MachineBasicBlock *Parent) {
-                                       return isLastVGPRUseVMEMStore(*Parent);
-                                     });
-  }
+  public:
+    LastVGPRUseIsVMEMStore(const MachineFunction &MF)
+        : BlockVMEMStore(MF.getNumBlockIDs()) {
+
+      df_iterator_default_set<const MachineBasicBlock *> Visited;
+      SmallVector<const MachineBasicBlock *> EndWithVMEMStoreBlocks;
+
+      for (const auto &MBB : MF) {
+        auto LastUseIsStore = lastVGPRUseIsStore(MBB);
+        if (!LastUseIsStore.has_value())
+          continue;
+
+        if (*LastUseIsStore) {
+          EndWithVMEMStoreBlocks.push_back(&MBB);
+        } else {
+          Visited.insert(&MBB);
+        }
+      }
+
+      for (const auto *MBB : EndWithVMEMStoreBlocks) {
+        for (const auto *Succ : depth_first_ext(MBB, Visited)) {
+          BlockVMEMStore[Succ->getNumber()] = true;
+        }
+      }
+    }
+
+    // Return true if the last instruction referencing a vgpr in this MBB
+    // is a VMEM store, otherwise return false.
+    bool isLastVGPRUseVMEMStore(const MachineBasicBlock &MBB) const {
+      return BlockVMEMStore[MBB.getNumber()];
+    }
+  };
 
-  bool runOnMachineBasicBlock(MachineBasicBlock &MBB) {
+  static bool
+  runOnMachineBasicBlock(MachineBasicBlock &MBB, const SIInstrInfo *SII,
+                         const LastVGPRUseIsVMEMStore &BlockVMEMStore) {
 
     bool Changed = false;
 
@@ -93,7 +109,7 @@ class AMDGPUReleaseVGPRs : public MachineFunctionPass {
         // If the last instruction using a VGPR in the block is a VMEM store,
         // release VGPRs. The VGPRs release will be placed just before ending
         // the program
-        if (isLastVGPRUseVMEMStore(MBB)) {
+        if (BlockVMEMStore.isLastVGPRUseVMEMStore(MBB)) {
           BuildMI(MBB, MI, DebugLoc(), SII->get(AMDGPU::S_SENDMSG))
               .addImm(AMDGPU::SendMsg::ID_DEALLOC_VGPRS_GFX11Plus);
           Changed = true;
@@ -117,16 +133,14 @@ class AMDGPUReleaseVGPRs : public MachineFunctionPass {
     LLVM_DEBUG(dbgs() << "AMDGPUReleaseVGPRs running on " << MF.getName()
                       << "\n");
 
-    SII = ST.getInstrInfo();
-    TRI = ST.getRegisterInfo();
+    const SIInstrInfo *SII = ST.getInstrInfo();
+    LastVGPRUseIsVMEMStore BlockVMEMStore(MF);
 
     bool Changed = false;
     for (auto &MBB : MF) {
-      Changed |= runOnMachineBasicBlock(MBB);
+      Changed |= runOnMachineBasicBlock(MBB, SII, BlockVMEMStore);
     }
 
-    BlockVMEMStore.clear();
-
     return Changed;
   }
 };

From 2593167b92dd2d27849e8bc331db2072a9b4bd7f Mon Sep 17 00:00:00 2001
From: Valentin Churavy <vchuravy@users.noreply.github.com>
Date: Mon, 4 Dec 2023 11:21:55 -0500
Subject: [PATCH 84/84] Block hoisting bitcasts over non-integral ascast (#23)

---
 llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp | 4 +++-
 1 file changed, 3 insertions(+), 1 deletion(-)

diff --git a/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp b/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp
index a9a930555b3c65..5f09f59cff7d64 100644
--- a/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp
+++ b/llvm/lib/Transforms/InstCombine/InstCombineCasts.cpp
@@ -2906,8 +2906,10 @@ Instruction *InstCombinerImpl::visitAddrSpaceCast(AddrSpaceCastInst &CI) {
   Value *Src = CI.getOperand(0);
   PointerType *SrcTy = cast<PointerType>(Src->getType()->getScalarType());
   PointerType *DestTy = cast<PointerType>(CI.getType()->getScalarType());
+  bool isni = DL.isNonIntegralAddressSpace(SrcTy->getAddressSpace()) ||
+              DL.isNonIntegralAddressSpace(DestTy->getAddressSpace());
 
-  if (!SrcTy->hasSameElementTypeAs(DestTy)) {
+  if (!SrcTy->hasSameElementTypeAs(DestTy) && !isni) {
     Type *MidTy =
         PointerType::getWithSamePointeeType(DestTy, SrcTy->getAddressSpace());
     // Handle vectors of pointers.
